<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>这是博客</title>
  
  <subtitle>试图存在, 但薛三无法自证</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2023-03-07T02:26:03.000Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Vincent Xue</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Leetcode-代码随想录总结</title>
    <link href="http://example.com/2023/03/07/Leetcode-%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95%E6%80%BB%E7%BB%93/"/>
    <id>http://example.com/2023/03/07/Leetcode-%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95%E6%80%BB%E7%BB%93/</id>
    <published>2023-03-07T02:26:03.000Z</published>
    <updated>2023-03-07T02:26:03.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>内容整理自<a href="https://www.programmercarl.com/">代码随想录</a></p></blockquote><h2 id="dp-动态规划">1. DP 动态规划</h2><h3 id="思路框架">1.1 思路框架</h3><p>动规五部曲分别为：</p><ol type="1"><li><p><strong>确定dp数组（dp table）以及下标的含义</strong></p><p>一般来说，dp数组元素即为题目所求的局部最优结果。分析问题规模确定数组维数；</p></li><li><p><strong>确定递推公式</strong></p><p>注意紧扣数组定义；</p></li><li><p><strong>dp数组如何初始化</strong></p></li><li><p><strong>确定遍历顺序</strong></p><p>根据递推公式所需的上下文，确定方向。</p><p>如有 <code>dp[i][j] = dp[i + 1][j - 1] + 1</code>，则遍历顺序为 i由大到小，j由小到大；</p></li><li><p><strong>举例推导dp数组</strong></p><p>辅助Debug检验代码实现/递推公式缺漏。</p></li></ol><h3 id="背包问题">1.2 背包问题</h3><ul><li>思路</li></ul><p>题目不会直给地点明是背包问题，需要分析物品和背包对应题目中的什么元素。有时元素<strong>同时是物品和背包</strong>。</p><ul><li>01背包（每种物品仅有1件）</li></ul><p>——滚动数组实现</p><p>dp[j]表示：容量为j的背包，所背的物品价值可以最大为dp[j]。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; weight.<span class="built_in">size</span>(); i++) &#123; <span class="comment">// 遍历物品</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = bagWeight; j &gt;= weight[i]; j--) &#123; <span class="comment">// 遍历背包容量</span></span><br><span class="line">        dp[j] = <span class="built_in">max</span>(dp[j], dp[j - weight[i]] + value[i]);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>倒序遍历</strong>是为了保证物品i只被放入一次！</p><ul><li>完全背包（每种物品有无限件）</li></ul><p>完全背包的物品是可以添加多次的，所以要<strong>从小到大去遍历</strong>，即：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 先遍历物品，再遍历背包</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; weight.<span class="built_in">size</span>(); i++) &#123; <span class="comment">// 遍历物品</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = weight[i]; j &lt;= bagWeight ; j++) &#123; <span class="comment">// 遍历背包容量</span></span><br><span class="line">        dp[j] = <span class="built_in">max</span>(dp[j], dp[j - weight[i]] + value[i]);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是仅仅是纯完全背包的遍历顺序是这样的，题目稍有变化，两个for循环的先后顺序就不一样了。</p><p><strong>如果求组合数就是外层for循环遍历物品，内层for遍历背包</strong>。</p><p><strong>如果求排列数就是外层for遍历背包，内层for循环遍历物品</strong>。</p><h3 id="其他系列">1.3 其他系列</h3><ul><li><a href="https://www.programmercarl.com/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93%E7%AF%87.html#%E8%82%A1%E7%A5%A8%E7%B3%BB%E5%88%97">股票系列</a></li><li><a href="https://www.programmercarl.com/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93%E7%AF%87.html#%E5%AD%90%E5%BA%8F%E5%88%97%E7%B3%BB%E5%88%97">子序列 Subsequence / 子数组 Subarray</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;内容整理自&lt;a href=&quot;https://www.programmercarl.com/&quot;&gt;代码随想录&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;dp-动态规划&quot;&gt;1. DP 动态规划&lt;/h2&gt;
&lt;h3 id=&quot;思路框架</summary>
      
    
    
    
    <category term="工具人" scheme="http://example.com/categories/%E5%B7%A5%E5%85%B7%E4%BA%BA/"/>
    
    
    <category term="Leetcode" scheme="http://example.com/tags/Leetcode/"/>
    
    <category term="找工" scheme="http://example.com/tags/%E6%89%BE%E5%B7%A5/"/>
    
  </entry>
  
  <entry>
    <title>MSL-24-自驱新时代(Memo)</title>
    <link href="http://example.com/2023/03/07/MSL-24-%E8%87%AA%E9%A9%B1%E6%96%B0%E6%97%B6%E4%BB%A3-Memo/"/>
    <id>http://example.com/2023/03/07/MSL-24-%E8%87%AA%E9%A9%B1%E6%96%B0%E6%97%B6%E4%BB%A3-Memo/</id>
    <published>2023-03-06T17:16:08.000Z</published>
    <updated>2023-03-06T17:16:08.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>自驱、持续学习重要性愈发凸显</strong>。 <span id="more"></span></p><p>ChatGPT Api 可供大众调用了，各式产品、生产力工具开始涌现。</p><p>摸鱼刷着知乎，看到：</p><blockquote><p>Bilibili x OpenAI x Notion x Python：分享我的长视频自动化摘要笔记完整工作流（万字长文，代码分享，点赞收藏） - 段小草的文章 - 知乎 https://zhuanlan.zhihu.com/p/610250035</p></blockquote><p>已经有人基于ChatGPT Api，定制出视频自动化摘要笔记的程序。意味着过往截图、摘抄、个人概括等繁琐流程，都被压缩，个人时间能更多用于吸收视频传递的信息。</p><ul><li><strong>工具的进化，拉大了人与人间可达的差距</strong></li></ul><p>好比两人比赛远行，过往只能徒步，自驱者每日多行二三小时不过领先几里路；而今两人都被赋予汽车，自驱者迅速学会开车并远行，不消几日就将彻底领先无踪。</p><ul><li><strong>自驱，主动学习</strong></li></ul><p>切要摆脱应试填鸭思维，被动学习。当下时代，更需要找到自己生活的主线，主动探索，利用新生产力工具提升自我。</p><ul><li><strong>自驱亦分层级</strong></li></ul><p>高级的，知晓个人需求，定制工具强壮自身；中级的，拥抱新工具，活学活用；低级的，则仍满足于低效的旧模式，暗自满足。</p><hr /><p>有了以ChatGPT代表的新LLM模型，仓鼠症更需根治了。徒劳囤积资料无效，逻辑与分辨力才是关键——海量信息可依靠AI负责提取，人则负责分辨并指引AI优化提取结果，进而将信息化作知识乃至更高维内容。</p><figure><img src="./image-20230307013217319-16781239438421.png" alt="image-20230307013217319" /><figcaption aria-hidden="true">image-20230307013217319</figcaption></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;自驱、持续学习重要性愈发凸显&lt;/strong&gt;。</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>Torch-CopyModel的坑</title>
    <link href="http://example.com/2023/02/16/Torch-CopyModel%E7%9A%84%E5%9D%91/"/>
    <id>http://example.com/2023/02/16/Torch-CopyModel%E7%9A%84%E5%9D%91/</id>
    <published>2023-02-16T02:32:11.000Z</published>
    <updated>2023-02-16T02:32:11.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Main reference: <a href="https://androidkt.com/copy-pytorch-model-using-deepcopy-and-state_dict/">Copy PyTorch Model using deepcopy() and state_dict()</a></p></blockquote><p>近日验证idea，踩中Pytorch复制模型的大坑，遂记录如下。</p><span id="more"></span><h1 id="概况">1. 概况</h1><p><strong>问题现象：</strong>进行联邦学习+GNN知识蒸馏的idea验证，发现在进行FedAvg后，模型loss、acc等不再变化。</p><figure><img src="./image-20230216104047624.png" alt="image-20230216104047624" /><figcaption aria-hidden="true">image-20230216104047624</figcaption></figure><p><strong>原因概述</strong>：复制模型时未对optimizer做重新初始化。</p><figure><img src="./image-20230216103949066.png" alt="image-20230216103949066" /><figcaption aria-hidden="true">image-20230216103949066</figcaption></figure><h1 id="问题发现与探索简述">2. 问题发现与探索（简述）</h1><ol type="1"><li>FedAvg+KD时，loss、acc未如预期一般成锯齿形下降，而是在第一次聚合后便不再变化。</li><li>检查模型架构是否异常；</li><li>聚合算法实现检查。但FedAvg + GNN/MLP 正常收敛（这就是坑点，代码实现的单个分析都没有问题）；</li><li>检查模型是否设置异常，未开启反向传播。但<code>print(model.weight.grad())</code>不为0，<code>require_grad==True</code>设置没有问题，但每轮训练，<code>weights, grad</code>都不变（接近发现原因了！）；</li><li>反思是否是梯度消失。但打印的梯度及其变化情况，与梯度消失现象不一致；</li><li>设置client=1，一个模型不进行<code>deepcopy()</code>，只进行知识蒸馏，可以正常训练。另一个模型进行知识蒸馏，并且每一个epoch将参数复制到相同架构的模型，再通过<code>deepcopy</code>拷贝回来，异常！</li></ol><h1 id="bug所在">3. BUG所在</h1><ol type="1"><li><p>FedAvg参考他人实现，server模型下发回客户端时使用的是<code>deepcopy</code>：</p><figure><img src="./image-20230216110124249.png" alt="image-20230216110124249" /><figcaption aria-hidden="true">image-20230216110124249</figcaption></figure></li><li><p>知识蒸馏参考他人实现，训练时<code>optimizer</code>作为参数传入：</p><figure><img src="./image-20230216110251502.png" alt="image-20230216110251502" /><figcaption aria-hidden="true">image-20230216110251502</figcaption></figure><p>（而我惯常的<code>train()</code>,optimizer对象是在函数内创建，即每次调用<code>train()</code>时都会重新初始化optimizer）</p></li></ol><p>上述二者，每个都能完成原始代码的既定任务，但两者结合使用时，就会发生optimizer无法更新模型参数的问题！</p><h1 id="pytorch-模型复制">4. Pytorch 模型复制</h1><p>见<a href="https://androidkt.com/copy-pytorch-model-using-deepcopy-and-state_dict/">Copy PyTorch Model using deepcopy() and state_dict()</a></p><ul><li><code>copy.deepcopy()</code>：完整地<strong>深拷贝</strong>整个模型，创建<strong>全新的对象</strong>。该对象递归地复制原模型的内部对象的值。训练新模型需要对原optimizer<strong>重新初始化</strong>；</li><li><code>new_model.load_state_dict(model.state_dict())</code>，首先用户需要自己创建<code>new_model</code>，新模型的架构应与被复制模型的架构一致。<code>load_state_dict</code> only copies parameters and buffers。实践发现不需对原optimizer重新初始化。</li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Main reference: &lt;a href=&quot;https://androidkt.com/copy-pytorch-model-using-deepcopy-and-state_dict/&quot;&gt;Copy PyTorch Model using deepcopy() and state_dict()&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;近日验证idea，踩中Pytorch复制模型的大坑，遂记录如下。&lt;/p&gt;</summary>
    
    
    
    <category term="工具人" scheme="http://example.com/categories/%E5%B7%A5%E5%85%B7%E4%BA%BA/"/>
    
    
    <category term="Pytorch" scheme="http://example.com/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>MSL-23-且行一步</title>
    <link href="http://example.com/2023/02/12/MSL-23-%E4%B8%94%E8%A1%8C%E4%B8%80%E6%AD%A5/"/>
    <id>http://example.com/2023/02/12/MSL-23-%E4%B8%94%E8%A1%8C%E4%B8%80%E6%AD%A5/</id>
    <published>2023-02-12T14:43:51.000Z</published>
    <updated>2023-02-12T14:43:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>终究还是迈出了那一步。</p><span id="more"></span><h1 id="再见的二义性">1. 再见的二义性</h1><p>再见：</p><p>1．再一次见面。 2．临别套语，用于分别时。表示希望以后再见面。</p><p>谭校长的《讲不出再见》一直未能欣赏，直到自己逢了那境遇，才知晓其词曲意。</p><p>情路旅途不止一段，然而此回，终于是轮到我，由我第一次来开口，道声再见。</p><p>原来主动开口，尽管理智层面已然分分秒秒间分析过千千万万回长远故事的不可为继，还是那般沉重且沉痛。会忍不住想象那头的神情——虽然被哥们骂自作多情；会恍惚质问自己；会失眠。</p><p>但仍是决定迈步，重整自我，先修身吧。</p><p>再见，不愿其为套话，由衷地期盼着未来仍能交会，或是作为并行的朋友。</p><h1 id="方向与前路">2. 方向与前路</h1><p>与共同成长的友人间距离愈发遥远。个人的成长是何时开始停滞的？</p><p>友人说，要做有价值的工作，让自己收获成就感与存在感。</p><p>友人说，对任何行事前不经思索，不明自己举止动机的人感到恶心。</p><p>友人说，构建自洽的生活方式……</p><p>我呢？些许混沌。谈恋爱，似乎也只是掌握不少讨欢心的tricks罢了。</p><p>怎样能拾回自信，怎样寻到方向与前路？</p><h1 id="启航">3. 启航</h1><p>此节且做为memo，等待不断补充吧。</p><p>愿景：</p><ul><li>姑且将人生目标，定为追求高质量且丰富的体验吧；</li></ul><p>愿望：</p><ul><li></li></ul><p>习惯：</p><ul><li>自省前置，决策前自问是否符合自我愿景，对其是否有利；</li></ul><p>技巧：</p><ul><li></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;终究还是迈出了那一步。&lt;/p&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>MSL_22_经得起变化</title>
    <link href="http://example.com/2023/01/16/MSL-22-%E7%BB%8F%E5%BE%97%E8%B5%B7%E5%8F%98%E5%8C%96/"/>
    <id>http://example.com/2023/01/16/MSL-22-%E7%BB%8F%E5%BE%97%E8%B5%B7%E5%8F%98%E5%8C%96/</id>
    <published>2023-01-16T03:00:59.000Z</published>
    <updated>2023-01-16T03:00:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>不再是光谷，没去到红馆。人来人往，终于是只身一人来顺德。</p><p>Alan Po，来日之音。</p><span id="more"></span><p>18排，1座——一楼靠后的角落，右手边是过道，左边坐着结伴而来的三位陌生人。早早到场的结果，便是开show前，些许无聊，些许尴尬无助，无人可倾谈、分享。</p><p>直到，灯光熄灭，舞台闪烁时。演唱会的意义，或许在于音乐奏响、歌手演唱时，观众间的陌生恍然间弥散，齐心随音乐摇摆、合唱。</p><p><img src="./摇摆.jpg" /></p><p>茫茫众生，大多都在寻求团体的温暖。演唱会两小时的时光，厅内的各位，仿似家人。为阿纶欢呼，为求婚的情侣祝福，为那首首单循过的歌曲尖叫。</p><p><img src="./昨天.jpg" /></p><p><img src="./合照.jpg" /></p><p>直到曲终人静时，又重回一个个陌生的个体。轻哼着encore的曲目，收拾行囊，步出会场。</p><p>不必否定孤独。混于人群时纷扰太多，忙于应付周遭；困于人群自我太少，疏于扪心自问。</p><p>三年疫情，太多人事消散变迁。我也陷入失语症：迟滞，不善表达，亦恐于落笔。关于疫情的管控已解绑，且将它视作一界碑，分隔前些日子茫然的自我。</p><p>而今，重温独处，重习专注，爱自我，爱生活吧。人，要经得起变化才是。</p><p>「望四周的身影如幻覺</p><p>舊照片的溫馨情已不再</p><p>縱使它不可變改</p><p>人總要自愛」</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;不再是光谷，没去到红馆。人来人往，终于是只身一人来顺德。&lt;/p&gt;
&lt;p&gt;Alan Po，来日之音。&lt;/p&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>MSL_21_LifeGoesOn</title>
    <link href="http://example.com/2022/12/31/MSL-21-LifeGoesOn/"/>
    <id>http://example.com/2022/12/31/MSL-21-LifeGoesOn/</id>
    <published>2022-12-31T15:21:32.000Z</published>
    <updated>2022-12-31T15:21:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>Life Must Goes On...</p><p>2022已过去，依旧青春热血莽撞无虑，但也依旧幼稚短视懒惰。</p><p>回首2022的日子，并不能骄傲地于此尽数，只得怯弱地将愿景寄托于2023年。</p><p>或许依旧该张狂地吹下种种牛逼，然而23年，24岁的我，该将吹得牛通通实现才是。</p><blockquote><p>有悲总有喜 人不要自危</p><p>随时代走用眼泪伴这双手</p><p>再辛苦也好 亦不要淡忘</p><p>前景多好看</p><p>不要淡忘</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Life Must Goes On...&lt;/p&gt;
&lt;p&gt;2022已过去，依旧青春热血莽撞无虑，但也依旧幼稚短视懒惰。&lt;/p&gt;
&lt;p&gt;回首2022的日子，并不能骄傲地于此尽数，只得怯弱地将愿景寄托于2023年。&lt;/p&gt;
&lt;p&gt;或许依旧该张狂地吹下种种牛逼，然而23年，2</summary>
      
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>联邦学习03_模型异构</title>
    <link href="http://example.com/2022/11/05/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A003-%E6%A8%A1%E5%9E%8B%E5%BC%82%E6%9E%84/"/>
    <id>http://example.com/2022/11/05/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A003-%E6%A8%A1%E5%9E%8B%E5%BC%82%E6%9E%84/</id>
    <published>2022-11-05T07:34:01.000Z</published>
    <updated>2022-11-10T11:18:06.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="flheterogeneous-model-小结">FL：Heterogeneous model 小结</h1><h2 id="motivations">0. Motivations</h2><ol type="1"><li><strong>System heterogeneity</strong>. Clients have various computation and bandwidth resources, where each participant has capacity and desire to design their own unique model.</li><li>Strong server, weak client.</li></ol><span id="more"></span><h2 id="knowledge-distillation-入门">1. Knowledge Distillation 入门</h2><blockquote><p>Ref: 【经典简读】知识蒸馏(Knowledge Distillation) 经典之作 - 潘小小的文章 - 知乎 https://zhuanlan.zhihu.com/p/102038521</p></blockquote><figure><img src="./image-20221104103056522.png" alt="image-20221104103056522" /><figcaption aria-hidden="true">image-20221104103056522</figcaption></figure><p>知识蒸馏使用的是Teacher—Student模型，其中teacher是“知识”的输出者，student是“知识”的接受者。知识蒸馏的过程分为2个阶段:</p><ol type="1"><li>原始模型训练: 训练"Teacher模型", 简称为Net-T，它的特点是模型相对复杂。对于输入X, 其都能输出Y，其中Y经过softmax的映射，输出值对应相应类别的概率值。</li><li>精简模型训练: 训练"Student模型", 简称为Net-S，它是参数量较小、模型结构相对简单的单模型。同样的，对于输入X，其都能输出Y，Y经过softmax映射后同样能输出对应相应类别的概率值。</li></ol><p><strong>Soft Labels(Soft Targets)</strong></p><figure><img src="./image-20221104103157056.png" alt="image-20221104103157056" /><figcaption aria-hidden="true">image-20221104103157056</figcaption></figure><p>最后，Net-S的目标函数有： <span class="math display">\[L=\alpha L_{\text {soft }}+\beta L_{\text {hard }}\]</span></p><h2 id="hetemodel-fl-with-knowledge-distillation">2. HeteModel-FL with knowledge distillation</h2><h3 id="fedhe">2.1 FedHe</h3><blockquote><p>FedHe: Heterogeneous Models and Communication-Efficient Federated Learning</p><p>2021 17th International Conference on Mobility, Sensing and Networking (MSN) 2021</p></blockquote><figure><img src="./image-20221104104226887.png" alt="image-20221104104226887" /><figcaption aria-hidden="true">image-20221104104226887</figcaption></figure><p>Server不承担teacher模型训练，只负责聚合各个client上传的各类样本的logits，并将聚合的结果发还。</p><p>Clients端把 aggregated logits 视作 soft label 进行学习。</p><h3 id="fedmd">2.2 FedMD</h3><blockquote><p>Fedmd: Heterogenous federated learning via model distillation</p><p>arXiv preprint 2019</p><p>Code: https://github.com/diogenes0319/FedMD_clean</p></blockquote><figure><img src="./image-20221104110228287.png" alt="image-20221104110228287" /><figcaption aria-hidden="true">image-20221104110228287</figcaption></figure><p>Clients提供一部分数据来构建public dataset。</p><p>各 client 求 public dataset 对应的 logits。Server 负责聚合各个 client 的 logits 并求平均。发还的 avg(logits) 用以蒸馏 client 端的 model。</p><p>由于各 client 是用private dataset + public dataset训练模型，故对public dataset算出的logits中隐性地包含client private data distribution的信息，意味着使用蒸馏可以在不侵犯隐私的情况下获得其他的client的帮助。</p><h3 id="fml">2.3 FML</h3><blockquote><p>Federated mutual learning</p><p>arXiv preprint 2020</p></blockquote><figure><img src="./image-20221104110855842.png" alt="image-20221104110855842" /><figcaption aria-hidden="true">image-20221104110855842</figcaption></figure><p>设置 Global model 及 Personalized model。 Global model 架构相同，按照一般FL方式进行训练，作为 teacher model使用。</p><h3 id="fedh2l">2.4 FedH2L</h3><blockquote><p>FedH2L: Federated learning with model and statistical heterogeneity</p><p>arXiv preprint 2021</p></blockquote><p>需要共享部分数据作为seed data（文中未讨论seed data的选择和对模型影响）。</p><p>直接将知识蒸馏迁移到去中心化FL场景。client间互为teacher-student，进行知识蒸馏。</p><h3 id="对比">2.5 对比</h3><table><thead><tr class="header"><th>Model</th><th>Architecture</th><th>Share</th></tr></thead><tbody><tr class="odd"><td>FedHe</td><td>CS</td><td>Logits with class</td></tr><tr class="even"><td>FedMD</td><td>CS</td><td>Public dataset</td></tr><tr class="odd"><td>FML</td><td>CS</td><td>Global model weights</td></tr><tr class="even"><td>FedH2L</td><td>P2P</td><td>Seed data</td></tr></tbody></table><p>如何兼顾隐私与构建强teacher模型，仍是待讨论的问题。</p><h2 id="others">3. Others</h2><p><strong>Hyper networks</strong></p><p>通过Hyper networks学习personalized model weights，模型自由度较知识蒸馏低。</p><figure><img src="./image-20221104111951949.png" alt="image-20221104111951949" /><figcaption aria-hidden="true">image-20221104111951949</figcaption></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;flheterogeneous-model-小结&quot;&gt;FL：Heterogeneous model 小结&lt;/h1&gt;
&lt;h2 id=&quot;motivations&quot;&gt;0. Motivations&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;strong&gt;System heterogeneity&lt;/strong&gt;. Clients have various computation and bandwidth resources, where each participant has capacity and desire to design their own unique model.&lt;/li&gt;
&lt;li&gt;Strong server, weak client.&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="ML知识总结" scheme="http://example.com/categories/ML%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="联邦学习" scheme="http://example.com/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>GNN_表达能力小结</title>
    <link href="http://example.com/2022/10/29/GNN-%E8%A1%A8%E8%BE%BE%E8%83%BD%E5%8A%9B%E5%B0%8F%E7%BB%93/"/>
    <id>http://example.com/2022/10/29/GNN-%E8%A1%A8%E8%BE%BE%E8%83%BD%E5%8A%9B%E5%B0%8F%E7%BB%93/</id>
    <published>2022-10-29T06:44:33.000Z</published>
    <updated>2022-10-29T06:44:33.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="如何理解-gnn-表达能力的粗浅小结">如何理解 GNN 表达能力的粗浅小结</h1><blockquote><p>参考阅读：</p><ol type="1"><li><a href="https://graph-neural-networks.github.io/gnnbook_Chapter5.html">Chapter5: The Expressive Power of Graph Neural Networks</a></li><li><a href="https://www.163.com/dy/article/FG0J275N0511DPVD.html">中科院计算所沈华伟：图神经网络表达能力的回顾和前沿</a></li><li><a href="https://zhuanlan.zhihu.com/p/369869891">【ICLR2021论文解读】初探 GNN 表达能力</a></li><li><a href="https://openreview.net/forum?id=-qh0M9XWxnv">Analyzing the Expressive Power of Graph Neural Networks in a Spectral Perspective</a></li><li><a href="https://www.cnblogs.com/hilbert9221/p/14443747.html">图神经网络的表达能力与置换同变性</a></li></ol></blockquote><span id="more"></span><h2 id="神经网络的表达能力">1. 神经网络的表达能力</h2><p>机器学习的任务，可以理解为存在一个从特征空间到目标空间的映射<span class="math inline">\(f^*\)</span>，希望能用模型 <span class="math inline">\(f_\theta\)</span> 来近似<span class="math inline">\(f^*\)</span> 。可将 <span class="math inline">\(f_\theta\)</span> 能近似的<strong>映射范围</strong>理解为模型的表达能力。</p><p>先前研究已证明了定义任意定义在compact space上的连续函数都可被<strong>MLP</strong>近似。但其实，一方面并不能保证<strong>模型经训练所学的<span class="math inline">\(\hat{f}\)</span> 是想近似的<span class="math inline">\(f^*\)</span></strong>，另一方面过强的表达能力还可能导致overfitting。</p><figure><img src="./image-20221024121136460.png" alt="image-20221024121136460" /><figcaption aria-hidden="true">image-20221024121136460</figcaption></figure><p>因此，我们希望建立能够保持强大表达能力的NN，同时对其参数施加约束——归纳偏置反映着对问题的先验认知。</p><p>对于CNN/RNN，模型共享参数的机制隐含着translation invariance的假设，对模型的表达力进行限制，但已经能完成对应任务<strong>(limited but sufficient)</strong>。</p><figure><img src="./image-20221024153918940.png" alt="image-20221024153918940" /><figcaption aria-hidden="true">image-20221024153918940</figcaption></figure><p>对于GNN，则有如下图所示的permutation invariance限定。</p><figure><img src="./image-20221024154514368.png" alt="image-20221024154514368" /><figcaption aria-hidden="true">image-20221024154514368</figcaption></figure><h2 id="gnn表达能力的不同视角">2. GNN表达能力的不同视角</h2><ol type="1"><li><p><strong>区分能力(separating power)/相似性度量</strong>：</p><p>经典工作为 <em>How Powerful are Graph Neural Networks？</em>，它使用的<strong>图同构检验graph isomorphism problem</strong>来衡量GNN表达能力。表达力强的GNN能学到分辨性强的graph embedding，让我们<strong>在隐空间中判定两个图是否同构</strong>。</p><p>进一步的，还可尝试探索GNN是否能处理更难的 <strong>图编辑距离graph edit distance problem</strong>。</p></li><li><p><strong>逼近能力(approximation power)</strong>：</p><p>基于<strong>函数逼近</strong>思路，关心神经网络能够<strong>表达的函数的范围有多大</strong>，工作举例有<em>EXPRESSIVE POWER OF INVARIANT AND EQUIVARIANT GRAPH NEURAL NETWORKS</em>。尝试证明GNN可以逼近的定义在图上的映射集合。</p></li><li><p><strong>模式识别</strong>：</p><p>通过研究GNN是否能识别图中的特定结构，把模式识别能力视作GNN的表达能力，工作举例有<em>Can graph neural networks count substructures?</em>。</p></li></ol><h2 id="提升表达力方式wl-test视角">3. 提升表达力方式（WL-test视角）</h2><p><a href="https://graph-neural-networks.github.io/gnnbook_Chapter5.html">Chapter5: The Expressive Power of Graph Neural Networks</a>的5.4章给出了具体介绍，在此不赘述。</p><figure><img src="./image-20221024162739401.png" alt="image-20221024162739401" /><figcaption aria-hidden="true">image-20221024162739401</figcaption></figure><hr /><p>上述观察，主要都聚焦在graph-level研究GNN表达能力，而缺乏从node-level出发的表达能力讨论。</p><p>一说对于node-level任务，GNN已经是universal approximator，不必深入研究。（参考阅读2）</p><figure><img src="./image-20221024185051603.png" alt="image-20221024185051603" /><figcaption aria-hidden="true">image-20221024185051603</figcaption></figure><p>但另一方面，一直以来关于GNN架构的研究，除了提升其表达能力外，也在努力提升其拟合能力——使模型能从有限的训练数据中尽可能拟合ground truth映射函数<span class="math inline">\(f^*\)</span>。</p><figure><img src="./image-20221024185802289.png" alt="image-20221024185802289" /><figcaption aria-hidden="true">image-20221024185802289</figcaption></figure><p>或许可理论层面分析node-level层面GNN的表达能力、泛化能力（待阅读<a href="https://openreview.net/pdf?id=UH-cmocLJC">How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks. Keyulu Xu et al. ICLR 2021.</a>、<a href="https://openreview.net/pdf?id=rJxbJeHFPS">What Can Neural Networks Reason About? Keyulu X et al. ICLR2020</a>）；</p><p>也可能参考上述他人证明，指导设计 theortical proven node-level specific GNN。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;如何理解-gnn-表达能力的粗浅小结&quot;&gt;如何理解 GNN 表达能力的粗浅小结&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;参考阅读：&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;a href=&quot;https://graph-neural-networks.github.io/gnnbook_Chapter5.html&quot;&gt;Chapter5: The Expressive Power of Graph Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.163.com/dy/article/FG0J275N0511DPVD.html&quot;&gt;中科院计算所沈华伟：图神经网络表达能力的回顾和前沿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/369869891&quot;&gt;【ICLR2021论文解读】初探 GNN 表达能力&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://openreview.net/forum?id=-qh0M9XWxnv&quot;&gt;Analyzing the Expressive Power of Graph Neural Networks in a Spectral Perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/hilbert9221/p/14443747.html&quot;&gt;图神经网络的表达能力与置换同变性&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="ML知识总结" scheme="http://example.com/categories/ML%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="图神经网络" scheme="http://example.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    <category term="图表示学习" scheme="http://example.com/tags/%E5%9B%BE%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>MSL_20_蹒跚科研小记</title>
    <link href="http://example.com/2022/10/15/MSL-20-%E8%B9%92%E8%B7%9A%E7%A7%91%E7%A0%94%E5%B0%8F%E8%AE%B0/"/>
    <id>http://example.com/2022/10/15/MSL-20-%E8%B9%92%E8%B7%9A%E7%A7%91%E7%A0%94%E5%B0%8F%E8%AE%B0/</id>
    <published>2022-10-15T08:26:32.000Z</published>
    <updated>2022-10-15T08:26:32.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Oct.14, 2022，再怎样不满意工作也好，终究是把自己的论文投了出去，为蹒跚的科研立下一个小里程碑。</p></blockquote><p>无论结果好坏，且将若干总结记录于此。</p><span id="more"></span><ul><li><p><strong>持续输入——哪怕idea定型</strong></p><p>把读论文变作习惯，把了解最新工作看作每日读报一样的消遣。</p><p>要保证持续的输入，跟进最新的工作。不只是研究选题时的广泛阅读，而是哪怕在idea定型，专心做实验时，依旧需要保持输入。他人的成果或能带来对个人研究方向的新视角，或提供更新的理论佐证等。闭门造车不可取，不知不觉就走入岔路落后他人了。</p></li><li><p><strong>活用工具，管理进度</strong></p><p>课题做了一年多，从新颖拖到平庸，自我的不断拖延虽是核心原因，但仍有不少工具能助我提振精神，管理进度。</p><p>一如这一个月来使用的任务看板<em>Trello</em></p><p><img src="./trello.png" /></p><p>借助看板，排好工作档期，依照重要性逐次按时攻破任务。每次将任务从“进行中”挪至“完成”时，都可享受自造的成就感。</p></li><li><p><strong>任何结论，想多一步</strong></p><p><strong>我们写的论文不是说明书，而重在议论</strong>。</p><p>论文不是简单罗列做了什么，而是完整地论述为何要做，怎样去做，解决了什么问题。</p><p>议论从何来，便是得到任何实验结果，推导出任何结论，都想多一步——为什么。</p></li><li><p><strong>推敲与交流并行</strong></p><p>科研不必做孤胆英雄，与其他方向友人交流或许有更多灵光乍现的时刻。</p></li><li><p><strong>平和心态——过程奋进，悦纳结果</strong></p><p>不及预期也罢，但求过程无悔。画上句点后，尊重自己的劳动成果，投身下一段研究中去吧。</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Oct.14, 2022，再怎样不满意工作也好，终究是把自己的论文投了出去，为蹒跚的科研立下一个小里程碑。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;无论结果好坏，且将若干总结记录于此。&lt;/p&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="科研心声" scheme="http://example.com/tags/%E7%A7%91%E7%A0%94%E5%BF%83%E5%A3%B0/"/>
    
  </entry>
  
  <entry>
    <title>MSL_19_Why Decentralization Matters笔记</title>
    <link href="http://example.com/2022/10/14/MSL-19-WhyDecentralizationMatters%E7%AC%94%E8%AE%B0/"/>
    <id>http://example.com/2022/10/14/MSL-19-WhyDecentralizationMatters%E7%AC%94%E8%AE%B0/</id>
    <published>2022-10-14T02:48:32.000Z</published>
    <updated>2022-10-14T17:08:34.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Ref:</p><p>原始blog 👉 <a href="https://cdixon.org/2018/02/18/why-decentralization-matters">here</a></p><p>zhihu笔记 👉 <a href="https://zhuanlan.zhihu.com/p/572235146">here</a></p></blockquote><span id="more"></span><p><img src="./Whydecentralizationmatters.png" /></p><blockquote><p>Instead of placing our trust in corporations, we can place our trust in community-owned and -operated software, transforming the internet’s governing principle from “don’t be evil” back to <strong>“can’t be evil.”</strong></p></blockquote><p>仅从此篇blog来看，以去中心化概念为核心的web 3.0 时代仅有淳朴的愿景。期待由于网络基础架构的改变，支持去中心化的网络发展后，人类组织合作方式能随之<strong>演进到community-govern的共治模式</strong>。基于web 3.0里的tokens激励机制，能让参与者劳有所得，从机制上实现<strong>公平的按劳分配</strong>。</p><p>从愿景而言让人向往，但其实现方式仍需继续了解。此外，如何顺利接轨现有社会体系，而非技术理论上的空想，也待分析。</p><hr /><p>放下对元宇宙，比特币的成见，了解下Internet可能的未来。</p><p>去中心化，朴素自治的未来有何技术基础支持？web 3.0到底在讨论怎样的Internet？便从此刻开始去了解，准备吧。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;p&gt;原始blog 👉 &lt;a href=&quot;https://cdixon.org/2018/02/18/why-decentralization-matters&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;zhihu笔记 👉 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/572235146&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="生活" scheme="http://example.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>Torch_Einsum入门</title>
    <link href="http://example.com/2022/09/19/Torch-Einsum%E5%85%A5%E9%97%A8/"/>
    <id>http://example.com/2022/09/19/Torch-Einsum%E5%85%A5%E9%97%A8/</id>
    <published>2022-09-19T13:42:11.000Z</published>
    <updated>2022-09-19T13:42:11.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>看代码遇到了精妙的<strong>爱因斯坦求和约定（einsum）</strong>，并在zhihu上发现了生动的讲解。简要拆解内容为知识导图做备份。 原文地址👉<a href="https://zhuanlan.zhihu.com/p/361209187">戳这里</a></p></blockquote><span id="more"></span><p>（原文还有结合代码的例子讲解哦！）</p><figure><img src="./einsum.png" alt="mindmap" /><figcaption aria-hidden="true">mindmap</figcaption></figure>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;看代码遇到了精妙的&lt;strong&gt;爱因斯坦求和约定（einsum）&lt;/strong&gt;，并在zhihu上发现了生动的讲解。简要拆解内容为知识导图做备份。 原文地址👉&lt;a href=&quot;https://zhuanlan.zhihu.com/p/361209187&quot;&gt;戳这里&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="工具人" scheme="http://example.com/categories/%E5%B7%A5%E5%85%B7%E4%BA%BA/"/>
    
    
    <category term="Pytorch" scheme="http://example.com/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Crawler_Elsevier Abstract爬取</title>
    <link href="http://example.com/2022/09/07/Crawler-Elsevier-Abstract%E7%88%AC%E5%8F%96/"/>
    <id>http://example.com/2022/09/07/Crawler-Elsevier-Abstract%E7%88%AC%E5%8F%96/</id>
    <published>2022-09-07T15:57:50.000Z</published>
    <updated>2022-09-08T01:53:40.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>机缘巧合，需要帮朋友爬取些论文摘要。遂将任务探索过程及解决方案记录如下。</p><p>初次接触Requests，代码较为稚嫩，多多包涵。</p></blockquote><span id="more"></span><h1 id="需求描述">1. 需求描述</h1><p>在<strong>Elsevier</strong>数据库中，给定<strong>查询条件</strong>（如，搜索“题目、摘要、关键词中包含<code>Target</code>的论文”），检索论文，并存取论文标题及<strong>摘要</strong>。</p><h1 id="解决方案">2. 解决方案</h1><h2 id="前期准备">2.1 前期准备</h2><ul><li><p>python环境</p></li><li><p>创建个人API-Key <a href="https://dev.elsevier.com/apikey/manage">link</a></p><figure><img src="./image-20220908003127528.png" alt="image-20220908003127528" /><figcaption aria-hidden="true">image-20220908003127528</figcaption></figure></li><li><p>下载<em>Elsapy</em> 源码 <a href="https://github.com/ElsevierDev/elsapy">Github</a></p><figure><img src="./image-20220908003348189.png" alt="image-20220908003348189" /><figcaption aria-hidden="true">image-20220908003348189</figcaption></figure></li></ul><h2 id="摘要相关api一览">2.2 摘要相关API一览</h2><blockquote><p>注：<em>Elsapy</em>封装了对相关api的request（虽然要魔改下）。</p></blockquote><ul><li><p><a href="https://dev.elsevier.com/documentation/ScopusSearchAPI.wadl">Scopus Search API</a></p><p>通过向此API发起请求，我们能得到<em>Scopus</em>数据库中符合检索条件的摘要的<strong>URL</strong>。</p><figure><img src="./image-20220908003940929.png" alt="image-20220908003940929" /><figcaption aria-hidden="true">image-20220908003940929</figcaption></figure><p>后续<em>Elsapy</em>将此<strong>query</strong>参数进行了封装。</p><figure><img src="./image-20220908004250354.png" alt="image-20220908004250354" /><figcaption aria-hidden="true">image-20220908004250354</figcaption></figure><p>API 返回结果的文档在此： <a href="https://dev.elsevier.com/guides/ScopusSearchViews.htm">Scopus Search Views</a></p><p>可惜不够尊贵，个人版的返回json中不包括abstract</p><figure><img src="./image-20220908005338776.png" alt="image-20220908005338776" /><figcaption aria-hidden="true">image-20220908005338776</figcaption></figure><p>实际返回项如下图：</p><p><img src="./image-20220908005405331.png" alt="image-20220908005405331" style="zoom:67%;" /></p><p>故我们需要使用<strong>prism:url</strong>进行abstract的提取。</p><p><img src="./image-20220908005443232.png" alt="image-20220908005443232" style="zoom:67%;" /></p></li><li><p><a href="https://dev.elsevier.com/documentation/AbstractRetrievalAPI.wadl">Abstract Retrieval API</a></p><p>用上述的<strong>prism:url</strong>做参数，调用Abstract Retrieval API就可以得到目标文章的摘要信息了。</p><figure><img src="./image-20220908005754680.png" alt="image-20220908005754680" /><figcaption aria-hidden="true">image-20220908005754680</figcaption></figure><p>返回的<a href="https://dev.elsevier.com/guides/AbstractRetrievalViews.htm">Abstract Retrieval Views</a>.链接在此，其中的<strong>dc:description</strong>即为我们所需的摘要，<strong>dc:title</strong>为标题。</p></li></ul><h2 id="elsapy-开发">2.3 Elsapy 开发</h2><p><em>Elsapy</em>使用<em>Requests</em>，封装了对Elsevier各个api访问的类及方法。不过其在Exception handling等方面很不完善。好在其本身代码简单，结构清晰，个人便对其做简单的定制。</p><ul><li><p>基本使用</p><ol type="1"><li><p>提供API-Key构建<code>ElsClient</code>对象，该对象负责向Elsevier发起请求；</p></li><li><p>再根据需求构建想访问的API的对象，如<code>ElsSearch</code>；</p></li><li><p>调用API对象的方法，进行访问。</p></li></ol><p>示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> elsapy.elsclient <span class="keyword">import</span> ElsClient</span><br><span class="line"><span class="keyword">from</span> elsapy.elssearch <span class="keyword">import</span> ElsSearch</span><br><span class="line"><span class="keyword">import</span> time </span><br><span class="line"></span><br><span class="line">query_str = <span class="string">&quot;your_query&quot;</span></span><br><span class="line">user_key = <span class="string">&#x27;your_key&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    client = ElsClient(user_key)</span><br><span class="line">    doc_src = ElsSearch(query_str, <span class="string">&#x27;scopus&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; Start crawling.\t Time: &quot;</span> + time.asctime())</span><br><span class="line">    doc_src.custom_execute(client, get_num=<span class="number">20000</span>, save_json=query_str+<span class="string">&quot;.json&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>改动</p><p>原本的<code>ElsSearch.execute</code>缺少异常处理，致使爬取中断。此外，我希望能指定爬取文章的数量，以及存储json的文件名。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">custom_execute</span>(<span class="params">self, els_client = <span class="literal">None</span>, get_num = <span class="literal">None</span>, get_all = <span class="literal">False</span>, save_json=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Executes the search. If get_all = False (default), this retrieves</span></span><br><span class="line"><span class="string">        the default number of results specified for the API. If</span></span><br><span class="line"><span class="string">        get_all = True, multiple API calls will be made to iteratively get </span></span><br><span class="line"><span class="string">        all results for the search, up to a maximum of 5,000.&quot;&quot;&quot;</span></span><br><span class="line">    api_response = els_client.exec_request(self._uri)</span><br><span class="line">    self._tot_num_res = <span class="built_in">int</span>(api_response[<span class="string">&#x27;search-results&#x27;</span>][<span class="string">&#x27;opensearch:totalResults&#x27;</span>])</span><br><span class="line">    self._results = api_response[<span class="string">&#x27;search-results&#x27;</span>][<span class="string">&#x27;entry&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> get_all <span class="keyword">is</span> <span class="literal">True</span> <span class="keyword">or</span> get_num <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> get_num <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:     </span><br><span class="line">            quota = get_num <span class="keyword">if</span> get_num &lt; self._tot_num_res <span class="keyword">else</span> self._tot_num_res</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            quota = self._tot_num_res</span><br><span class="line">  </span><br><span class="line">        failed_flag = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">while</span> self.num_res &lt; quota <span class="keyword">and</span> <span class="keyword">not</span> failed_flag:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&gt; Executing &#123;cur&#125; | &#123;total&#125;&quot;</span>.<span class="built_in">format</span>(cur = self.num_res, total = quota))</span><br><span class="line">            <span class="keyword">for</span> e <span class="keyword">in</span> api_response[<span class="string">&#x27;search-results&#x27;</span>][<span class="string">&#x27;link&#x27;</span>]:</span><br><span class="line">                <span class="keyword">if</span> e[<span class="string">&#x27;@ref&#x27;</span>] == <span class="string">&#x27;next&#x27;</span>:</span><br><span class="line">                    next_url = e[<span class="string">&#x27;@href&#x27;</span>]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>): <span class="comment"># if failed, retry up to 5 times</span></span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    api_response = els_client.exec_request(next_url)</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">except</span> RequestException <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="built_in">print</span>(e)</span><br><span class="line">                    <span class="keyword">if</span> i &lt; <span class="number">4</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; retry: &#123;t&#125; times&quot;</span>.<span class="built_in">format</span>(t= i + <span class="number">1</span>))</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; TASK FAILED. Save current results.&quot;</span>)</span><br><span class="line">                        failed_flag = <span class="literal">True</span></span><br><span class="line">  </span><br><span class="line">            self._results += api_response[<span class="string">&#x27;search-results&#x27;</span>][<span class="string">&#x27;entry&#x27;</span>]</span><br><span class="line">    name = save_json <span class="keyword">if</span> save_json <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="string">&#x27;dump.json&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(name, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(json.dumps(self._results))</span><br><span class="line">    self.results_df = recast_df(pd.DataFrame(self._results))</span><br></pre></td></tr></table></figure><p>此外，实际爬取过程中遇到 <code>ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接</code>问题。尽管原<code>ElsClient</code>已经按照Elsevier限定的每秒1次访问设定了interval，我仍在此基础上增加0.5s间隔，从而解决上述问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">time.sleep( self.__min_req_interval - interval + <span class="number">0.5</span> ) <span class="comment"># sleep 0.5 more second</span></span><br></pre></td></tr></table></figure><h2 id="完整代码">2.4 完整代码</h2></li><li><p>Scopus search</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> elsapy.elsclient <span class="keyword">import</span> ElsClient</span><br><span class="line"><span class="keyword">from</span> elsapy.elssearch <span class="keyword">import</span> ElsSearch</span><br><span class="line"><span class="keyword">import</span> time </span><br><span class="line"></span><br><span class="line">query_str = <span class="string">&quot;YOUR_QUERY&quot;</span></span><br><span class="line">user_key = <span class="string">&#x27;YOUR_KEY&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    client = ElsClient(user_key)</span><br><span class="line">    doc_src = ElsSearch(query_str, <span class="string">&#x27;scopus&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; Start crawling.\t Time: &quot;</span> + time.asctime())</span><br><span class="line">    doc_src.custom_execute(client, get_num=<span class="number">20000</span>, save_json=query_str+<span class="string">&quot;.json&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>Abstract retrieval</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> elsapy.elsclient <span class="keyword">import</span> ElsClient</span><br><span class="line"><span class="keyword">from</span> elsapy.elsdoc <span class="keyword">import</span> AbsDoc</span><br><span class="line"></span><br><span class="line">abs_field = <span class="string">&#x27;dc:description&#x27;</span></span><br><span class="line">title_field = <span class="string">&#x27;dc:title&#x27;</span></span><br><span class="line">publication_field = <span class="string">&#x27;prism:publicationName&#x27;</span></span><br><span class="line"></span><br><span class="line">user_key = <span class="string">&#x27;YOUR_KEY&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_json2pd</span>(<span class="params">file</span>):</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        data = json.load(f)</span><br><span class="line">    <span class="keyword">return</span> pd.json_normalize(data)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crawl_abstracts</span>(<span class="params">df, client</span>):</span></span><br><span class="line">    failed_list = []</span><br><span class="line">    abstracts = []</span><br><span class="line">    titles = []</span><br><span class="line">    publications = []</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; Start crawling.\t Time: &quot;</span> + time.asctime())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, url <span class="keyword">in</span> <span class="built_in">enumerate</span>(df[<span class="string">&#x27;prism:url&#x27;</span>]):</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&gt; Parsing &#123;cur&#125; / &#123;total&#125;&quot;</span>.<span class="built_in">format</span>(cur = i + <span class="number">1</span>, total = <span class="built_in">len</span>(df[<span class="string">&#x27;prism:url&#x27;</span>])))</span><br><span class="line">        abs_doc = AbsDoc(url)</span><br><span class="line">        rst = abs_doc.read(client)</span><br><span class="line">        <span class="keyword">if</span> rst:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                abstracts.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][abs_field])</span><br><span class="line">                titles.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][title_field])</span><br><span class="line">                publications.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][publication_field])</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&gt; &#123;cur&#125; - th failed.&quot;</span>.<span class="built_in">format</span>(cur = i + <span class="number">1</span>))</span><br><span class="line">            failed_list.append(url)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(failed_list) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&gt; Retry failed url...&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> failed_list:</span><br><span class="line">            abs_doc = AbsDoc(url)</span><br><span class="line">            <span class="keyword">if</span> abs_doc.read(client):</span><br><span class="line">                <span class="keyword">try</span>: </span><br><span class="line">                    abstracts.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][abs_field])</span><br><span class="line">                    titles.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][title_field])</span><br><span class="line">                    publications.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][publication_field])</span><br><span class="line">                <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Completed. Total crawled abstracts: &quot;</span>, <span class="built_in">len</span>(abstracts))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> titles, abstracts, publications</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    client = ElsClient(user_key)</span><br><span class="line">    json_file = <span class="string">&#x27;TITLE-ABS-KEY(inorganic compounds).json&#x27;</span></span><br><span class="line">    csv_path = json_file[:-<span class="number">5</span>] + <span class="string">&#x27;_2&#x27;</span> + <span class="string">&#x27;.csv&#x27;</span></span><br><span class="line"></span><br><span class="line">    df = load_json2pd(json_file)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 一点点来爬</span></span><br><span class="line">    cut_l, cut_r = <span class="number">1000</span>, <span class="number">5000</span></span><br><span class="line"></span><br><span class="line">    titles, abstracts, publications = crawl_abstracts(df[cut_l:cut_r], client) </span><br><span class="line">    abs_df = pd.concat([pd.DataFrame(titles),</span><br><span class="line">                        pd.DataFrame(abstracts),</span><br><span class="line">                        pd.DataFrame(publications)],</span><br><span class="line">                        axis=<span class="number">1</span>)</span><br><span class="line">    abs_df.to_csv(csv_path, header=<span class="literal">False</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h1 id="相关资料">3. 相关资料</h1><p>除上文中包含的链接外，</p><ul><li><p><a href="https://dev.elsevier.com/sc_search_tips.html">Scopus Search Guide</a></p><p>介绍所支持<strong>Query</strong>的关键词，表达式（基本上用户进行advanced search时的条件都可以实现）；</p></li><li><p><a href="https://dev.elsevier.com/api_key_settings.html">How much data can I retrieve with my APIKey?</a></p><p><img src="./image-20220908100750603.png" alt="image-20220908100750603" style="zoom:50%;" /></p></li><li><p><a href="https://dev.elsevier.com/support.html">Frequently Asked Questions</a></p><figure><img src="./image-20220908100837747.png" alt="image-20220908100837747" /><figcaption aria-hidden="true">image-20220908100837747</figcaption></figure></li></ul><h1 id="可优化点">4. 可优化点</h1><ul><li><p>多线程爬取</p><p>现在受制于Elsevier限制，每秒只能发送1次请求，导致爬虫龟速。或可申请多个API-Key，进行多线程爬取。</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;机缘巧合，需要帮朋友爬取些论文摘要。遂将任务探索过程及解决方案记录如下。&lt;/p&gt;
&lt;p&gt;初次接触Requests，代码较为稚嫩，多多包涵。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="工具人" scheme="http://example.com/categories/%E5%B7%A5%E5%85%B7%E4%BA%BA/"/>
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>MSL-18-声生不息</title>
    <link href="http://example.com/2022/07/10/MSL-18-%E5%A3%B0%E7%94%9F%E4%B8%8D%E6%81%AF/"/>
    <id>http://example.com/2022/07/10/MSL-18-%E5%A3%B0%E7%94%9F%E4%B8%8D%E6%81%AF/</id>
    <published>2022-07-10T15:56:29.000Z</published>
    <updated>2022-07-10T17:56:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>《声生不息》落下帷幕，第一次追完了一档芒果台综艺，此刻，应该记录下什么，评述些什么？</p><span id="more"></span><h2 id="听歌">听歌？</h2><p>发掘新歌手、听喜爱的歌者演绎旧曲当是置于首位的乐趣。</p><p>香港新生代Mike同Gigi，此前只略有耳闻，欣赏他们演绎后，被彻底征服；Hacken、千嬅的歌一直在我的歌单里，此回也算是追星成功；不曾想还能见到真声大魔王般的林子祥老师录制节目。</p><p>一个季度地录制，给予观众充分的时间了解各位歌手。仍记得初听第一期节目时，吐槽魔动闪霸等——不知道哪里抓出来的喽啰。现今，已发现他们各自的可爱之处、音乐上的造诣。</p><p>虽然一些曲目改编得过于华丽而失其本韵，仍有不少舞美与歌唱俱佳的作品产出。不是我过往随笔的风格，掉书袋一样进行罗列。不过随笔就该随心所欲吧，还是列一下印象中喜爱的舞台吧。</p><ul><li>《单车》 父子，车站，不知将远行或是总算相逢。结合Mike身世，不由就想起日常父子默然对视，心中思绪翻涌，却总是无言；</li><li>《红绿灯》大约总有个人，会隔着红绿灯的距离，待到绿灯亮起时，只能夹于人潮中在斑马线上擦身而过吧；</li><li>《灰姑娘》Mike唱出了浮夸的感觉；</li><li>《高山低谷》《勇》撇开情爱的纷纷扰扰，品味生活的五味吧。</li></ul><h2 id="小遗憾">小遗憾？</h2><p>广东歌这么多年，又怎能是一季节目，十几位歌手能回顾完的呢？</p><p>只是，陈胖子你的歌基本集集都被唱，人却一集都不来算什么。一边哭穷一边不出来营业也不发歌，上一首歌还是变成儿歌的《孤勇者》😢；Joey在内地却在另一个台陪着那些只知口水半吊子的假粤语歌《大风吹》的网红们又是什么情况🤦‍♂️；古Sir和Hins怕是和TVB关系不好也来不到现场？</p><p>虽然新歌实在太少，但选歌属于是众口难调，不必多言。</p><p>政治原因，两伟文，林夕千首填词的曲直接石沉海底，黄伟文填词的歌被翻唱，本人却不得出现在背景介绍中。不能说政治绝对凌驾于艺术，只是涉及民族、家国底线的原则，在公众传媒上不能含糊。</p><p>幸运的是仍能欣赏二位的作品，也愿家国能更自由、包容吧。</p><h2 id="生生不息">生生不息？</h2><p>要正视粤语的地位和历史。</p><p>靠着地理位置的优势，广东、港澳的经济才得以在近代腾飞；而由于中英的历史问题，香港特立独行地走了很长一段路。</p><p>粤语得以从一众方言中脱颖而出，在近代得到更多的发展和曝光。广东歌，更随着HK八九十年代特殊的经济地位，短暂披上黄金时代的外衣。</p><p>而今，该老实承认广东歌不再与繁华挂钩，慢慢成为音乐类别里一小小的按钮才是。</p><p>或许未来，是“不生不死”的。难再有过往那般火热的消费者市场，其能吸纳、养活的音乐人便有限。小众门类里，不离不弃的粤语爱好者们亦不会离去。</p><blockquote><p>香港歌手不會死</p><p>怎麼尖酸的你　那樣看不起</p><p>漠視　挖苦　比較</p><p>恥笑　指責　拋棄這一代</p><p>我請你不必再比</p><p>贈你這卡式機　聽返你舊時多優美</p></blockquote><hr /><p>有趣的是，周末来到武汉的猫咖，老板一直放着声生不息的歌单，吵着不让我午睡——听到就忍不住跟着哼唱。在武汉咖啡馆里听广东歌，一听一下午，巴适。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;《声生不息》落下帷幕，第一次追完了一档芒果台综艺，此刻，应该记录下什么，评述些什么？&lt;/p&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
  </entry>
  
  <entry>
    <title>MSL-17-多安的岛</title>
    <link href="http://example.com/2022/06/22/MSL-17-%E5%A4%9A%E5%AE%89%E7%9A%84%E5%B2%9B/"/>
    <id>http://example.com/2022/06/22/MSL-17-%E5%A4%9A%E5%AE%89%E7%9A%84%E5%B2%9B/</id>
    <published>2022-06-22T03:43:51.000Z</published>
    <updated>2022-06-22T03:43:51.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>孤岛生存，非桃花源，而是片刻的幻梦。抛开高达繁重的设定、历史，不失为佳作。</p></blockquote><hr /><p>久违了啊，高达的新剧场版。</p><span id="more"></span><p><img src="./image-20220622113823158.png" alt="image-20220622113823158" style="zoom:33%;" /></p><p>历史的脚注总是简短而片面。哪怕留名者，大多也就寥寥数句记录其官衔军功。其人真实的生命历程，种种细节不可追。借助段段OVA或剧场版展开，延申多些许人物的弧光，实是幸事。</p><p>看到本片里坚毅的塞拉，不由忆起《GTO》中她幼年时所一路闯过的磨难；留下“北宋的壶，这可是好东西啊”名梗的马·克贝上校，除善谋权术数，亦是真切地心系地球文化——作战失败时的大笑怕是一种释怀吧。</p><p><img src="./image-20220622012934111.png" alt="image-20220622012934111" style="zoom: 33%;" /></p><p>以及，库库鲁斯·多安。</p><p>哪怕是没看过0079的人，但凡接触过高达相关的游戏，都会记得有个格斗专精、会扔石头的扎古Ⅱ，往往戏称驾驶员为石头哥，却不知其人经历。得以此番，略睹多安的人生碎片。</p><p>小队内战的片段，虽然久违的机战动作镜头激起多巴胺的刺激，反倒最令人感到沉重。多安是谁，追溯他过往MS出击的履历，是技术高超乃至坊间评价堪比“赤色彗星”的ACE，却也是驾驶扎古试图逃离战场的人。于是，来袭的原小队里，有视其为叛徒，咬牙切齿要歼灭多安的递补队长；有慕名而来的挑战者；还有暗生情愫却未能理解多安远走缘由的队员。所驾驶的绿扎已然破旧，却仍无言挥舞仅剩的热能斧，击破来者。</p><p><img src="./image-20220622111003227.png" alt="image-20220622111003227" style="zoom:33%;" /></p><p>斩杀的可是曾经的战友——一同出生入死，将后背交由其保护的战友。他会在想些什么？兵戎相见、刀剑相交之间，没留下互述苦衷的时空。捍卫这弹丸小岛，保护孩子们以赎罪，是多安唯一踏入驾驶舱的理由了吧。多安或许会选择什么都不再想了吧。从战场脱逃的战争机器，只会延续机械的迎战。</p><p>阿姆罗最后毁掉多安的扎古，算是将多安从杀人机器中解脱出来。</p><p><img src="./image-20220622113008083.png" alt="image-20220622113008083" style="zoom:33%;" /></p><p>算是happy ending了吧，核弹被摧毁，小岛彻底失去战略价值，多安岛的和平能延续多些时日。</p><p>但转念又觉得唏嘘，联邦的“白色恶魔”阿姆罗，往后宿命仍与战争绑定，直到推着阿克西斯消失在银河彼端的那天。</p><hr /><p>专属于高达的槽点不少：</p><ul><li><p>财团为了卖模型不择手段啊，强行插入10秒高机动型红扎广告片段；</p><p><img src="./image-20220622113922357.png" alt="image-20220622113922357" style="zoom:25%;" /></p></li><li><p>重制“我爸爸也没有打过我”，好评；</p><p><img src="./image-20220622114220005.png" alt="image-20220622114220005" style="zoom:25%;" /></p></li><li><p>阿姆罗不愧白色恶魔，上来就捅驾驶舱，从不手软。</p><p><img src="胡扯.assets/image-20220622114048397.png" alt="image-20220622114048397" style="zoom:25%;" /></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;孤岛生存，非桃花源，而是片刻的幻梦。抛开高达繁重的设定、历史，不失为佳作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;p&gt;久违了啊，高达的新剧场版。&lt;/p&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
  </entry>
  
  <entry>
    <title>BOOK-08-蛤蟆先生去看心理医生</title>
    <link href="http://example.com/2022/06/09/BOOK-08-%E8%9B%A4%E8%9F%86%E5%85%88%E7%94%9F%E5%8E%BB%E7%9C%8B%E5%BF%83%E7%90%86%E5%8C%BB%E7%94%9F/"/>
    <id>http://example.com/2022/06/09/BOOK-08-%E8%9B%A4%E8%9F%86%E5%85%88%E7%94%9F%E5%8E%BB%E7%9C%8B%E5%BF%83%E7%90%86%E5%8C%BB%E7%94%9F/</id>
    <published>2022-06-09T03:43:52.000Z</published>
    <updated>2022-06-09T03:43:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>把问题留在这里，时时回顾思索吧。</p><span id="more"></span><blockquote><ul><li>“心理咨询向来是一个自发的过程，咨询师和来访者双方都得出于自愿。所以这就意味着，只有当你是为自己而不是为取悦朋友们才想咨询的时候，我们才能真正合作。</li><li>如果你要更好地理解自己，就需要跟自己的情绪做联结，并理解这些情绪。如果你否认它们，不论是用无视还是压抑的方式，结果都像是做了截肢，就如身体的重要部位被切掉了一样，你在某种程度上成了一个残缺的人。</li><li>能帮你的人是你自己，也只有你自己。有许多问题需要你向自己发问。比如你能停止自我批判吗？你能对自己好一些吗？也许最重要的问题是，你能开始爱自己吗？</li><li>如果你为自己负责，就会认识到你对自己是有自主权的。因此你就知道自己有力量来改变处境，更重要的是，有力量改变你自己。</li><li>第一个问题是 我是怎么看自己的？我好吗？第二个问题是：我是怎么看别人的？他们好吗？</li><li>一旦我们在童年决定用哪种态度和观点，我们就会在随后的人生里始终坚持自己的选择。这些态度和观点，变成我们存在的底层架构。从那以后，我们便建构出一个世界，不断确认和支持这些信念和个预期。换一个词来说，我们把自己的人生变成了一个’自证预言'。</li><li>有些人会竭尽所能地选择记住那些悲伤和不快乐的事件，而忘记或忽略美好的时光。这种活法看起来很容易让人抑郁。</li><li>我觉得我比过去更能顺应生活了。可我不会忘记自己曾经是那么消沉，那段记忆会永远留在那儿，或许就是对我的提醒，告诉我，<strong>滑落到生活边缘的人生</strong>是什么样的。</li><li>人们太容易让重要的事件就这么过去，忘记关注或为它们庆祝，也许是因为我们通常都只在事后才明白它们有多重要。</li></ul></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;把问题留在这里，时时回顾思索吧。&lt;/p&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="书单" scheme="http://example.com/tags/%E4%B9%A6%E5%8D%95/"/>
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>GNN-GATv2</title>
    <link href="http://example.com/2022/05/20/GNN-GATv2/"/>
    <id>http://example.com/2022/05/20/GNN-GATv2/</id>
    <published>2022-05-20T06:44:17.000Z</published>
    <updated>2022-05-20T06:44:17.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="论文笔记how-attentive-are-graph-attention-networks">论文笔记：HOW ATTENTIVE ARE GRAPH ATTENTION NETWORKS?</h1><blockquote><p>PDF: https://openreview.net/pdf?id=F72ximsx7C1</p><p>OpenReview：https://openreview.net/forum?id=F72ximsx7C1</p><p>ICLR 2022</p></blockquote><h2 id="abstract">1. Abstract</h2><p>认为GAT是static attention，仅实现了对节点重要度的静态ranking，而未实现对不同query给出不同key的设想；提出GATv2，通过调整LeakyReLU和linear unit计算顺序，实现dynamic attention，即对不同query能给出不同key。</p><span id="more"></span><h2 id="motivations">2. Motivations</h2><p>GAT已成为图神经网络发展历程中的标志性架构，但本文观察发现，GAT的attention对于相同的keys实现的其实是ranking。</p><p>假设有如下二部图，求解 <em>Dictionary Lookup</em> 问题：</p><p><img src="./gatv2_01.png" style="zoom:67%;" /></p><p>使用GAT所得的attention scores如下：</p><p><img src="./gatv2_02.png" style="zoom:38%;" /></p><p>可以看到，对于不同的query，key的scores排序实际是一样的（<strong>静态</strong>的）。这限制了GAT的表达能力。</p><p>而本文认为，attention的初衷应该是：给定不同的query，能找到不同的key（即不同query，ranking结果应该不同，<strong>动态</strong>的）。</p><h2 id="method">3. Method</h2><h3 id="definitions">3.1 Definitions</h3><p>注意力机制其实是求解给定query时keys的注意力得分分布。</p><ul><li><p><strong>Static Attention</strong></p><p>设有计算注意力得分的函数族<span class="math inline">\(\mathcal{F}\)</span>, 对于任意 <span class="math inline">\(f \in \mathcal{F}\)</span>，给出 key <span class="math inline">\(\mathbb{K}=\left\{\boldsymbol{k}_{1}, \ldots, \boldsymbol{k}_{n}\right\} \subset \mathbb{R}^{d}\)</span> 和 query <span class="math inline">\(\mathbb{Q}=\left\{\boldsymbol{q}_{1}, \ldots, \boldsymbol{q}_{m}\right\} \subset \mathbb{R}^{d}\)</span>，若存在一个“得分最高”的 key <span class="math inline">\(k_{j_f}\)</span> 使得 <span class="math inline">\(f\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{j_{f}}\right) \geq f\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{j}\right)\)</span>，则称 <span class="math inline">\(\mathcal{F}\)</span> 为静态注意力；</p></li><li><p><strong>Dynamic Attention</strong></p><p>设有计算注意力得分的函数族<span class="math inline">\(\mathcal{F}\)</span>, <span class="math inline">\(f \in \mathcal{F}\)</span>，给出 key <span class="math inline">\(\mathbb{K}=\left\{\boldsymbol{k}_{1}, \ldots, \boldsymbol{k}_{n}\right\} \subset \mathbb{R}^{d}\)</span> 和 query <span class="math inline">\(\mathbb{Q}=\left\{\boldsymbol{q}_{1}, \ldots, \boldsymbol{q}_{m}\right\} \subset \mathbb{R}^{d}\)</span>，对于任意的映射 <span class="math inline">\(\varphi:[m] \rightarrow[n]\)</span>，存在 <span class="math inline">\(f \in \mathcal{F}\)</span>，使任意的 query 及任意的 key <span class="math inline">\(j_{\neq \varphi(i)} \in[n]\)</span>，有<span class="math inline">\(f\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{\varphi(i)}\right)&gt;f\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{j}\right)\)</span>，则称 <span class="math inline">\(\mathcal{F}\)</span> 为动态注意力。</p></li></ul><h2 id="gat有限的表达能力及修正">3.2 GAT有限的表达能力及修正</h2><ul><li><p><strong>GAT 分析</strong></p><p>首先回顾GAT中attention score计算方式，有： <span class="math display">\[e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j}\right)=\text { LeakyReLU }\left(\boldsymbol{a}^{\top} \cdot\left[\boldsymbol{W} \boldsymbol{h}_{i} \| \boldsymbol{W} \boldsymbol{h}_{j}\right]\right)\]</span></p><p><span class="math display">\[\alpha_{i j}=\operatorname{softmax}_{j}\left(e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j}\right)\right)=\frac{\exp \left(e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j}\right)\right)}{\sum_{j^{\prime} \in \mathcal{N}_{i}} \exp \left(e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j^{\prime}}\right)\right)}\]</span></p><p>对于式子(1)，我们令 <span class="math inline">\(\boldsymbol{a}=\left[\boldsymbol{a}_{1} \| \boldsymbol{a}_{2}\right] \in \mathbb{R}^{2 d^{\prime}}\)</span>，可得： <span class="math display">\[e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j}\right)=\text { LeakyReLU }\left(\boldsymbol{a}_{1}^{\top} \boldsymbol{W} \boldsymbol{h}_{i}+\boldsymbol{a}_{2}^{\top} \boldsymbol{W} \boldsymbol{h}_{j}\right)\]</span> 可以发现，对于有限的节点集合 <span class="math inline">\(\mathcal{V}\)</span>，存在一个节点 <span class="math inline">\(j_{max}\)</span>，使 <span class="math inline">\(\boldsymbol{a}_{2}^{\top} \boldsymbol{W} \boldsymbol{h}_{j_{max}}\)</span> 最大，即GAT计算的为 <em>static attention</em>。节点重要程度排序是确定的，和 query node 无关。Query node 只能影响注意力得分分布的 "sharpeness"。</p><blockquote><p>关于 <strong>multi-head</strong> ：上述结论对每个head仍适用，只是每个head的 <span class="math inline">\(j_{max}\)</span> 节点未必相同。</p></blockquote></li><li><p><strong>改进</strong></p><p>本文核心内容，将 <span class="math inline">\(\boldsymbol{a}\)</span> 移动到非线性激活外，使GAT成为 <em>dynamic attention</em>。</p><p><img src="./gatv2_03.png" /></p><p>证明较长，见文章appendix。</p></li></ul><h2 id="exp">4. Exp</h2><ul><li><em>Dictionary Lookup</em></li></ul><p>对于上文中二部图问题，使用改进后的GAT能有效实现<em>dynamic attention</em>。</p><p><img src="./gatv2_04.png" style="zoom:50%;" /></p><ul><li><p>Robustness to Noise</p><p>本文发现<em>dynamic attention</em>能更好抵抗噪声（不过没有进一步分析原因）。</p><p><img src="./gatv2_05.png" style="zoom:38%;" /></p></li><li><p>Node / Graph / Link Prediction</p><p><img src="./gatv2_06.png" style="zoom:50%;" /></p><p><img src="./gatv2_07.png" style="zoom:50%;" /></p><p><img src="./gatv2_08.png" style="zoom:50%;" /></p><p>值得注意的是，节点预测中 单头的 GATv2 在两个数据集上有更佳表现。作者解释为单头的GATv2已经有足够的表达能力，使用8头时反而由于过强的表达能力，遭遇了过拟合。</p></li></ul><h2 id="其他">其他</h2><p>twitter和openreview上的讨论很有意思，截取一些在此。</p><ul><li><p>GAT原作者</p><p><img src="./gatv2_09.png" style="zoom:38%;" /></p></li><li><p>关于GATv1, v2表达能力与参数数量的讨论 (二者参数数量相同，表达能力不同)</p><p><img src="./gatv2_10.png" style="zoom:50%;" /></p></li><li><p>作者关于 <em>dynamic attention</em> 的思考</p><p><img src="./gatv2_11.png" /></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;论文笔记how-attentive-are-graph-attention-networks&quot;&gt;论文笔记：HOW ATTENTIVE ARE GRAPH ATTENTION NETWORKS?&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;PDF: https://openreview.net/pdf?id=F72ximsx7C1&lt;/p&gt;
&lt;p&gt;OpenReview：https://openreview.net/forum?id=F72ximsx7C1&lt;/p&gt;
&lt;p&gt;ICLR 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;abstract&quot;&gt;1. Abstract&lt;/h2&gt;
&lt;p&gt;认为GAT是static attention，仅实现了对节点重要度的静态ranking，而未实现对不同query给出不同key的设想；提出GATv2，通过调整LeakyReLU和linear unit计算顺序，实现dynamic attention，即对不同query能给出不同key。&lt;/p&gt;</summary>
    
    
    
    <category term="论文笔记" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="图神经网络" scheme="http://example.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    <category term="图表示学习" scheme="http://example.com/tags/%E5%9B%BE%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>BOOK-07-工作消费主义和新穷人</title>
    <link href="http://example.com/2022/03/25/BOOK-07-%E5%B7%A5%E4%BD%9C%E6%B6%88%E8%B4%B9%E4%B8%BB%E4%B9%89%E5%92%8C%E6%96%B0%E7%A9%B7%E4%BA%BA/"/>
    <id>http://example.com/2022/03/25/BOOK-07-%E5%B7%A5%E4%BD%9C%E6%B6%88%E8%B4%B9%E4%B8%BB%E4%B9%89%E5%92%8C%E6%96%B0%E7%A9%B7%E4%BA%BA/</id>
    <published>2022-03-25T02:37:54.000Z</published>
    <updated>2022-03-25T02:37:54.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>武汉夜雨狂泻，狂躁的雨滴砸落地面。哦不，该称之为水面了。持续一日的雨水，在柏油路上新铺一层水面。</p><p>听闻“麻豆传媒”的一个摄影团队被抓获，翻看知乎里对事件的评价，产业链的介绍、情色作品的科普。总是会错过些“艺术”，错过了汤不热时代，一如曾经错过了快播的便捷。</p><p>如今，大约大部分人已是<strong>笑贫不笑娼</strong>了。</p></blockquote><span id="more"></span><p>一直提醒自己用发展的眼光观察、评析事物，却不时忘记亦要时常回顾历史，看看我们是如何一步步走成今天的道路。</p><ul><li>关于劳动</li></ul><p>这本书，回顾随生产力进步与社会发展的需要，人们如何一步步丢失职业自豪，被塑造成机械化的部件，进而一步步被挖去朴素的道德，被灌输用不断的消费来填充自己.</p><blockquote><p>越来越多的人认为，从工匠变成工人时失去的人的尊严，只有通过赢得更多盈余才能恢复。这种变迁中，努力工作能使人们道德升华的呼声日益衰弱。现在，衡量人们声望和社会地位的是工资的差别，而不是勤于工作的道德或惰于工作的罪恶。</p></blockquote><ul><li>关于穷人</li></ul><p>同时，还残酷地揭露着某些国家对穷人的“污名化”——生产力进步不再需要本国劳工时，穷人不再是失业，而是单纯的<strong>过剩</strong>人口。</p><blockquote><p>“失业者”虽然暂时没有工作，但一旦环境好转，他们就有望回到“生产者”的行列，一切也将回到正轨。“过剩”的人则不同，他们是多余的、编外的，不被需要。他们要么出生在一个“饱和”的社会里（即社会的续存无需更多的人从事生产），要么由于经济和技术进步（即有了新的生产力，较少的人员参与就能满足日益增长的商品和服务需求），变得不再必要。</p></blockquote><p>过剩的穷人开始背负各种污蔑，成为各种社会负面情绪转嫁的出口。媒体不断吹风造势，让大众逐渐接受人穷必是其自身有罪过，合理化对穷人的冷漠。以至于确实能见到身边有人，抱着书中所提态度：</p><blockquote><p>他们确实有一个共同点：在其他人看来，他们没有存在的必要，正是因为完全无用才会被归入社会底层——若他们消失，其他人会生活得更好。他们无疑是美丽风景线中的污渍，是丑陋又贪婪的杂草，他们对园林的和谐之美没有任何贡献，还偷走了其他植物的养分。如果他们消失，所有人都会获益。</p></blockquote><p>这般冷漠蔓延，剩下保有对生命基本尊重与对人类良知的人将如《狂人日记》中一般，道“我疯了”吧。</p><p>穷人们真是那般懒散罪恶吗，更多时候只是他们的故事被改写，从<strong>被剥夺</strong>的故事被叙述为自甘堕落的故事。</p><ul><li>关于消费</li></ul><blockquote><p>如果消费是衡量成功人生的标准，衡量幸福的标准，甚至是衡量尊严的标准，那么人类欲望的潘多拉之盒已经打开，再多的购买和刺激的感觉，都不能唤回过去“达到标准”带来的满足感：现在根本就没有标准可言。终点线和参赛者一起前行，人们力图到达的目标永远领先一步之遥。</p></blockquote><p>为人嘛，求给自己立下标准，反抗下动物性的欲望吧。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;武汉夜雨狂泻，狂躁的雨滴砸落地面。哦不，该称之为水面了。持续一日的雨水，在柏油路上新铺一层水面。&lt;/p&gt;
&lt;p&gt;听闻“麻豆传媒”的一个摄影团队被抓获，翻看知乎里对事件的评价，产业链的介绍、情色作品的科普。总是会错过些“艺术”，错过了汤不热时代，一如曾经错过了快播的便捷。&lt;/p&gt;
&lt;p&gt;如今，大约大部分人已是&lt;strong&gt;笑贫不笑娼&lt;/strong&gt;了。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="书单" scheme="http://example.com/tags/%E4%B9%A6%E5%8D%95/"/>
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>FLAG2022-1-阅读书单</title>
    <link href="http://example.com/2022/01/09/FLAG2022-1-%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95/"/>
    <id>http://example.com/2022/01/09/FLAG2022-1-%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95/</id>
    <published>2022-01-09T09:37:14.000Z</published>
    <updated>2022-11-23T12:55:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>2021年分明是较为清闲的一年，看得书却是近年来最少的一年。2022已至，决心在开年时列出今年的书单，年末再回首自己的完成情况吧。</p><p>不高估自己，且算每月两本，一年读<strong>24本</strong>已是小小的进步。闲时阅读，求广不求精，愿能涉猎各科，览阅人事。未必每本都有触动，暂且约定每读一本，于此留下至少百来字随感，若有触动，便是继续细书随笔吧。</p><p>2022，许愿：<strong>无畏，求知</strong>。</p><span id="more"></span><h1 id="书单1525">书单(15/25)</h1><h2 id="历史">历史</h2><ul class="task-list"><li><input type="checkbox" disabled="" />《<a href="https://book.douban.com/subject/24316346/">美帝国的崩溃 : 过去、现在与未来</a>》</li><li><input type="checkbox" disabled="" />《<a href="https://book.douban.com/subject/34869500/">被统治的艺术</a>》</li><li><input type="checkbox" disabled="" checked="" />《<a href="https://book.douban.com/subject/3580750/">潜规则</a>》</li></ul><blockquote><p>出门上班，满眼小商小贩雇主雇员，下班上路，到处是行色匆匆的路人和讨价还价的顾客。想叫一声同志，招呼一声兄弟，真不知冲谁开口。</p></blockquote><p>不曾想，现时常用的“潜规则”一词，居然源自此书。</p><p>能直视现实里潜在运行的规则，约莫是放下书生意气的理想年华，行到经世为人识相的标志吧。</p><p>有史以来，有人群居处，自有不便置于台面的规则运行，或遵循，或抗拒，或自立新规。</p><h2 id="经管">经管</h2><ul class="task-list"><li><input type="checkbox" disabled="" />《<a href="https://book.douban.com/subject/5346110/">穷查理宝典</a>》</li><li><input type="checkbox" disabled="" checked="" />《<a href="https://book.douban.com/subject/21331443/">中国是部金融史 : 透过金融读懂中国三千年</a>》</li><li><input type="checkbox" disabled="" checked="" />《<a href="https://book.douban.com/subject/10773362/">随机漫步的傻瓜 : 发现市场和人生中的隐藏机遇</a>》</li></ul><blockquote><ul><li>记者那一行中还是有不少懂得深思熟虑的人，只是主流媒体新闻依然不动大脑，只顾提供引人注意的噪声，而且没有什么机制能够区分两者。事实上，聪明的新闻记者反而遭到了惩罚。</li><li>投资人基于情感因素，采取的策略也会让他们偶尔才承受波动，但只要一有波动，幅度都很大。这叫做掩耳盗铃，把随机性塞到地毯底下。</li><li>“看好”或“看坏”这两个名词，是不必在不确定性状况下做事的人，例如电视评论员，或没有处理风险经验的人使用的。投资人和企业要赚的不是概率，而是白花花的钞票。因此对他们来说，某个事件发生的可能性多大并不重要，重要的是那件事发生时能赚多少钱。利润出现的频率有多高并不重要，结果多少才重要。</li></ul></blockquote><p>明辨噪音与真正的信息，意识到生活中的随机性，对事物不只考虑其发生概率更应计算其收益的<strong>期望</strong>。 知易行难。</p><h2 id="社会">社会</h2><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />《<a href="https://book.douban.com/subject/21966353/">贫穷的本质</a>》</li></ul><blockquote><p>贫穷并不仅仅意味着缺钱，它会使人丧失挖掘自身潜力的能力。</p></blockquote><p>人们生来并无无可跨越的差异，但贫富差异导致了人成长后彻头彻尾的分化。贫富差异下最大的差异之一，便是信息差。</p><blockquote><p>我们应该认识到，谁也没有那么明智、耐心或博学到能够为自己的健康做出正确的决定。同样，对于那些生活在富裕国家的人来说，他们周围充满了<strong>无形的助推力</strong>。</p></blockquote><p>贫穷存在陷阱，同样的才智，穷人不知道如何得到更廉价的贷款、更高营养的食物、无法计算投资教育的收益，视野只局限于对周身环境的认知——不止穷人，你我也是如此。穷人往往选择尽可能多的生育，反映的是他们的智慧。利用已知信息和家庭资源，养育更多子女才可能获得更高收益。</p><p>不过书中种种的实验表明，我们并非全然无能为力。一点点小的指点信息、微小的资金输入和政策扶持等，都能敲下阻隔阶级的厚墙上的砖头。</p><ul class="task-list"><li><input type="checkbox" disabled="" />《社会学的想象力》</li><li><input type="checkbox" disabled="" checked="" />《<a href="https://book.douban.com/subject/35593780/">工作、消费主义和新穷人</a>》</li></ul><p>见《BOOK-07-工作消费主义和新穷人》</p><ul class="task-list"><li><input type="checkbox" disabled="" />《失控》</li></ul><h2 id="cs">CS</h2><ul class="task-list"><li><input type="checkbox" disabled="" />《<a href="https://book.douban.com/subject/35084616/">隐私简史</a>》</li><li><input type="checkbox" disabled="" checked="" />《史蒂夫·乔布斯传》</li><li><input type="checkbox" disabled="" checked="" />《<a href="https://book.douban.com/subject/26297606/">从0到1 : 开启商业与未来的秘密</a>》</li></ul><p><strong>大胆尝试胜过平庸保守</strong>。且行且思。</p><p>摘录一些句子吧：</p><blockquote><ul><li>一旦你认为自己在抽奖，你就已经做好了亏损的心理准备。</li><li>创立公司前，能否回答下列七个问题：<ol type="1"><li>工程问题： 你的技术具有突破性，而不仅仅是稍有改进吗？</li><li>时机问题： 现在开创事业，时机合适吗？</li><li>垄断问题： 开创之初，是在一个小市场抢占大份额吗？</li><li>人员问题： 你有合适的团队吗？</li><li>销售问题： 除了创造产品，你有没有办法销售产品？</li><li>持久问题： 未来10年或20年，你能保住自己的市场地位吗？</li><li>秘密问题： 你有没有找到一个其他人没有发现的独特机会？</li></ol></li></ul></blockquote><ul class="task-list"><li><input type="checkbox" disabled="" />《<a href="https://book.douban.com/subject/35641088/">计算之魂 : 计算科学品位和认知进阶</a>》</li><li><input type="checkbox" disabled="" />《程序员修炼之道（第2版）》</li><li><input type="checkbox" disabled="" />《<a href="https://book.douban.com/subject/25930025/">只是为了好玩 : Linux之父林纳斯自传</a>》</li><li><input type="checkbox" disabled="" />《数据科学家访谈录》</li><li><input type="checkbox" disabled="" checked="" /><a href="https://book.douban.com/subject/22993903/">《区块链：从数字货币到信用社会》</a></li></ul><blockquote><p>在区块链的信用评价中，信用其实是一个数学问题。</p></blockquote><p><img src="./区块链从数字货币到信用社会.png" /></p><p>出于了解web3技术基础的需求，略读此书。前三章生动入微，后续章节务虚难解。</p><p>区块链技术为互联网中的信息赋予了绑定在数据本身上的价值。然而该价值如何和现实社会桥接，仍有一段长路要走。</p><p>文中有段对比甚是有趣，摘录如下：“如果说印刷机的意义就在于将信息资源抽离物理世界的束缚，变为一种非竞争性资源，区块链则是起着与印刷机截然相反的作用，<strong>它以处理竞争性资源的方式来处理信息资源（非竞争性）</strong>，人们可以摆脱对可信第三方的依赖，在数字世界中自由地交换数字货币、知识产权、股权甚至不动产所有权。虽然两者处理资源的方式是相反的，但两者对话语结构的改变是一致的。”</p><h2 id="休闲">休闲</h2><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />《<a href="https://book.douban.com/subject/30243002/">食物与科学的美味邂逅</a>》</li></ul><p>高开低走的一本书，开篇吊足胃口后发现更多是稳固高中理化生知识，佐以一些生活例子为延展。</p><p>倒也没错，料理的科学本就不是高高在上的。</p><p>书中不少有趣的科普或故事：</p><ul><li>居然有人（埃尔韦·蒂斯）使用“食材状态（gas/water/etc.）+分子活动的状态（分散/并存/包含/复层）”来描述料理，饶是有趣。不仅给出新的分类体系，还为料理的创新提供了新路数——替换公式中的项；</li><li><em>食物搭配学</em>居然是门新兴学科，https://www.foodpairing.com/ 👈还存在着这样的食物搭配数据库；</li><li>高压锅已经走入我们的生活了，但<strong>超高压</strong>有更多料理的想象空间——通过超高压把食品的分子挤压为高密度的状态，致使分子发生物理性变化。比如，带壳的生鸡蛋在6500个静水压力的影响下，保留了生蛋的风味，蛋黄、蛋白却“凝固”成水煮蛋的状态。</li></ul><blockquote><p>但美味并不存在于食物本身，只有在食用者的大脑接收到美味信息时才会产生美味。因此，考虑食用者如何感受这道菜品，与考虑精选食物用料、严格按照食谱烹制食物时同等重要的。</p></blockquote><p>​ 所以，做好吃的料理，要让食物、环境、氛围，都传递出爱意呀。</p><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />《贪婪的多巴胺》</li></ul><blockquote><p>多巴胺追求更多，而不是追求道德；对多巴胺来说，武力和欺诈只不过是达成目的的工具。</p></blockquote><p>科普小品文，助人了解行为背后哦的生化动机。</p><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />《质数的孤独》</li></ul><blockquote><p>质数只能被一和它自身整除。在自然数的无穷序列中它们处于自己的位置上，和其他所有数字一样被前后两个数字挤着。但它们彼此间的距离却比其他数字更远一步。它们是多疑而又孤独的数字。</p></blockquote><p>难得感性起来——一旦开始阅读，仿佛被黑洞吞噬般卷入那孤寂中。</p><p>书中马蒂亚与身边人的距离，是非连续的，在0到某个或许无穷小的实数间，有个无法跨越的距离。</p><p>没有他那般数学天赋，却莫名的想起在武汉的那些孤寂时刻，是那种，被孤寂漫灌，浓稠的黑泥直钻鼻孔，附着在每寸皮肤，无法呼吸的感觉。</p><p>瑟缩在床上，床单的褶皱似鬼脸无情的嘲笑；反复的键入又删除，方块字规整依旧，却永无那笔下所描绘的质感；雨夜、酷暑、寒冬、湿热，相同点在于眼镜总是看不清楚。</p><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />《突然，响起一阵敲门声》</li></ul><p>很迅速在偷闲中看完了，很遗憾只偷闲了一周。本想作为睡前读物，每日小看一篇。却是在看完后哭笑不得，总忍不住再续上一篇。 尤其爱《其实，我最近勃起过两次，硬得就像根金刚棒》。虽然仍是年轻，却总觉自己的宝贝将要一蹶不振。没有晨勃的日子里，会有什么能让人金鸡独立呢？</p><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />《蛤蟆先生去看心理医生》</li></ul><blockquote><p>身处情绪的特殊时期看此书，像是借蛤蟆这一傀儡，去面见了心理医生一般。</p></blockquote><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />《乡村教师》</li></ul><blockquote><p>「上尉，你是个白痴吗？！」舰队统帅大怒，「你是想告诉我们，一种没有记忆遗传，相互间用声波进行信息交流，并且是以令人难以置信的每秒１至１０比特的速率进行交流的物种，能创造出５Ｂ级文明？！而且这种文明是在没有任何外部高级文明培植的情况下自行进化的？！」</p></blockquote><p>被大刘强行拉到星际文明的智慧高度来审视我们星球的文明，才意识到我们获取知识的方式那么缓慢低效。人类，便是这样迟缓却生生不息的进步着。</p><ul class="task-list"><li><input type="checkbox" disabled="" checked="" /><a href="https://book.douban.com/subject/35710421/">《老妓抄》</a></li></ul><blockquote><p>肿瘤上歪曲的独眼，像是在瞪视人间、嘲笑人间一般，看起来反而更具有深邃意义。这张冷眼旁观人生不如意与悲欢无常的人脸上，根本已经没有必要再添加任何一笔了。</p></blockquote><p>久违的日本文学，抚慰我囚禁于疫情荒诞防控下阴暗的灵魂。可以一无所成，但请珍惜自己所有的，如《花束般的恋爱》中所述——看少年漫画仍能痛哭流涕的稚气。</p><p>上述，无关此书，只是借机感叹罢了。因为所谓的疫情，只求活着的话，活着本事实在是无趣呢。</p><hr /><p>再加点bonus项吧，不求参透，不知道2022年能读多少呢。</p><ul class="task-list"><li><input type="checkbox" disabled="" />《毛选》</li><li><input type="checkbox" disabled="" />《资本论》</li><li><input type="checkbox" disabled="" />《史记》</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;2021年分明是较为清闲的一年，看得书却是近年来最少的一年。2022已至，决心在开年时列出今年的书单，年末再回首自己的完成情况吧。&lt;/p&gt;
&lt;p&gt;不高估自己，且算每月两本，一年读&lt;strong&gt;24本&lt;/strong&gt;已是小小的进步。闲时阅读，求广不求精，愿能涉猎各科，览阅人事。未必每本都有触动，暂且约定每读一本，于此留下至少百来字随感，若有触动，便是继续细书随笔吧。&lt;/p&gt;
&lt;p&gt;2022，许愿：&lt;strong&gt;无畏，求知&lt;/strong&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="生活" scheme="http://example.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="书单" scheme="http://example.com/tags/%E4%B9%A6%E5%8D%95/"/>
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
    <category term="打卡" scheme="http://example.com/tags/%E6%89%93%E5%8D%A1/"/>
    
  </entry>
  
  <entry>
    <title>MSL-16-匆匆2021又一年</title>
    <link href="http://example.com/2021/12/28/MSL-16-%E5%8C%86%E5%8C%862021%E5%8F%88%E4%B8%80%E5%B9%B4/"/>
    <id>http://example.com/2021/12/28/MSL-16-%E5%8C%86%E5%8C%862021%E5%8F%88%E4%B8%80%E5%B9%B4/</id>
    <published>2021-12-28T12:35:25.000Z</published>
    <updated>2022-01-01T03:25:38.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>总算考完一门硬核的试，抢下些许喘息时间。不知不觉年关又至，流水账般收集下今年尚能想起的记忆碎片吧。</p><p>试图手动统计些数据，量化将逝的2021。要是有时间，或许再来做点好看的可视化吧。</p></blockquote><span id="more"></span><h1 id="输出">1. 输出</h1><p>2020年彻底抛弃了个人公众号，扼住自己的咽喉，不再发声。2021年，换了这个私人角落，重新逼着自己输出。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;总数&quot;</span>: <span class="number">31</span>,</span><br><span class="line">    <span class="attr">&quot;分类&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;ML知识总结&quot;</span>: <span class="number">3</span>,</span><br><span class="line">        <span class="attr">&quot;随笔&quot;</span>: <span class="number">20</span>,</span><br><span class="line">        <span class="attr">&quot;论文笔记&quot;</span>: <span class="number">5</span>,</span><br><span class="line">        <span class="attr">&quot;算法实践&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">&quot;工具人&quot;</span>: <span class="number">2</span>,</span><br><span class="line">&#125;,</span><br><span class="line">    <span class="attr">&quot;总字数&quot;</span>: <span class="number">33024</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>总字数的统计有偏差有水分，一些读书笔记里包括着复制的内容，一些总结归纳的文字绘制在图片中无法计数。</p></blockquote><p>总体而言，持续撰写博客是个好的开端，但仍有广阔的发展空间。</p><p>每每想到要码稿，对事物的观察就会细致些。无论是论文的研读，还是生活中的种种体验，借着要输出的压力，更能挖掘出易忽略的细节。生活的感知能力随着写作，一点点被唤醒。虽然说来有点矫情，但仍为自己庆幸，寻到了几分对抗冷漠功利社会的“多情”——愿为黄叶驻足，看它摇摆地飘落，乐得雨夜阳台闭目，倾听雨珠敲打万物的声响。</p><p>从内容分布上看，呻吟、唠叨太多而干货太少。随笔与学习笔记将近二比一的比例，反映出今年学习总结得太少了些，对半开才是理想情况。此外，学习还主要停留在“集百家所长”的积累阶段，愿明年能厚积薄发，注重知行合一，除了“论文笔记”外，能有更多“算法实践”类别文章的产出。</p><h1 id="阅读">2. 阅读</h1><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;书&quot;</span>: <span class="number">12</span>,</span><br><span class="line">    <span class="attr">&quot;影视&quot;</span>: <span class="number">21</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如上，是在豆瓣中可追溯的记录。还有些许看了小半，或是阅后无感等等，未作标记。</p><p>少，太少了。堪称贫瘠的一年。</p><p>借口是有的，诸如上半年忙着毕设，又遇情感波澜；临了毕业，栽进《沙丘》大长篇里；开学后总算找回阅读的状态，却随着学业渐紧，阅读量像抛物线样起了又伏。</p><p>终究是借口。来年但求翻个倍吧，<strong>每月2本</strong>不是难事才对。</p><p>所读数量太少，不好意思分享书单。现时回忆起来，《沙丘》系列及《富爸爸，穷爸爸》应被提名——是马上能想起的书。《富爸爸，穷爸爸》催促着人积极入世，与人斗、与金钱为友，摆正心态积极入世。《沙丘》尽管能联系当今世界风云变幻，但仍被我孤立地当成科幻史诗欣赏。从此，脑中除了战火纷飞的三国，满是自由浪漫海贼的大海等外，又多了黄沙漫天的沙丘星可供游历、幻想。</p><p>文学作品读少的结果，是遣词造句都干瘪乏力，写这些博客都要绞尽脑汁才能勉强成篇散文。</p><p>今年印象最深的影视， 都与满腔热血相关——《觉醒年代》，宣告我们何以选择今日道路；《1950他们正年轻》，述说我们的道路何以延续。历史不可不知不能遗忘，时时回望来时鲜血浇筑的道路，才能更坚定前行的方向。愿能一直赤诚，仿效先人，怀揣大志大义，不被物欲盲目，不为五斗米折腰。</p><h1 id="运动">3. 运动</h1><p>自8月来的不完全统计数据如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;健身&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;俯卧撑&quot;</span>:&#123;</span><br><span class="line">            <span class="attr">&quot;标准&quot;</span>: <span class="number">2214</span>,</span><br><span class="line">            <span class="attr">&quot;标准慢速&quot;</span>: <span class="number">115</span>,</span><br><span class="line">            <span class="attr">&quot;窄距&quot;</span>: <span class="number">230</span>,</span><br><span class="line">            <span class="attr">&quot;宽距&quot;</span>: <span class="number">284</span>,</span><br><span class="line">            <span class="attr">&quot;偏重&quot;</span>: <span class="number">600</span>,</span><br><span class="line">            <span class="attr">&quot;偏重慢速&quot;</span>: <span class="number">20</span>,</span><br><span class="line">            <span class="attr">&quot;钻石&quot;</span>: <span class="number">1055</span>,</span><br><span class="line">            <span class="attr">&quot;钻石慢速&quot;</span>: <span class="number">100</span>,</span><br><span class="line">            <span class="attr">&quot;Total&quot;</span>: <span class="number">4618</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;撸铁&quot;</span>:&#123;</span><br><span class="line">            <span class="attr">&quot;哑铃弯举7kg&quot;</span>: <span class="number">1138</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃弯举8kg&quot;</span>: <span class="number">212</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃俯身肱三弯举8kg&quot;</span>: <span class="number">176</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃俯身划船5kg&quot;</span>: <span class="number">440</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃俯身划船7kg&quot;</span>: <span class="number">606</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃俯身划船8kg&quot;</span>: <span class="number">360</span>,</span><br><span class="line">            &#x27;哑铃前&amp;侧平举2.5kg&#x27;: <span class="number">1260</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;引体向上&quot;</span>:&#123;</span><br><span class="line">            <span class="attr">&quot;半引体&quot;</span>: <span class="number">470</span>,</span><br><span class="line">            <span class="attr">&quot;正手&quot;</span>: <span class="number">864</span>,</span><br><span class="line">            <span class="attr">&quot;反手&quot;</span>: <span class="number">38</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;举腿&quot;</span>: <span class="number">439</span>, </span><br><span class="line">        <span class="attr">&quot;卷腹&quot;</span>: <span class="number">470</span>,</span><br><span class="line">        <span class="attr">&quot;深蹲&quot;</span>: <span class="number">559</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;跑步&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;总距离/km&quot;</span>: <span class="number">1294.92</span>,</span><br><span class="line">        <span class="attr">&quot;总时间/min&quot;</span>: <span class="number">7497</span>,</span><br><span class="line">        <span class="attr">&quot;半马&quot;</span>: <span class="number">8</span>,</span><br><span class="line">        <span class="attr">&quot;全马&quot;</span>: <span class="number">2</span>,</span><br><span class="line">        <span class="attr">&quot;10km PB&quot;</span>: <span class="string">&quot;00:43:50&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;半马 PB&quot;</span>: <span class="string">&quot;01:43:44&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;全马 PB&quot;</span>: <span class="string">&quot;04:18:59&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>“欲文明其精神，先自野蛮其体魄。 苟野蛮其体魄矣，则文明之精神随之。 ”</p></blockquote><p>农历新年起开始重拾跑步，下半年开始自重健身。看了数据才知道，原来坚持一点点的锻炼，积少成多也有成百上千的数量，从5公里、十公里，到了能挑战全马的距离。</p><p>体型变化仍不甚明显，更多的是对心态的调节吧。不快时，换双跑鞋出门小跑个把小时，或是找出干净地方就地俯卧撑，练到双臂酸胀，整个人趴在地上，心头的烦扰杂念也消散不少。不像其他事物，运动的进步曲线大多平滑且平缓，最能获取一分耕耘一分收获的欢喜。以及胃口是真的好了很多，成“饭学长”了。</p><h1 id="其他">4. 其他</h1><p>情感方面，高低起伏动荡不安的一年，行至年关总算是到了心略安的时候。今年学业不敢说有何增进，亲密关系的处置方面绝对是学习良多。来到第四季度算是打点好自己重新出发了。</p><p>本科毕业的年份，因顺利的保研继续求学，显得平淡。仍是老地方，一点点推进所谓的“科研”吧。</p><hr /><p>匆匆，着实匆匆。跨了年后，欠下的文稿已不想再补。</p><p>总结与展望，以及新的FLAG，留待农历新年吧。总觉得《难忘今宵》唱响，一年才是真的到头了。</p><p>以及，虚岁已是二三，愿见贤思齐，多内省，多干实事。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;总算考完一门硬核的试，抢下些许喘息时间。不知不觉年关又至，流水账般收集下今年尚能想起的记忆碎片吧。&lt;/p&gt;
&lt;p&gt;试图手动统计些数据，量化将逝的2021。要是有时间，或许再来做点好看的可视化吧。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>GNN_STARGNN_Adaptive感受野</title>
    <link href="http://example.com/2021/12/18/GNN-STARGNN-Adaptive%E6%84%9F%E5%8F%97%E9%87%8E/"/>
    <id>http://example.com/2021/12/18/GNN-STARGNN-Adaptive%E6%84%9F%E5%8F%97%E9%87%8E/</id>
    <published>2021-12-18T02:49:16.000Z</published>
    <updated>2021-12-18T02:49:16.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="improving-graph-neural-networks-with-structural-adaptive-receptive-fields">Improving Graph Neural Networks with Structural Adaptive Receptive Fields</h1><blockquote><p>PDF: https://dl.acm.org/doi/10.1145/3442381.3449896</p><p>Conferences: WWW '21</p></blockquote><h2 id="abstract">1. Abstract</h2><p>现有GNN模型未能充分利用图结构信息，此工作提出STructural Adaptive Receptive fields (<strong>STAR-GNN</strong>)，适应性地构建每个节点的感受野(receptive field)以捕获结构信息。具体贡献如下：</p><ul><li>提出基于节点结构信息来自适应调节receptive field范围STAR-GNN；</li><li>将Anonymous Random Walks (ARWs)和互信息结合来捕获节点的结构信息，此外还提出针对receptive field的subgraph 聚合算子。</li></ul><span id="more"></span><h2 id="motivations">2. Motivations</h2><p><strong>大部分GNNs未能充分利用图结构信息，对邻居节点的重要性没有区分：</strong></p><ul><li>传统的GCN将邻居节点一视同仁，或者根据边权来分配权重，因而忽略了许多与邻居重要性有关的信息；</li><li>GAT使用soft attention，基于节点特征的相似度来学习权重，但其，① 忽略拓扑特征的相似度信息，② soft attention在邻居数量较大时可能遭遇过平滑问题。</li></ul><p>对此，希望能提出一种<strong>结合结构信息来适应性地构建节点receptive field</strong>的方法，该方法希望能 ①同时根据节点特征和结构特征来衡量邻居重要性，② receptive field聚合irregular neighborhoods 且避免过平滑问题。</p><p>遇到的挑战如下：</p><ol type="1"><li>图复杂的结构信息难捕获；</li><li>适应性地构建receptive field计算复杂度高。该adaptive构建过程是不可微的，因而难直接优化。此前使用强化学习及组合优化的方式计算复杂度都过高；</li><li>不能基于k-order邻居来建立receptive field。理想的receptive field是不规则的子图，可能有数量各异的各阶邻居，现有聚合算子难有效聚合这样的子图结构。</li></ol><h2 id="method">3. Method</h2><figure><img src="./STARGNN_01.png" alt="overview" /><figcaption aria-hidden="true">overview</figcaption></figure><h3 id="overview">3.1 Overview</h3><p>STAR-GNN主要分为3个部分：</p><ol type="1"><li><strong>Local Structural Distribution</strong>，使用ARWs来捕获节点的邻居分布，结合Mutual Information(MI)来计算注意力，得到包含节点特征和结构信息的structural embedding；</li><li><strong>Construction of Optimal Receptive Fields</strong>，用structural embedding计算节点对间MI，贪心地寻找optima receptive field；</li><li><strong>GNN with Sub-graph Structures</strong>，通过采样不规则subgraph（receptive field）中节点，进行聚合。</li></ol><h3 id="neighborhood-contributions-local-structural-distribution">3.2 Neighborhood Contributions Local Structural Distribution</h3><p>Attention score 计算，过往一些方法基于节点特征相似度，一些则引入了人为设计的结构信息patterns，都只能捕获有限结构信息且泛化性不佳。</p><p>本工作则使用ARWs刻画节点的邻居结构特征，认为ARWs能较好地描述节点的local structural distribution。ARWs定义如下：</p><p><img src="./STARGNN_03.png" style="zoom:50%;" /></p><p>进一步地，本工作引入互信息(MI)来辅助学习节点embedding <span class="math inline">\(U={u_i}\)</span>，希望最大化节点对间特征、结构信息。Loss设计有：</p><p><img src="./STARGNN_04.png" style="zoom:67%;" /></p><p>其中<span class="math inline">\(w_{i j}=\sigma\left(\mathbf{u}_{i}^{T} \mathbf{u}_{j}\right)\)</span>，<span class="math inline">\(\mathcal{N}_{i}\)</span>为节点<span class="math inline">\(i\)</span>的ARWs中所访问到的节点集合，<span class="math inline">\(I(·, ·)\)</span>为互信息，第一项衡量节点间特征相似度，第二项衡量结构相似度。</p><p><img src="./STARGNN_05.png" style="zoom:67%;" /></p><p>Attention score则由上述<span class="math inline">\(u\)</span>计算，</p><p><img src="./STARGNN_06.png" style="zoom:50%;" /></p><h3 id="construction-of-optimal-receptive-fields">3.3 Construction of Optimal Receptive Fields</h3><p>作者先前的工作说明GAT中的soft attention，在节点度较高时会遇到过平滑问题。因而构建receptive field时，应当“construct discrete adaptive receptive fields to avoid over-smoothing”(不是很理解，是否理解为需要筛选邻居，以减少聚合对象个数)。</p><p>作者认为，理想的receptive field应当<strong>为中心节点提供最多的信息</strong>，并希望用<strong>MI</strong>来衡量获取信息的多少。</p><p>因为MI≥0，故receptive field增大时MI和单调不减，故本工作将优化目标定为：以最小的receptive field取得满足阈值的MI：</p><p><img src="./STARGNN_07.png" style="zoom:67%;" /></p><p>本工作使用贪心算法求解上述优化问题。</p><h3 id="gnn-with-sub-graph-structures">3.4 GNN with Sub-graph Structures</h3><p>当前聚合算子如Mean, Max, LSTM针对k-hop邻居做聚合，对于不规则的subgraph，聚合时难以区分不同阶邻居信息。</p><p>本工作对如下聚合方式进行一系列证明，说明其满足permutation invariant。最后得到的聚合方式为：</p><p><img src="./STARGNN_08.png" style="zoom:67%;" /></p><p>模型loss则为</p><p><img src="./STARGNN_09.png" style="zoom:50%;" /></p><p>模型算法描述如下：</p><p><img src="./STARGNN_10.png" style="zoom:50%;" /></p><h2 id="exp">4. Exp</h2><ol type="1"><li><p>节点分类</p><ul><li>Transductive</li><li><img src="./STARGNN_11.png" style="zoom:80%;" /></li><li>Inductive</li><li><img src="./STARGNN_12.png" style="zoom:50%;" /></li></ul></li><li><p>Ablation study</p><p><img src="./STARGNN_13.png" style="zoom:50%;" /></p><p>相对而言，引入结构信息和选择optimal receptive field对性能帮助更大。</p></li></ol><h2 id="personal-thoughts">5. Personal Thoughts</h2><p>建模阶段：</p><ul><li>在base node embedding阶段，用ARWs来刻画节点的local structure。RW-based方法implicit捕获拓扑结构，相较于explicit的子图挖掘，泛化性更好，对边缘节点等刻画更清晰，但未必能准确刻画cohesive subgraph等子图结构；</li><li>（越看越奇怪，感觉没看懂）base node embedding依旧通过GNN在原图上(?)学习，不过在loss中加入MI构造的penalty，来捕获ARWs所刻画的结构信息，此处可算出attention scores，留给final embedding的聚合阶段使用；</li><li>optimal receptive field通过MI+贪心算法构建。它们不在聚合阶段做邻居的筛选，而是将receptive field的构建前置，从而减少噪音，思路值得借鉴；</li><li>final embedding由传统的邻居聚合+及<span class="math inline">\(\tilde{h_i}\)</span>构成，<span class="math inline">\(\tilde{h_i}\)</span>聚合了节点<span class="math inline">\(i\)</span>的感受野信息。其聚合方法符合个人为实现子图聚合的想法——<em>抽样聚合</em>，提供了理论证明；</li></ul><p>整体工作：</p><ul><li>可以发现，本工作实际的编码器只有两个分离的GNN及若干MLP，主要工作在于<strong>adaptively调整编码器的输入</strong>；</li><li>亮点：<ul><li>MI的引入比较系统，从loss设计到optimal感受野的选择都结合了MI；</li><li>理论的证明和实验做得比较齐全，模型在数据集上的F1表现优异；</li></ul></li><li>不足：<ul><li>为得到final embedding，过程中产生较多冗余变量来调整模型输入，模型整体性略差。更理想来说，通过模型架构和penalty来自动选择感受野更为理想，贪婪算法整体性不强；</li><li>模型的推理速度堪忧。</li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;improving-graph-neural-networks-with-structural-adaptive-receptive-fields&quot;&gt;Improving Graph Neural Networks with Structural Adaptive Receptive Fields&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;PDF: https://dl.acm.org/doi/10.1145/3442381.3449896&lt;/p&gt;
&lt;p&gt;Conferences: WWW &#39;21&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;abstract&quot;&gt;1. Abstract&lt;/h2&gt;
&lt;p&gt;现有GNN模型未能充分利用图结构信息，此工作提出STructural Adaptive Receptive fields (&lt;strong&gt;STAR-GNN&lt;/strong&gt;)，适应性地构建每个节点的感受野(receptive field)以捕获结构信息。具体贡献如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提出基于节点结构信息来自适应调节receptive field范围STAR-GNN；&lt;/li&gt;
&lt;li&gt;将Anonymous Random Walks (ARWs)和互信息结合来捕获节点的结构信息，此外还提出针对receptive field的subgraph 聚合算子。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="论文笔记" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="图神经网络" scheme="http://example.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    <category term="图表示学习" scheme="http://example.com/tags/%E5%9B%BE%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
