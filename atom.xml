<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>这是博客</title>
  
  <subtitle>试图存在, 但薛三无法自证</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2023-01-16T03:00:59.000Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Vincent Xue</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MSL_22_经得起变化</title>
    <link href="http://example.com/2023/01/16/MSL-22-%E7%BB%8F%E5%BE%97%E8%B5%B7%E5%8F%98%E5%8C%96/"/>
    <id>http://example.com/2023/01/16/MSL-22-%E7%BB%8F%E5%BE%97%E8%B5%B7%E5%8F%98%E5%8C%96/</id>
    <published>2023-01-16T03:00:59.000Z</published>
    <updated>2023-01-16T03:00:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>不再是光谷，没去到红馆。人来人往，终于是只身一人来顺德。</p><p>Alan Po，来日之音。</p><span id="more"></span><p>18排，1座——一楼靠后的角落，右手边是过道，左边坐着结伴而来的三位陌生人。早早到场的结果，便是开show前，些许无聊，些许尴尬无助，无人可倾谈、分享。</p><p>直到，灯光熄灭，舞台闪烁时。演唱会的意义，或许在于音乐奏响、歌手演唱时，观众间的陌生恍然间弥散，齐心随音乐摇摆、合唱。</p><p><img src="./摇摆.jpg" /></p><p>茫茫众生，大多都在寻求团体的温暖。演唱会两小时的时光，厅内的各位，仿似家人。为阿纶欢呼，为求婚的情侣祝福，为那首首单循过的歌曲尖叫。</p><p><img src="./昨天.jpg" /></p><p><img src="./合照.jpg" /></p><p>直到曲终人静时，又重回一个个陌生的个体。轻哼着encore的曲目，收拾行囊，步出会场。</p><p>不必否定孤独。混于人群时纷扰太多，忙于应付周遭；困于人群自我太少，疏于扪心自问。</p><p>三年疫情，太多人事消散变迁。我也陷入失语症：迟滞，不善表达，亦恐于落笔。关于疫情的管控已解绑，且将它视作一界碑，分隔前些日子茫然的自我。</p><p>而今，重温独处，重习专注，爱自我，爱生活吧。人，要经得起变化才是。</p><p>「望四周的身影如幻覺</p><p>舊照片的溫馨情已不再</p><p>縱使它不可變改</p><p>人總要自愛」</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;不再是光谷，没去到红馆。人来人往，终于是只身一人来顺德。&lt;/p&gt;
&lt;p&gt;Alan Po，来日之音。&lt;/p&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>MSL_21_LifeGoesOn</title>
    <link href="http://example.com/2022/12/31/MSL-21-LifeGoesOn/"/>
    <id>http://example.com/2022/12/31/MSL-21-LifeGoesOn/</id>
    <published>2022-12-31T15:21:32.000Z</published>
    <updated>2022-12-31T15:21:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>Life Must Goes On...</p><p>2022已过去，依旧青春热血莽撞无虑，但也依旧幼稚短视懒惰。</p><p>回首2022的日子，并不能骄傲地于此尽数，只得怯弱地将愿景寄托于2023年。</p><p>或许依旧该张狂地吹下种种牛逼，然而23年，24岁的我，该将吹得牛通通实现才是。</p><blockquote><p>有悲总有喜 人不要自危</p><p>随时代走用眼泪伴这双手</p><p>再辛苦也好 亦不要淡忘</p><p>前景多好看</p><p>不要淡忘</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Life Must Goes On...&lt;/p&gt;
&lt;p&gt;2022已过去，依旧青春热血莽撞无虑，但也依旧幼稚短视懒惰。&lt;/p&gt;
&lt;p&gt;回首2022的日子，并不能骄傲地于此尽数，只得怯弱地将愿景寄托于2023年。&lt;/p&gt;
&lt;p&gt;或许依旧该张狂地吹下种种牛逼，然而23年，2</summary>
      
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>联邦学习03_模型异构</title>
    <link href="http://example.com/2022/11/05/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A003-%E6%A8%A1%E5%9E%8B%E5%BC%82%E6%9E%84/"/>
    <id>http://example.com/2022/11/05/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A003-%E6%A8%A1%E5%9E%8B%E5%BC%82%E6%9E%84/</id>
    <published>2022-11-05T07:34:01.000Z</published>
    <updated>2022-11-10T11:18:06.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="flheterogeneous-model-小结">FL：Heterogeneous model 小结</h1><h2 id="motivations">0. Motivations</h2><ol type="1"><li><strong>System heterogeneity</strong>. Clients have various computation and bandwidth resources, where each participant has capacity and desire to design their own unique model.</li><li>Strong server, weak client.</li></ol><span id="more"></span><h2 id="knowledge-distillation-入门">1. Knowledge Distillation 入门</h2><blockquote><p>Ref: 【经典简读】知识蒸馏(Knowledge Distillation) 经典之作 - 潘小小的文章 - 知乎 https://zhuanlan.zhihu.com/p/102038521</p></blockquote><figure><img src="./image-20221104103056522.png" alt="image-20221104103056522" /><figcaption aria-hidden="true">image-20221104103056522</figcaption></figure><p>知识蒸馏使用的是Teacher—Student模型，其中teacher是“知识”的输出者，student是“知识”的接受者。知识蒸馏的过程分为2个阶段:</p><ol type="1"><li>原始模型训练: 训练"Teacher模型", 简称为Net-T，它的特点是模型相对复杂。对于输入X, 其都能输出Y，其中Y经过softmax的映射，输出值对应相应类别的概率值。</li><li>精简模型训练: 训练"Student模型", 简称为Net-S，它是参数量较小、模型结构相对简单的单模型。同样的，对于输入X，其都能输出Y，Y经过softmax映射后同样能输出对应相应类别的概率值。</li></ol><p><strong>Soft Labels(Soft Targets)</strong></p><figure><img src="./image-20221104103157056.png" alt="image-20221104103157056" /><figcaption aria-hidden="true">image-20221104103157056</figcaption></figure><p>最后，Net-S的目标函数有： <span class="math display">\[L=\alpha L_{\text {soft }}+\beta L_{\text {hard }}\]</span></p><h2 id="hetemodel-fl-with-knowledge-distillation">2. HeteModel-FL with knowledge distillation</h2><h3 id="fedhe">2.1 FedHe</h3><blockquote><p>FedHe: Heterogeneous Models and Communication-Efficient Federated Learning</p><p>2021 17th International Conference on Mobility, Sensing and Networking (MSN) 2021</p></blockquote><figure><img src="./image-20221104104226887.png" alt="image-20221104104226887" /><figcaption aria-hidden="true">image-20221104104226887</figcaption></figure><p>Server不承担teacher模型训练，只负责聚合各个client上传的各类样本的logits，并将聚合的结果发还。</p><p>Clients端把 aggregated logits 视作 soft label 进行学习。</p><h3 id="fedmd">2.2 FedMD</h3><blockquote><p>Fedmd: Heterogenous federated learning via model distillation</p><p>arXiv preprint 2019</p><p>Code: https://github.com/diogenes0319/FedMD_clean</p></blockquote><figure><img src="./image-20221104110228287.png" alt="image-20221104110228287" /><figcaption aria-hidden="true">image-20221104110228287</figcaption></figure><p>Clients提供一部分数据来构建public dataset。</p><p>各 client 求 public dataset 对应的 logits。Server 负责聚合各个 client 的 logits 并求平均。发还的 avg(logits) 用以蒸馏 client 端的 model。</p><p>由于各 client 是用private dataset + public dataset训练模型，故对public dataset算出的logits中隐性地包含client private data distribution的信息，意味着使用蒸馏可以在不侵犯隐私的情况下获得其他的client的帮助。</p><h3 id="fml">2.3 FML</h3><blockquote><p>Federated mutual learning</p><p>arXiv preprint 2020</p></blockquote><figure><img src="./image-20221104110855842.png" alt="image-20221104110855842" /><figcaption aria-hidden="true">image-20221104110855842</figcaption></figure><p>设置 Global model 及 Personalized model。 Global model 架构相同，按照一般FL方式进行训练，作为 teacher model使用。</p><h3 id="fedh2l">2.4 FedH2L</h3><blockquote><p>FedH2L: Federated learning with model and statistical heterogeneity</p><p>arXiv preprint 2021</p></blockquote><p>需要共享部分数据作为seed data（文中未讨论seed data的选择和对模型影响）。</p><p>直接将知识蒸馏迁移到去中心化FL场景。client间互为teacher-student，进行知识蒸馏。</p><h3 id="对比">2.5 对比</h3><table><thead><tr class="header"><th>Model</th><th>Architecture</th><th>Share</th></tr></thead><tbody><tr class="odd"><td>FedHe</td><td>CS</td><td>Logits with class</td></tr><tr class="even"><td>FedMD</td><td>CS</td><td>Public dataset</td></tr><tr class="odd"><td>FML</td><td>CS</td><td>Global model weights</td></tr><tr class="even"><td>FedH2L</td><td>P2P</td><td>Seed data</td></tr></tbody></table><p>如何兼顾隐私与构建强teacher模型，仍是待讨论的问题。</p><h2 id="others">3. Others</h2><p><strong>Hyper networks</strong></p><p>通过Hyper networks学习personalized model weights，模型自由度较知识蒸馏低。</p><figure><img src="./image-20221104111951949.png" alt="image-20221104111951949" /><figcaption aria-hidden="true">image-20221104111951949</figcaption></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;flheterogeneous-model-小结&quot;&gt;FL：Heterogeneous model 小结&lt;/h1&gt;
&lt;h2 id=&quot;motivations&quot;&gt;0. Motivations&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;strong&gt;System heterogeneity&lt;/strong&gt;. Clients have various computation and bandwidth resources, where each participant has capacity and desire to design their own unique model.&lt;/li&gt;
&lt;li&gt;Strong server, weak client.&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="ML知识总结" scheme="http://example.com/categories/ML%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="联邦学习" scheme="http://example.com/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>GNN_表达能力小结</title>
    <link href="http://example.com/2022/10/29/GNN-%E8%A1%A8%E8%BE%BE%E8%83%BD%E5%8A%9B%E5%B0%8F%E7%BB%93/"/>
    <id>http://example.com/2022/10/29/GNN-%E8%A1%A8%E8%BE%BE%E8%83%BD%E5%8A%9B%E5%B0%8F%E7%BB%93/</id>
    <published>2022-10-29T06:44:33.000Z</published>
    <updated>2022-10-29T06:44:33.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="如何理解-gnn-表达能力的粗浅小结">如何理解 GNN 表达能力的粗浅小结</h1><blockquote><p>参考阅读：</p><ol type="1"><li><a href="https://graph-neural-networks.github.io/gnnbook_Chapter5.html">Chapter5: The Expressive Power of Graph Neural Networks</a></li><li><a href="https://www.163.com/dy/article/FG0J275N0511DPVD.html">中科院计算所沈华伟：图神经网络表达能力的回顾和前沿</a></li><li><a href="https://zhuanlan.zhihu.com/p/369869891">【ICLR2021论文解读】初探 GNN 表达能力</a></li><li><a href="https://openreview.net/forum?id=-qh0M9XWxnv">Analyzing the Expressive Power of Graph Neural Networks in a Spectral Perspective</a></li><li><a href="https://www.cnblogs.com/hilbert9221/p/14443747.html">图神经网络的表达能力与置换同变性</a></li></ol></blockquote><span id="more"></span><h2 id="神经网络的表达能力">1. 神经网络的表达能力</h2><p>机器学习的任务，可以理解为存在一个从特征空间到目标空间的映射<span class="math inline">\(f^*\)</span>，希望能用模型 <span class="math inline">\(f_\theta\)</span> 来近似<span class="math inline">\(f^*\)</span> 。可将 <span class="math inline">\(f_\theta\)</span> 能近似的<strong>映射范围</strong>理解为模型的表达能力。</p><p>先前研究已证明了定义任意定义在compact space上的连续函数都可被<strong>MLP</strong>近似。但其实，一方面并不能保证<strong>模型经训练所学的<span class="math inline">\(\hat{f}\)</span> 是想近似的<span class="math inline">\(f^*\)</span></strong>，另一方面过强的表达能力还可能导致overfitting。</p><figure><img src="./image-20221024121136460.png" alt="image-20221024121136460" /><figcaption aria-hidden="true">image-20221024121136460</figcaption></figure><p>因此，我们希望建立能够保持强大表达能力的NN，同时对其参数施加约束——归纳偏置反映着对问题的先验认知。</p><p>对于CNN/RNN，模型共享参数的机制隐含着translation invariance的假设，对模型的表达力进行限制，但已经能完成对应任务<strong>(limited but sufficient)</strong>。</p><figure><img src="./image-20221024153918940.png" alt="image-20221024153918940" /><figcaption aria-hidden="true">image-20221024153918940</figcaption></figure><p>对于GNN，则有如下图所示的permutation invariance限定。</p><figure><img src="./image-20221024154514368.png" alt="image-20221024154514368" /><figcaption aria-hidden="true">image-20221024154514368</figcaption></figure><h2 id="gnn表达能力的不同视角">2. GNN表达能力的不同视角</h2><ol type="1"><li><p><strong>区分能力(separating power)/相似性度量</strong>：</p><p>经典工作为 <em>How Powerful are Graph Neural Networks？</em>，它使用的<strong>图同构检验graph isomorphism problem</strong>来衡量GNN表达能力。表达力强的GNN能学到分辨性强的graph embedding，让我们<strong>在隐空间中判定两个图是否同构</strong>。</p><p>进一步的，还可尝试探索GNN是否能处理更难的 <strong>图编辑距离graph edit distance problem</strong>。</p></li><li><p><strong>逼近能力(approximation power)</strong>：</p><p>基于<strong>函数逼近</strong>思路，关心神经网络能够<strong>表达的函数的范围有多大</strong>，工作举例有<em>EXPRESSIVE POWER OF INVARIANT AND EQUIVARIANT GRAPH NEURAL NETWORKS</em>。尝试证明GNN可以逼近的定义在图上的映射集合。</p></li><li><p><strong>模式识别</strong>：</p><p>通过研究GNN是否能识别图中的特定结构，把模式识别能力视作GNN的表达能力，工作举例有<em>Can graph neural networks count substructures?</em>。</p></li></ol><h2 id="提升表达力方式wl-test视角">3. 提升表达力方式（WL-test视角）</h2><p><a href="https://graph-neural-networks.github.io/gnnbook_Chapter5.html">Chapter5: The Expressive Power of Graph Neural Networks</a>的5.4章给出了具体介绍，在此不赘述。</p><figure><img src="./image-20221024162739401.png" alt="image-20221024162739401" /><figcaption aria-hidden="true">image-20221024162739401</figcaption></figure><hr /><p>上述观察，主要都聚焦在graph-level研究GNN表达能力，而缺乏从node-level出发的表达能力讨论。</p><p>一说对于node-level任务，GNN已经是universal approximator，不必深入研究。（参考阅读2）</p><figure><img src="./image-20221024185051603.png" alt="image-20221024185051603" /><figcaption aria-hidden="true">image-20221024185051603</figcaption></figure><p>但另一方面，一直以来关于GNN架构的研究，除了提升其表达能力外，也在努力提升其拟合能力——使模型能从有限的训练数据中尽可能拟合ground truth映射函数<span class="math inline">\(f^*\)</span>。</p><figure><img src="./image-20221024185802289.png" alt="image-20221024185802289" /><figcaption aria-hidden="true">image-20221024185802289</figcaption></figure><p>或许可理论层面分析node-level层面GNN的表达能力、泛化能力（待阅读<a href="https://openreview.net/pdf?id=UH-cmocLJC">How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks. Keyulu Xu et al. ICLR 2021.</a>、<a href="https://openreview.net/pdf?id=rJxbJeHFPS">What Can Neural Networks Reason About? Keyulu X et al. ICLR2020</a>）；</p><p>也可能参考上述他人证明，指导设计 theortical proven node-level specific GNN。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;如何理解-gnn-表达能力的粗浅小结&quot;&gt;如何理解 GNN 表达能力的粗浅小结&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;参考阅读：&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;a href=&quot;https://graph-neural-networks.github.io/gnnbook_Chapter5.html&quot;&gt;Chapter5: The Expressive Power of Graph Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.163.com/dy/article/FG0J275N0511DPVD.html&quot;&gt;中科院计算所沈华伟：图神经网络表达能力的回顾和前沿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/369869891&quot;&gt;【ICLR2021论文解读】初探 GNN 表达能力&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://openreview.net/forum?id=-qh0M9XWxnv&quot;&gt;Analyzing the Expressive Power of Graph Neural Networks in a Spectral Perspective&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/hilbert9221/p/14443747.html&quot;&gt;图神经网络的表达能力与置换同变性&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="ML知识总结" scheme="http://example.com/categories/ML%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="图神经网络" scheme="http://example.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    <category term="图表示学习" scheme="http://example.com/tags/%E5%9B%BE%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>MSL_20_蹒跚科研小记</title>
    <link href="http://example.com/2022/10/15/MSL-20-%E8%B9%92%E8%B7%9A%E7%A7%91%E7%A0%94%E5%B0%8F%E8%AE%B0/"/>
    <id>http://example.com/2022/10/15/MSL-20-%E8%B9%92%E8%B7%9A%E7%A7%91%E7%A0%94%E5%B0%8F%E8%AE%B0/</id>
    <published>2022-10-15T08:26:32.000Z</published>
    <updated>2022-10-15T08:26:32.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Oct.14, 2022，再怎样不满意工作也好，终究是把自己的论文投了出去，为蹒跚的科研立下一个小里程碑。</p></blockquote><p>无论结果好坏，且将若干总结记录于此。</p><span id="more"></span><ul><li><p><strong>持续输入——哪怕idea定型</strong></p><p>把读论文变作习惯，把了解最新工作看作每日读报一样的消遣。</p><p>要保证持续的输入，跟进最新的工作。不只是研究选题时的广泛阅读，而是哪怕在idea定型，专心做实验时，依旧需要保持输入。他人的成果或能带来对个人研究方向的新视角，或提供更新的理论佐证等。闭门造车不可取，不知不觉就走入岔路落后他人了。</p></li><li><p><strong>活用工具，管理进度</strong></p><p>课题做了一年多，从新颖拖到平庸，自我的不断拖延虽是核心原因，但仍有不少工具能助我提振精神，管理进度。</p><p>一如这一个月来使用的任务看板<em>Trello</em></p><p><img src="./trello.png" /></p><p>借助看板，排好工作档期，依照重要性逐次按时攻破任务。每次将任务从“进行中”挪至“完成”时，都可享受自造的成就感。</p></li><li><p><strong>任何结论，想多一步</strong></p><p><strong>我们写的论文不是说明书，而重在议论</strong>。</p><p>论文不是简单罗列做了什么，而是完整地论述为何要做，怎样去做，解决了什么问题。</p><p>议论从何来，便是得到任何实验结果，推导出任何结论，都想多一步——为什么。</p></li><li><p><strong>推敲与交流并行</strong></p><p>科研不必做孤胆英雄，与其他方向友人交流或许有更多灵光乍现的时刻。</p></li><li><p><strong>平和心态——过程奋进，悦纳结果</strong></p><p>不及预期也罢，但求过程无悔。画上句点后，尊重自己的劳动成果，投身下一段研究中去吧。</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Oct.14, 2022，再怎样不满意工作也好，终究是把自己的论文投了出去，为蹒跚的科研立下一个小里程碑。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;无论结果好坏，且将若干总结记录于此。&lt;/p&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="科研心声" scheme="http://example.com/tags/%E7%A7%91%E7%A0%94%E5%BF%83%E5%A3%B0/"/>
    
  </entry>
  
  <entry>
    <title>MSL_19_Why Decentralization Matters笔记</title>
    <link href="http://example.com/2022/10/14/MSL-19-WhyDecentralizationMatters%E7%AC%94%E8%AE%B0/"/>
    <id>http://example.com/2022/10/14/MSL-19-WhyDecentralizationMatters%E7%AC%94%E8%AE%B0/</id>
    <published>2022-10-14T02:48:32.000Z</published>
    <updated>2022-10-14T17:08:34.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Ref:</p><p>原始blog 👉 <a href="https://cdixon.org/2018/02/18/why-decentralization-matters">here</a></p><p>zhihu笔记 👉 <a href="https://zhuanlan.zhihu.com/p/572235146">here</a></p></blockquote><span id="more"></span><p><img src="./Whydecentralizationmatters.png" /></p><blockquote><p>Instead of placing our trust in corporations, we can place our trust in community-owned and -operated software, transforming the internet’s governing principle from “don’t be evil” back to <strong>“can’t be evil.”</strong></p></blockquote><p>仅从此篇blog来看，以去中心化概念为核心的web 3.0 时代仅有淳朴的愿景。期待由于网络基础架构的改变，支持去中心化的网络发展后，人类组织合作方式能随之<strong>演进到community-govern的共治模式</strong>。基于web 3.0里的tokens激励机制，能让参与者劳有所得，从机制上实现<strong>公平的按劳分配</strong>。</p><p>从愿景而言让人向往，但其实现方式仍需继续了解。此外，如何顺利接轨现有社会体系，而非技术理论上的空想，也待分析。</p><hr /><p>放下对元宇宙，比特币的成见，了解下Internet可能的未来。</p><p>去中心化，朴素自治的未来有何技术基础支持？web 3.0到底在讨论怎样的Internet？便从此刻开始去了解，准备吧。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Ref:&lt;/p&gt;
&lt;p&gt;原始blog 👉 &lt;a href=&quot;https://cdixon.org/2018/02/18/why-decentralization-matters&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;zhihu笔记 👉 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/572235146&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="生活" scheme="http://example.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>Torch_Einsum入门</title>
    <link href="http://example.com/2022/09/19/Torch-Einsum%E5%85%A5%E9%97%A8/"/>
    <id>http://example.com/2022/09/19/Torch-Einsum%E5%85%A5%E9%97%A8/</id>
    <published>2022-09-19T13:42:11.000Z</published>
    <updated>2022-09-19T13:42:11.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>看代码遇到了精妙的<strong>爱因斯坦求和约定（einsum）</strong>，并在zhihu上发现了生动的讲解。简要拆解内容为知识导图做备份。 原文地址👉<a href="https://zhuanlan.zhihu.com/p/361209187">戳这里</a></p></blockquote><span id="more"></span><p>（原文还有结合代码的例子讲解哦！）</p><figure><img src="./einsum.png" alt="mindmap" /><figcaption aria-hidden="true">mindmap</figcaption></figure>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;看代码遇到了精妙的&lt;strong&gt;爱因斯坦求和约定（einsum）&lt;/strong&gt;，并在zhihu上发现了生动的讲解。简要拆解内容为知识导图做备份。 原文地址👉&lt;a href=&quot;https://zhuanlan.zhihu.com/p/361209187&quot;&gt;戳这里&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="工具人" scheme="http://example.com/categories/%E5%B7%A5%E5%85%B7%E4%BA%BA/"/>
    
    
    <category term="Pytorch" scheme="http://example.com/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Crawler_Elsevier Abstract爬取</title>
    <link href="http://example.com/2022/09/07/Crawler-Elsevier-Abstract%E7%88%AC%E5%8F%96/"/>
    <id>http://example.com/2022/09/07/Crawler-Elsevier-Abstract%E7%88%AC%E5%8F%96/</id>
    <published>2022-09-07T15:57:50.000Z</published>
    <updated>2022-09-08T01:53:40.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>机缘巧合，需要帮朋友爬取些论文摘要。遂将任务探索过程及解决方案记录如下。</p><p>初次接触Requests，代码较为稚嫩，多多包涵。</p></blockquote><span id="more"></span><h1 id="需求描述">1. 需求描述</h1><p>在<strong>Elsevier</strong>数据库中，给定<strong>查询条件</strong>（如，搜索“题目、摘要、关键词中包含<code>Target</code>的论文”），检索论文，并存取论文标题及<strong>摘要</strong>。</p><h1 id="解决方案">2. 解决方案</h1><h2 id="前期准备">2.1 前期准备</h2><ul><li><p>python环境</p></li><li><p>创建个人API-Key <a href="https://dev.elsevier.com/apikey/manage">link</a></p><figure><img src="./image-20220908003127528.png" alt="image-20220908003127528" /><figcaption aria-hidden="true">image-20220908003127528</figcaption></figure></li><li><p>下载<em>Elsapy</em> 源码 <a href="https://github.com/ElsevierDev/elsapy">Github</a></p><figure><img src="./image-20220908003348189.png" alt="image-20220908003348189" /><figcaption aria-hidden="true">image-20220908003348189</figcaption></figure></li></ul><h2 id="摘要相关api一览">2.2 摘要相关API一览</h2><blockquote><p>注：<em>Elsapy</em>封装了对相关api的request（虽然要魔改下）。</p></blockquote><ul><li><p><a href="https://dev.elsevier.com/documentation/ScopusSearchAPI.wadl">Scopus Search API</a></p><p>通过向此API发起请求，我们能得到<em>Scopus</em>数据库中符合检索条件的摘要的<strong>URL</strong>。</p><figure><img src="./image-20220908003940929.png" alt="image-20220908003940929" /><figcaption aria-hidden="true">image-20220908003940929</figcaption></figure><p>后续<em>Elsapy</em>将此<strong>query</strong>参数进行了封装。</p><figure><img src="./image-20220908004250354.png" alt="image-20220908004250354" /><figcaption aria-hidden="true">image-20220908004250354</figcaption></figure><p>API 返回结果的文档在此： <a href="https://dev.elsevier.com/guides/ScopusSearchViews.htm">Scopus Search Views</a></p><p>可惜不够尊贵，个人版的返回json中不包括abstract</p><figure><img src="./image-20220908005338776.png" alt="image-20220908005338776" /><figcaption aria-hidden="true">image-20220908005338776</figcaption></figure><p>实际返回项如下图：</p><p><img src="./image-20220908005405331.png" alt="image-20220908005405331" style="zoom:67%;" /></p><p>故我们需要使用<strong>prism:url</strong>进行abstract的提取。</p><p><img src="./image-20220908005443232.png" alt="image-20220908005443232" style="zoom:67%;" /></p></li><li><p><a href="https://dev.elsevier.com/documentation/AbstractRetrievalAPI.wadl">Abstract Retrieval API</a></p><p>用上述的<strong>prism:url</strong>做参数，调用Abstract Retrieval API就可以得到目标文章的摘要信息了。</p><figure><img src="./image-20220908005754680.png" alt="image-20220908005754680" /><figcaption aria-hidden="true">image-20220908005754680</figcaption></figure><p>返回的<a href="https://dev.elsevier.com/guides/AbstractRetrievalViews.htm">Abstract Retrieval Views</a>.链接在此，其中的<strong>dc:description</strong>即为我们所需的摘要，<strong>dc:title</strong>为标题。</p></li></ul><h2 id="elsapy-开发">2.3 Elsapy 开发</h2><p><em>Elsapy</em>使用<em>Requests</em>，封装了对Elsevier各个api访问的类及方法。不过其在Exception handling等方面很不完善。好在其本身代码简单，结构清晰，个人便对其做简单的定制。</p><ul><li><p>基本使用</p><ol type="1"><li><p>提供API-Key构建<code>ElsClient</code>对象，该对象负责向Elsevier发起请求；</p></li><li><p>再根据需求构建想访问的API的对象，如<code>ElsSearch</code>；</p></li><li><p>调用API对象的方法，进行访问。</p></li></ol><p>示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> elsapy.elsclient <span class="keyword">import</span> ElsClient</span><br><span class="line"><span class="keyword">from</span> elsapy.elssearch <span class="keyword">import</span> ElsSearch</span><br><span class="line"><span class="keyword">import</span> time </span><br><span class="line"></span><br><span class="line">query_str = <span class="string">&quot;your_query&quot;</span></span><br><span class="line">user_key = <span class="string">&#x27;your_key&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    client = ElsClient(user_key)</span><br><span class="line">    doc_src = ElsSearch(query_str, <span class="string">&#x27;scopus&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; Start crawling.\t Time: &quot;</span> + time.asctime())</span><br><span class="line">    doc_src.custom_execute(client, get_num=<span class="number">20000</span>, save_json=query_str+<span class="string">&quot;.json&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>改动</p><p>原本的<code>ElsSearch.execute</code>缺少异常处理，致使爬取中断。此外，我希望能指定爬取文章的数量，以及存储json的文件名。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">custom_execute</span>(<span class="params">self, els_client = <span class="literal">None</span>, get_num = <span class="literal">None</span>, get_all = <span class="literal">False</span>, save_json=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Executes the search. If get_all = False (default), this retrieves</span></span><br><span class="line"><span class="string">        the default number of results specified for the API. If</span></span><br><span class="line"><span class="string">        get_all = True, multiple API calls will be made to iteratively get </span></span><br><span class="line"><span class="string">        all results for the search, up to a maximum of 5,000.&quot;&quot;&quot;</span></span><br><span class="line">    api_response = els_client.exec_request(self._uri)</span><br><span class="line">    self._tot_num_res = <span class="built_in">int</span>(api_response[<span class="string">&#x27;search-results&#x27;</span>][<span class="string">&#x27;opensearch:totalResults&#x27;</span>])</span><br><span class="line">    self._results = api_response[<span class="string">&#x27;search-results&#x27;</span>][<span class="string">&#x27;entry&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> get_all <span class="keyword">is</span> <span class="literal">True</span> <span class="keyword">or</span> get_num <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> get_num <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:     </span><br><span class="line">            quota = get_num <span class="keyword">if</span> get_num &lt; self._tot_num_res <span class="keyword">else</span> self._tot_num_res</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            quota = self._tot_num_res</span><br><span class="line">  </span><br><span class="line">        failed_flag = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">while</span> self.num_res &lt; quota <span class="keyword">and</span> <span class="keyword">not</span> failed_flag:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&gt; Executing &#123;cur&#125; | &#123;total&#125;&quot;</span>.<span class="built_in">format</span>(cur = self.num_res, total = quota))</span><br><span class="line">            <span class="keyword">for</span> e <span class="keyword">in</span> api_response[<span class="string">&#x27;search-results&#x27;</span>][<span class="string">&#x27;link&#x27;</span>]:</span><br><span class="line">                <span class="keyword">if</span> e[<span class="string">&#x27;@ref&#x27;</span>] == <span class="string">&#x27;next&#x27;</span>:</span><br><span class="line">                    next_url = e[<span class="string">&#x27;@href&#x27;</span>]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>): <span class="comment"># if failed, retry up to 5 times</span></span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    api_response = els_client.exec_request(next_url)</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">except</span> RequestException <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="built_in">print</span>(e)</span><br><span class="line">                    <span class="keyword">if</span> i &lt; <span class="number">4</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; retry: &#123;t&#125; times&quot;</span>.<span class="built_in">format</span>(t= i + <span class="number">1</span>))</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; TASK FAILED. Save current results.&quot;</span>)</span><br><span class="line">                        failed_flag = <span class="literal">True</span></span><br><span class="line">  </span><br><span class="line">            self._results += api_response[<span class="string">&#x27;search-results&#x27;</span>][<span class="string">&#x27;entry&#x27;</span>]</span><br><span class="line">    name = save_json <span class="keyword">if</span> save_json <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="string">&#x27;dump.json&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(name, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(json.dumps(self._results))</span><br><span class="line">    self.results_df = recast_df(pd.DataFrame(self._results))</span><br></pre></td></tr></table></figure><p>此外，实际爬取过程中遇到 <code>ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接</code>问题。尽管原<code>ElsClient</code>已经按照Elsevier限定的每秒1次访问设定了interval，我仍在此基础上增加0.5s间隔，从而解决上述问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">time.sleep( self.__min_req_interval - interval + <span class="number">0.5</span> ) <span class="comment"># sleep 0.5 more second</span></span><br></pre></td></tr></table></figure><h2 id="完整代码">2.4 完整代码</h2></li><li><p>Scopus search</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> elsapy.elsclient <span class="keyword">import</span> ElsClient</span><br><span class="line"><span class="keyword">from</span> elsapy.elssearch <span class="keyword">import</span> ElsSearch</span><br><span class="line"><span class="keyword">import</span> time </span><br><span class="line"></span><br><span class="line">query_str = <span class="string">&quot;YOUR_QUERY&quot;</span></span><br><span class="line">user_key = <span class="string">&#x27;YOUR_KEY&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    client = ElsClient(user_key)</span><br><span class="line">    doc_src = ElsSearch(query_str, <span class="string">&#x27;scopus&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; Start crawling.\t Time: &quot;</span> + time.asctime())</span><br><span class="line">    doc_src.custom_execute(client, get_num=<span class="number">20000</span>, save_json=query_str+<span class="string">&quot;.json&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>Abstract retrieval</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> elsapy.elsclient <span class="keyword">import</span> ElsClient</span><br><span class="line"><span class="keyword">from</span> elsapy.elsdoc <span class="keyword">import</span> AbsDoc</span><br><span class="line"></span><br><span class="line">abs_field = <span class="string">&#x27;dc:description&#x27;</span></span><br><span class="line">title_field = <span class="string">&#x27;dc:title&#x27;</span></span><br><span class="line">publication_field = <span class="string">&#x27;prism:publicationName&#x27;</span></span><br><span class="line"></span><br><span class="line">user_key = <span class="string">&#x27;YOUR_KEY&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_json2pd</span>(<span class="params">file</span>):</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        data = json.load(f)</span><br><span class="line">    <span class="keyword">return</span> pd.json_normalize(data)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crawl_abstracts</span>(<span class="params">df, client</span>):</span></span><br><span class="line">    failed_list = []</span><br><span class="line">    abstracts = []</span><br><span class="line">    titles = []</span><br><span class="line">    publications = []</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; Start crawling.\t Time: &quot;</span> + time.asctime())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, url <span class="keyword">in</span> <span class="built_in">enumerate</span>(df[<span class="string">&#x27;prism:url&#x27;</span>]):</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&gt; Parsing &#123;cur&#125; / &#123;total&#125;&quot;</span>.<span class="built_in">format</span>(cur = i + <span class="number">1</span>, total = <span class="built_in">len</span>(df[<span class="string">&#x27;prism:url&#x27;</span>])))</span><br><span class="line">        abs_doc = AbsDoc(url)</span><br><span class="line">        rst = abs_doc.read(client)</span><br><span class="line">        <span class="keyword">if</span> rst:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                abstracts.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][abs_field])</span><br><span class="line">                titles.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][title_field])</span><br><span class="line">                publications.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][publication_field])</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&gt; &#123;cur&#125; - th failed.&quot;</span>.<span class="built_in">format</span>(cur = i + <span class="number">1</span>))</span><br><span class="line">            failed_list.append(url)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(failed_list) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&gt; Retry failed url...&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> failed_list:</span><br><span class="line">            abs_doc = AbsDoc(url)</span><br><span class="line">            <span class="keyword">if</span> abs_doc.read(client):</span><br><span class="line">                <span class="keyword">try</span>: </span><br><span class="line">                    abstracts.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][abs_field])</span><br><span class="line">                    titles.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][title_field])</span><br><span class="line">                    publications.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][publication_field])</span><br><span class="line">                <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Completed. Total crawled abstracts: &quot;</span>, <span class="built_in">len</span>(abstracts))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> titles, abstracts, publications</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    client = ElsClient(user_key)</span><br><span class="line">    json_file = <span class="string">&#x27;TITLE-ABS-KEY(inorganic compounds).json&#x27;</span></span><br><span class="line">    csv_path = json_file[:-<span class="number">5</span>] + <span class="string">&#x27;_2&#x27;</span> + <span class="string">&#x27;.csv&#x27;</span></span><br><span class="line"></span><br><span class="line">    df = load_json2pd(json_file)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 一点点来爬</span></span><br><span class="line">    cut_l, cut_r = <span class="number">1000</span>, <span class="number">5000</span></span><br><span class="line"></span><br><span class="line">    titles, abstracts, publications = crawl_abstracts(df[cut_l:cut_r], client) </span><br><span class="line">    abs_df = pd.concat([pd.DataFrame(titles),</span><br><span class="line">                        pd.DataFrame(abstracts),</span><br><span class="line">                        pd.DataFrame(publications)],</span><br><span class="line">                        axis=<span class="number">1</span>)</span><br><span class="line">    abs_df.to_csv(csv_path, header=<span class="literal">False</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h1 id="相关资料">3. 相关资料</h1><p>除上文中包含的链接外，</p><ul><li><p><a href="https://dev.elsevier.com/sc_search_tips.html">Scopus Search Guide</a></p><p>介绍所支持<strong>Query</strong>的关键词，表达式（基本上用户进行advanced search时的条件都可以实现）；</p></li><li><p><a href="https://dev.elsevier.com/api_key_settings.html">How much data can I retrieve with my APIKey?</a></p><p><img src="./image-20220908100750603.png" alt="image-20220908100750603" style="zoom:50%;" /></p></li><li><p><a href="https://dev.elsevier.com/support.html">Frequently Asked Questions</a></p><figure><img src="./image-20220908100837747.png" alt="image-20220908100837747" /><figcaption aria-hidden="true">image-20220908100837747</figcaption></figure></li></ul><h1 id="可优化点">4. 可优化点</h1><ul><li><p>多线程爬取</p><p>现在受制于Elsevier限制，每秒只能发送1次请求，导致爬虫龟速。或可申请多个API-Key，进行多线程爬取。</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;机缘巧合，需要帮朋友爬取些论文摘要。遂将任务探索过程及解决方案记录如下。&lt;/p&gt;
&lt;p&gt;初次接触Requests，代码较为稚嫩，多多包涵。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="工具人" scheme="http://example.com/categories/%E5%B7%A5%E5%85%B7%E4%BA%BA/"/>
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>MSL-18-声生不息</title>
    <link href="http://example.com/2022/07/10/MSL-18-%E5%A3%B0%E7%94%9F%E4%B8%8D%E6%81%AF/"/>
    <id>http://example.com/2022/07/10/MSL-18-%E5%A3%B0%E7%94%9F%E4%B8%8D%E6%81%AF/</id>
    <published>2022-07-10T15:56:29.000Z</published>
    <updated>2022-07-10T17:56:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>《声生不息》落下帷幕，第一次追完了一档芒果台综艺，此刻，应该记录下什么，评述些什么？</p><span id="more"></span><h2 id="听歌">听歌？</h2><p>发掘新歌手、听喜爱的歌者演绎旧曲当是置于首位的乐趣。</p><p>香港新生代Mike同Gigi，此前只略有耳闻，欣赏他们演绎后，被彻底征服；Hacken、千嬅的歌一直在我的歌单里，此回也算是追星成功；不曾想还能见到真声大魔王般的林子祥老师录制节目。</p><p>一个季度地录制，给予观众充分的时间了解各位歌手。仍记得初听第一期节目时，吐槽魔动闪霸等——不知道哪里抓出来的喽啰。现今，已发现他们各自的可爱之处、音乐上的造诣。</p><p>虽然一些曲目改编得过于华丽而失其本韵，仍有不少舞美与歌唱俱佳的作品产出。不是我过往随笔的风格，掉书袋一样进行罗列。不过随笔就该随心所欲吧，还是列一下印象中喜爱的舞台吧。</p><ul><li>《单车》 父子，车站，不知将远行或是总算相逢。结合Mike身世，不由就想起日常父子默然对视，心中思绪翻涌，却总是无言；</li><li>《红绿灯》大约总有个人，会隔着红绿灯的距离，待到绿灯亮起时，只能夹于人潮中在斑马线上擦身而过吧；</li><li>《灰姑娘》Mike唱出了浮夸的感觉；</li><li>《高山低谷》《勇》撇开情爱的纷纷扰扰，品味生活的五味吧。</li></ul><h2 id="小遗憾">小遗憾？</h2><p>广东歌这么多年，又怎能是一季节目，十几位歌手能回顾完的呢？</p><p>只是，陈胖子你的歌基本集集都被唱，人却一集都不来算什么。一边哭穷一边不出来营业也不发歌，上一首歌还是变成儿歌的《孤勇者》😢；Joey在内地却在另一个台陪着那些只知口水半吊子的假粤语歌《大风吹》的网红们又是什么情况🤦‍♂️；古Sir和Hins怕是和TVB关系不好也来不到现场？</p><p>虽然新歌实在太少，但选歌属于是众口难调，不必多言。</p><p>政治原因，两伟文，林夕千首填词的曲直接石沉海底，黄伟文填词的歌被翻唱，本人却不得出现在背景介绍中。不能说政治绝对凌驾于艺术，只是涉及民族、家国底线的原则，在公众传媒上不能含糊。</p><p>幸运的是仍能欣赏二位的作品，也愿家国能更自由、包容吧。</p><h2 id="生生不息">生生不息？</h2><p>要正视粤语的地位和历史。</p><p>靠着地理位置的优势，广东、港澳的经济才得以在近代腾飞；而由于中英的历史问题，香港特立独行地走了很长一段路。</p><p>粤语得以从一众方言中脱颖而出，在近代得到更多的发展和曝光。广东歌，更随着HK八九十年代特殊的经济地位，短暂披上黄金时代的外衣。</p><p>而今，该老实承认广东歌不再与繁华挂钩，慢慢成为音乐类别里一小小的按钮才是。</p><p>或许未来，是“不生不死”的。难再有过往那般火热的消费者市场，其能吸纳、养活的音乐人便有限。小众门类里，不离不弃的粤语爱好者们亦不会离去。</p><blockquote><p>香港歌手不會死</p><p>怎麼尖酸的你　那樣看不起</p><p>漠視　挖苦　比較</p><p>恥笑　指責　拋棄這一代</p><p>我請你不必再比</p><p>贈你這卡式機　聽返你舊時多優美</p></blockquote><hr /><p>有趣的是，周末来到武汉的猫咖，老板一直放着声生不息的歌单，吵着不让我午睡——听到就忍不住跟着哼唱。在武汉咖啡馆里听广东歌，一听一下午，巴适。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;《声生不息》落下帷幕，第一次追完了一档芒果台综艺，此刻，应该记录下什么，评述些什么？&lt;/p&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
  </entry>
  
  <entry>
    <title>MSL-17-多安的岛</title>
    <link href="http://example.com/2022/06/22/MSL-17-%E5%A4%9A%E5%AE%89%E7%9A%84%E5%B2%9B/"/>
    <id>http://example.com/2022/06/22/MSL-17-%E5%A4%9A%E5%AE%89%E7%9A%84%E5%B2%9B/</id>
    <published>2022-06-22T03:43:51.000Z</published>
    <updated>2022-06-22T03:43:51.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>孤岛生存，非桃花源，而是片刻的幻梦。抛开高达繁重的设定、历史，不失为佳作。</p></blockquote><hr /><p>久违了啊，高达的新剧场版。</p><span id="more"></span><p><img src="./image-20220622113823158.png" alt="image-20220622113823158" style="zoom:33%;" /></p><p>历史的脚注总是简短而片面。哪怕留名者，大多也就寥寥数句记录其官衔军功。其人真实的生命历程，种种细节不可追。借助段段OVA或剧场版展开，延申多些许人物的弧光，实是幸事。</p><p>看到本片里坚毅的塞拉，不由忆起《GTO》中她幼年时所一路闯过的磨难；留下“北宋的壶，这可是好东西啊”名梗的马·克贝上校，除善谋权术数，亦是真切地心系地球文化——作战失败时的大笑怕是一种释怀吧。</p><p><img src="./image-20220622012934111.png" alt="image-20220622012934111" style="zoom: 33%;" /></p><p>以及，库库鲁斯·多安。</p><p>哪怕是没看过0079的人，但凡接触过高达相关的游戏，都会记得有个格斗专精、会扔石头的扎古Ⅱ，往往戏称驾驶员为石头哥，却不知其人经历。得以此番，略睹多安的人生碎片。</p><p>小队内战的片段，虽然久违的机战动作镜头激起多巴胺的刺激，反倒最令人感到沉重。多安是谁，追溯他过往MS出击的履历，是技术高超乃至坊间评价堪比“赤色彗星”的ACE，却也是驾驶扎古试图逃离战场的人。于是，来袭的原小队里，有视其为叛徒，咬牙切齿要歼灭多安的递补队长；有慕名而来的挑战者；还有暗生情愫却未能理解多安远走缘由的队员。所驾驶的绿扎已然破旧，却仍无言挥舞仅剩的热能斧，击破来者。</p><p><img src="./image-20220622111003227.png" alt="image-20220622111003227" style="zoom:33%;" /></p><p>斩杀的可是曾经的战友——一同出生入死，将后背交由其保护的战友。他会在想些什么？兵戎相见、刀剑相交之间，没留下互述苦衷的时空。捍卫这弹丸小岛，保护孩子们以赎罪，是多安唯一踏入驾驶舱的理由了吧。多安或许会选择什么都不再想了吧。从战场脱逃的战争机器，只会延续机械的迎战。</p><p>阿姆罗最后毁掉多安的扎古，算是将多安从杀人机器中解脱出来。</p><p><img src="./image-20220622113008083.png" alt="image-20220622113008083" style="zoom:33%;" /></p><p>算是happy ending了吧，核弹被摧毁，小岛彻底失去战略价值，多安岛的和平能延续多些时日。</p><p>但转念又觉得唏嘘，联邦的“白色恶魔”阿姆罗，往后宿命仍与战争绑定，直到推着阿克西斯消失在银河彼端的那天。</p><hr /><p>专属于高达的槽点不少：</p><ul><li><p>财团为了卖模型不择手段啊，强行插入10秒高机动型红扎广告片段；</p><p><img src="./image-20220622113922357.png" alt="image-20220622113922357" style="zoom:25%;" /></p></li><li><p>重制“我爸爸也没有打过我”，好评；</p><p><img src="./image-20220622114220005.png" alt="image-20220622114220005" style="zoom:25%;" /></p></li><li><p>阿姆罗不愧白色恶魔，上来就捅驾驶舱，从不手软。</p><p><img src="胡扯.assets/image-20220622114048397.png" alt="image-20220622114048397" style="zoom:25%;" /></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;孤岛生存，非桃花源，而是片刻的幻梦。抛开高达繁重的设定、历史，不失为佳作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;p&gt;久违了啊，高达的新剧场版。&lt;/p&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
  </entry>
  
  <entry>
    <title>BOOK-08-蛤蟆先生去看心理医生</title>
    <link href="http://example.com/2022/06/09/BOOK-08-%E8%9B%A4%E8%9F%86%E5%85%88%E7%94%9F%E5%8E%BB%E7%9C%8B%E5%BF%83%E7%90%86%E5%8C%BB%E7%94%9F/"/>
    <id>http://example.com/2022/06/09/BOOK-08-%E8%9B%A4%E8%9F%86%E5%85%88%E7%94%9F%E5%8E%BB%E7%9C%8B%E5%BF%83%E7%90%86%E5%8C%BB%E7%94%9F/</id>
    <published>2022-06-09T03:43:52.000Z</published>
    <updated>2022-06-09T03:43:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>把问题留在这里，时时回顾思索吧。</p><span id="more"></span><blockquote><ul><li>“心理咨询向来是一个自发的过程，咨询师和来访者双方都得出于自愿。所以这就意味着，只有当你是为自己而不是为取悦朋友们才想咨询的时候，我们才能真正合作。</li><li>如果你要更好地理解自己，就需要跟自己的情绪做联结，并理解这些情绪。如果你否认它们，不论是用无视还是压抑的方式，结果都像是做了截肢，就如身体的重要部位被切掉了一样，你在某种程度上成了一个残缺的人。</li><li>能帮你的人是你自己，也只有你自己。有许多问题需要你向自己发问。比如你能停止自我批判吗？你能对自己好一些吗？也许最重要的问题是，你能开始爱自己吗？</li><li>如果你为自己负责，就会认识到你对自己是有自主权的。因此你就知道自己有力量来改变处境，更重要的是，有力量改变你自己。</li><li>第一个问题是 我是怎么看自己的？我好吗？第二个问题是：我是怎么看别人的？他们好吗？</li><li>一旦我们在童年决定用哪种态度和观点，我们就会在随后的人生里始终坚持自己的选择。这些态度和观点，变成我们存在的底层架构。从那以后，我们便建构出一个世界，不断确认和支持这些信念和个预期。换一个词来说，我们把自己的人生变成了一个’自证预言'。</li><li>有些人会竭尽所能地选择记住那些悲伤和不快乐的事件，而忘记或忽略美好的时光。这种活法看起来很容易让人抑郁。</li><li>我觉得我比过去更能顺应生活了。可我不会忘记自己曾经是那么消沉，那段记忆会永远留在那儿，或许就是对我的提醒，告诉我，<strong>滑落到生活边缘的人生</strong>是什么样的。</li><li>人们太容易让重要的事件就这么过去，忘记关注或为它们庆祝，也许是因为我们通常都只在事后才明白它们有多重要。</li></ul></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;把问题留在这里，时时回顾思索吧。&lt;/p&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="书单" scheme="http://example.com/tags/%E4%B9%A6%E5%8D%95/"/>
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>GNN-GATv2</title>
    <link href="http://example.com/2022/05/20/GNN-GATv2/"/>
    <id>http://example.com/2022/05/20/GNN-GATv2/</id>
    <published>2022-05-20T06:44:17.000Z</published>
    <updated>2022-05-20T06:44:17.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="论文笔记how-attentive-are-graph-attention-networks">论文笔记：HOW ATTENTIVE ARE GRAPH ATTENTION NETWORKS?</h1><blockquote><p>PDF: https://openreview.net/pdf?id=F72ximsx7C1</p><p>OpenReview：https://openreview.net/forum?id=F72ximsx7C1</p><p>ICLR 2022</p></blockquote><h2 id="abstract">1. Abstract</h2><p>认为GAT是static attention，仅实现了对节点重要度的静态ranking，而未实现对不同query给出不同key的设想；提出GATv2，通过调整LeakyReLU和linear unit计算顺序，实现dynamic attention，即对不同query能给出不同key。</p><span id="more"></span><h2 id="motivations">2. Motivations</h2><p>GAT已成为图神经网络发展历程中的标志性架构，但本文观察发现，GAT的attention对于相同的keys实现的其实是ranking。</p><p>假设有如下二部图，求解 <em>Dictionary Lookup</em> 问题：</p><p><img src="./gatv2_01.png" style="zoom:67%;" /></p><p>使用GAT所得的attention scores如下：</p><p><img src="./gatv2_02.png" style="zoom:38%;" /></p><p>可以看到，对于不同的query，key的scores排序实际是一样的（<strong>静态</strong>的）。这限制了GAT的表达能力。</p><p>而本文认为，attention的初衷应该是：给定不同的query，能找到不同的key（即不同query，ranking结果应该不同，<strong>动态</strong>的）。</p><h2 id="method">3. Method</h2><h3 id="definitions">3.1 Definitions</h3><p>注意力机制其实是求解给定query时keys的注意力得分分布。</p><ul><li><p><strong>Static Attention</strong></p><p>设有计算注意力得分的函数族<span class="math inline">\(\mathcal{F}\)</span>, 对于任意 <span class="math inline">\(f \in \mathcal{F}\)</span>，给出 key <span class="math inline">\(\mathbb{K}=\left\{\boldsymbol{k}_{1}, \ldots, \boldsymbol{k}_{n}\right\} \subset \mathbb{R}^{d}\)</span> 和 query <span class="math inline">\(\mathbb{Q}=\left\{\boldsymbol{q}_{1}, \ldots, \boldsymbol{q}_{m}\right\} \subset \mathbb{R}^{d}\)</span>，若存在一个“得分最高”的 key <span class="math inline">\(k_{j_f}\)</span> 使得 <span class="math inline">\(f\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{j_{f}}\right) \geq f\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{j}\right)\)</span>，则称 <span class="math inline">\(\mathcal{F}\)</span> 为静态注意力；</p></li><li><p><strong>Dynamic Attention</strong></p><p>设有计算注意力得分的函数族<span class="math inline">\(\mathcal{F}\)</span>, <span class="math inline">\(f \in \mathcal{F}\)</span>，给出 key <span class="math inline">\(\mathbb{K}=\left\{\boldsymbol{k}_{1}, \ldots, \boldsymbol{k}_{n}\right\} \subset \mathbb{R}^{d}\)</span> 和 query <span class="math inline">\(\mathbb{Q}=\left\{\boldsymbol{q}_{1}, \ldots, \boldsymbol{q}_{m}\right\} \subset \mathbb{R}^{d}\)</span>，对于任意的映射 <span class="math inline">\(\varphi:[m] \rightarrow[n]\)</span>，存在 <span class="math inline">\(f \in \mathcal{F}\)</span>，使任意的 query 及任意的 key <span class="math inline">\(j_{\neq \varphi(i)} \in[n]\)</span>，有<span class="math inline">\(f\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{\varphi(i)}\right)&gt;f\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{j}\right)\)</span>，则称 <span class="math inline">\(\mathcal{F}\)</span> 为动态注意力。</p></li></ul><h2 id="gat有限的表达能力及修正">3.2 GAT有限的表达能力及修正</h2><ul><li><p><strong>GAT 分析</strong></p><p>首先回顾GAT中attention score计算方式，有： <span class="math display">\[e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j}\right)=\text { LeakyReLU }\left(\boldsymbol{a}^{\top} \cdot\left[\boldsymbol{W} \boldsymbol{h}_{i} \| \boldsymbol{W} \boldsymbol{h}_{j}\right]\right)\]</span></p><p><span class="math display">\[\alpha_{i j}=\operatorname{softmax}_{j}\left(e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j}\right)\right)=\frac{\exp \left(e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j}\right)\right)}{\sum_{j^{\prime} \in \mathcal{N}_{i}} \exp \left(e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j^{\prime}}\right)\right)}\]</span></p><p>对于式子(1)，我们令 <span class="math inline">\(\boldsymbol{a}=\left[\boldsymbol{a}_{1} \| \boldsymbol{a}_{2}\right] \in \mathbb{R}^{2 d^{\prime}}\)</span>，可得： <span class="math display">\[e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j}\right)=\text { LeakyReLU }\left(\boldsymbol{a}_{1}^{\top} \boldsymbol{W} \boldsymbol{h}_{i}+\boldsymbol{a}_{2}^{\top} \boldsymbol{W} \boldsymbol{h}_{j}\right)\]</span> 可以发现，对于有限的节点集合 <span class="math inline">\(\mathcal{V}\)</span>，存在一个节点 <span class="math inline">\(j_{max}\)</span>，使 <span class="math inline">\(\boldsymbol{a}_{2}^{\top} \boldsymbol{W} \boldsymbol{h}_{j_{max}}\)</span> 最大，即GAT计算的为 <em>static attention</em>。节点重要程度排序是确定的，和 query node 无关。Query node 只能影响注意力得分分布的 "sharpeness"。</p><blockquote><p>关于 <strong>multi-head</strong> ：上述结论对每个head仍适用，只是每个head的 <span class="math inline">\(j_{max}\)</span> 节点未必相同。</p></blockquote></li><li><p><strong>改进</strong></p><p>本文核心内容，将 <span class="math inline">\(\boldsymbol{a}\)</span> 移动到非线性激活外，使GAT成为 <em>dynamic attention</em>。</p><p><img src="./gatv2_03.png" /></p><p>证明较长，见文章appendix。</p></li></ul><h2 id="exp">4. Exp</h2><ul><li><em>Dictionary Lookup</em></li></ul><p>对于上文中二部图问题，使用改进后的GAT能有效实现<em>dynamic attention</em>。</p><p><img src="./gatv2_04.png" style="zoom:50%;" /></p><ul><li><p>Robustness to Noise</p><p>本文发现<em>dynamic attention</em>能更好抵抗噪声（不过没有进一步分析原因）。</p><p><img src="./gatv2_05.png" style="zoom:38%;" /></p></li><li><p>Node / Graph / Link Prediction</p><p><img src="./gatv2_06.png" style="zoom:50%;" /></p><p><img src="./gatv2_07.png" style="zoom:50%;" /></p><p><img src="./gatv2_08.png" style="zoom:50%;" /></p><p>值得注意的是，节点预测中 单头的 GATv2 在两个数据集上有更佳表现。作者解释为单头的GATv2已经有足够的表达能力，使用8头时反而由于过强的表达能力，遭遇了过拟合。</p></li></ul><h2 id="其他">其他</h2><p>twitter和openreview上的讨论很有意思，截取一些在此。</p><ul><li><p>GAT原作者</p><p><img src="./gatv2_09.png" style="zoom:38%;" /></p></li><li><p>关于GATv1, v2表达能力与参数数量的讨论 (二者参数数量相同，表达能力不同)</p><p><img src="./gatv2_10.png" style="zoom:50%;" /></p></li><li><p>作者关于 <em>dynamic attention</em> 的思考</p><p><img src="./gatv2_11.png" /></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;论文笔记how-attentive-are-graph-attention-networks&quot;&gt;论文笔记：HOW ATTENTIVE ARE GRAPH ATTENTION NETWORKS?&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;PDF: https://openreview.net/pdf?id=F72ximsx7C1&lt;/p&gt;
&lt;p&gt;OpenReview：https://openreview.net/forum?id=F72ximsx7C1&lt;/p&gt;
&lt;p&gt;ICLR 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;abstract&quot;&gt;1. Abstract&lt;/h2&gt;
&lt;p&gt;认为GAT是static attention，仅实现了对节点重要度的静态ranking，而未实现对不同query给出不同key的设想；提出GATv2，通过调整LeakyReLU和linear unit计算顺序，实现dynamic attention，即对不同query能给出不同key。&lt;/p&gt;</summary>
    
    
    
    <category term="论文笔记" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="图神经网络" scheme="http://example.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    <category term="图表示学习" scheme="http://example.com/tags/%E5%9B%BE%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>BOOK-07-工作消费主义和新穷人</title>
    <link href="http://example.com/2022/03/25/BOOK-07-%E5%B7%A5%E4%BD%9C%E6%B6%88%E8%B4%B9%E4%B8%BB%E4%B9%89%E5%92%8C%E6%96%B0%E7%A9%B7%E4%BA%BA/"/>
    <id>http://example.com/2022/03/25/BOOK-07-%E5%B7%A5%E4%BD%9C%E6%B6%88%E8%B4%B9%E4%B8%BB%E4%B9%89%E5%92%8C%E6%96%B0%E7%A9%B7%E4%BA%BA/</id>
    <published>2022-03-25T02:37:54.000Z</published>
    <updated>2022-03-25T02:37:54.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>武汉夜雨狂泻，狂躁的雨滴砸落地面。哦不，该称之为水面了。持续一日的雨水，在柏油路上新铺一层水面。</p><p>听闻“麻豆传媒”的一个摄影团队被抓获，翻看知乎里对事件的评价，产业链的介绍、情色作品的科普。总是会错过些“艺术”，错过了汤不热时代，一如曾经错过了快播的便捷。</p><p>如今，大约大部分人已是<strong>笑贫不笑娼</strong>了。</p></blockquote><span id="more"></span><p>一直提醒自己用发展的眼光观察、评析事物，却不时忘记亦要时常回顾历史，看看我们是如何一步步走成今天的道路。</p><ul><li>关于劳动</li></ul><p>这本书，回顾随生产力进步与社会发展的需要，人们如何一步步丢失职业自豪，被塑造成机械化的部件，进而一步步被挖去朴素的道德，被灌输用不断的消费来填充自己.</p><blockquote><p>越来越多的人认为，从工匠变成工人时失去的人的尊严，只有通过赢得更多盈余才能恢复。这种变迁中，努力工作能使人们道德升华的呼声日益衰弱。现在，衡量人们声望和社会地位的是工资的差别，而不是勤于工作的道德或惰于工作的罪恶。</p></blockquote><ul><li>关于穷人</li></ul><p>同时，还残酷地揭露着某些国家对穷人的“污名化”——生产力进步不再需要本国劳工时，穷人不再是失业，而是单纯的<strong>过剩</strong>人口。</p><blockquote><p>“失业者”虽然暂时没有工作，但一旦环境好转，他们就有望回到“生产者”的行列，一切也将回到正轨。“过剩”的人则不同，他们是多余的、编外的，不被需要。他们要么出生在一个“饱和”的社会里（即社会的续存无需更多的人从事生产），要么由于经济和技术进步（即有了新的生产力，较少的人员参与就能满足日益增长的商品和服务需求），变得不再必要。</p></blockquote><p>过剩的穷人开始背负各种污蔑，成为各种社会负面情绪转嫁的出口。媒体不断吹风造势，让大众逐渐接受人穷必是其自身有罪过，合理化对穷人的冷漠。以至于确实能见到身边有人，抱着书中所提态度：</p><blockquote><p>他们确实有一个共同点：在其他人看来，他们没有存在的必要，正是因为完全无用才会被归入社会底层——若他们消失，其他人会生活得更好。他们无疑是美丽风景线中的污渍，是丑陋又贪婪的杂草，他们对园林的和谐之美没有任何贡献，还偷走了其他植物的养分。如果他们消失，所有人都会获益。</p></blockquote><p>这般冷漠蔓延，剩下保有对生命基本尊重与对人类良知的人将如《狂人日记》中一般，道“我疯了”吧。</p><p>穷人们真是那般懒散罪恶吗，更多时候只是他们的故事被改写，从<strong>被剥夺</strong>的故事被叙述为自甘堕落的故事。</p><ul><li>关于消费</li></ul><blockquote><p>如果消费是衡量成功人生的标准，衡量幸福的标准，甚至是衡量尊严的标准，那么人类欲望的潘多拉之盒已经打开，再多的购买和刺激的感觉，都不能唤回过去“达到标准”带来的满足感：现在根本就没有标准可言。终点线和参赛者一起前行，人们力图到达的目标永远领先一步之遥。</p></blockquote><p>为人嘛，求给自己立下标准，反抗下动物性的欲望吧。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;武汉夜雨狂泻，狂躁的雨滴砸落地面。哦不，该称之为水面了。持续一日的雨水，在柏油路上新铺一层水面。&lt;/p&gt;
&lt;p&gt;听闻“麻豆传媒”的一个摄影团队被抓获，翻看知乎里对事件的评价，产业链的介绍、情色作品的科普。总是会错过些“艺术”，错过了汤不热时代，一如曾经错过了快播的便捷。&lt;/p&gt;
&lt;p&gt;如今，大约大部分人已是&lt;strong&gt;笑贫不笑娼&lt;/strong&gt;了。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="书单" scheme="http://example.com/tags/%E4%B9%A6%E5%8D%95/"/>
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>FLAG2022-1-阅读书单</title>
    <link href="http://example.com/2022/01/09/FLAG2022-1-%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95/"/>
    <id>http://example.com/2022/01/09/FLAG2022-1-%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95/</id>
    <published>2022-01-09T09:37:14.000Z</published>
    <updated>2022-11-23T12:55:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>2021年分明是较为清闲的一年，看得书却是近年来最少的一年。2022已至，决心在开年时列出今年的书单，年末再回首自己的完成情况吧。</p><p>不高估自己，且算每月两本，一年读<strong>24本</strong>已是小小的进步。闲时阅读，求广不求精，愿能涉猎各科，览阅人事。未必每本都有触动，暂且约定每读一本，于此留下至少百来字随感，若有触动，便是继续细书随笔吧。</p><p>2022，许愿：<strong>无畏，求知</strong>。</p><span id="more"></span><h1 id="书单1525">书单(15/25)</h1><h2 id="历史">历史</h2><ul class="task-list"><li><input type="checkbox" disabled="" />《<a href="https://book.douban.com/subject/24316346/">美帝国的崩溃 : 过去、现在与未来</a>》</li><li><input type="checkbox" disabled="" />《<a href="https://book.douban.com/subject/34869500/">被统治的艺术</a>》</li><li><input type="checkbox" disabled="" checked="" />《<a href="https://book.douban.com/subject/3580750/">潜规则</a>》</li></ul><blockquote><p>出门上班，满眼小商小贩雇主雇员，下班上路，到处是行色匆匆的路人和讨价还价的顾客。想叫一声同志，招呼一声兄弟，真不知冲谁开口。</p></blockquote><p>不曾想，现时常用的“潜规则”一词，居然源自此书。</p><p>能直视现实里潜在运行的规则，约莫是放下书生意气的理想年华，行到经世为人识相的标志吧。</p><p>有史以来，有人群居处，自有不便置于台面的规则运行，或遵循，或抗拒，或自立新规。</p><h2 id="经管">经管</h2><ul class="task-list"><li><input type="checkbox" disabled="" />《<a href="https://book.douban.com/subject/5346110/">穷查理宝典</a>》</li><li><input type="checkbox" disabled="" checked="" />《<a href="https://book.douban.com/subject/21331443/">中国是部金融史 : 透过金融读懂中国三千年</a>》</li><li><input type="checkbox" disabled="" checked="" />《<a href="https://book.douban.com/subject/10773362/">随机漫步的傻瓜 : 发现市场和人生中的隐藏机遇</a>》</li></ul><blockquote><ul><li>记者那一行中还是有不少懂得深思熟虑的人，只是主流媒体新闻依然不动大脑，只顾提供引人注意的噪声，而且没有什么机制能够区分两者。事实上，聪明的新闻记者反而遭到了惩罚。</li><li>投资人基于情感因素，采取的策略也会让他们偶尔才承受波动，但只要一有波动，幅度都很大。这叫做掩耳盗铃，把随机性塞到地毯底下。</li><li>“看好”或“看坏”这两个名词，是不必在不确定性状况下做事的人，例如电视评论员，或没有处理风险经验的人使用的。投资人和企业要赚的不是概率，而是白花花的钞票。因此对他们来说，某个事件发生的可能性多大并不重要，重要的是那件事发生时能赚多少钱。利润出现的频率有多高并不重要，结果多少才重要。</li></ul></blockquote><p>明辨噪音与真正的信息，意识到生活中的随机性，对事物不只考虑其发生概率更应计算其收益的<strong>期望</strong>。 知易行难。</p><h2 id="社会">社会</h2><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />《<a href="https://book.douban.com/subject/21966353/">贫穷的本质</a>》</li></ul><blockquote><p>贫穷并不仅仅意味着缺钱，它会使人丧失挖掘自身潜力的能力。</p></blockquote><p>人们生来并无无可跨越的差异，但贫富差异导致了人成长后彻头彻尾的分化。贫富差异下最大的差异之一，便是信息差。</p><blockquote><p>我们应该认识到，谁也没有那么明智、耐心或博学到能够为自己的健康做出正确的决定。同样，对于那些生活在富裕国家的人来说，他们周围充满了<strong>无形的助推力</strong>。</p></blockquote><p>贫穷存在陷阱，同样的才智，穷人不知道如何得到更廉价的贷款、更高营养的食物、无法计算投资教育的收益，视野只局限于对周身环境的认知——不止穷人，你我也是如此。穷人往往选择尽可能多的生育，反映的是他们的智慧。利用已知信息和家庭资源，养育更多子女才可能获得更高收益。</p><p>不过书中种种的实验表明，我们并非全然无能为力。一点点小的指点信息、微小的资金输入和政策扶持等，都能敲下阻隔阶级的厚墙上的砖头。</p><ul class="task-list"><li><input type="checkbox" disabled="" />《社会学的想象力》</li><li><input type="checkbox" disabled="" checked="" />《<a href="https://book.douban.com/subject/35593780/">工作、消费主义和新穷人</a>》</li></ul><p>见《BOOK-07-工作消费主义和新穷人》</p><ul class="task-list"><li><input type="checkbox" disabled="" />《失控》</li></ul><h2 id="cs">CS</h2><ul class="task-list"><li><input type="checkbox" disabled="" />《<a href="https://book.douban.com/subject/35084616/">隐私简史</a>》</li><li><input type="checkbox" disabled="" checked="" />《史蒂夫·乔布斯传》</li><li><input type="checkbox" disabled="" checked="" />《<a href="https://book.douban.com/subject/26297606/">从0到1 : 开启商业与未来的秘密</a>》</li></ul><p><strong>大胆尝试胜过平庸保守</strong>。且行且思。</p><p>摘录一些句子吧：</p><blockquote><ul><li>一旦你认为自己在抽奖，你就已经做好了亏损的心理准备。</li><li>创立公司前，能否回答下列七个问题：<ol type="1"><li>工程问题： 你的技术具有突破性，而不仅仅是稍有改进吗？</li><li>时机问题： 现在开创事业，时机合适吗？</li><li>垄断问题： 开创之初，是在一个小市场抢占大份额吗？</li><li>人员问题： 你有合适的团队吗？</li><li>销售问题： 除了创造产品，你有没有办法销售产品？</li><li>持久问题： 未来10年或20年，你能保住自己的市场地位吗？</li><li>秘密问题： 你有没有找到一个其他人没有发现的独特机会？</li></ol></li></ul></blockquote><ul class="task-list"><li><input type="checkbox" disabled="" />《<a href="https://book.douban.com/subject/35641088/">计算之魂 : 计算科学品位和认知进阶</a>》</li><li><input type="checkbox" disabled="" />《程序员修炼之道（第2版）》</li><li><input type="checkbox" disabled="" />《<a href="https://book.douban.com/subject/25930025/">只是为了好玩 : Linux之父林纳斯自传</a>》</li><li><input type="checkbox" disabled="" />《数据科学家访谈录》</li><li><input type="checkbox" disabled="" checked="" /><a href="https://book.douban.com/subject/22993903/">《区块链：从数字货币到信用社会》</a></li></ul><blockquote><p>在区块链的信用评价中，信用其实是一个数学问题。</p></blockquote><p><img src="./区块链从数字货币到信用社会.png" /></p><p>出于了解web3技术基础的需求，略读此书。前三章生动入微，后续章节务虚难解。</p><p>区块链技术为互联网中的信息赋予了绑定在数据本身上的价值。然而该价值如何和现实社会桥接，仍有一段长路要走。</p><p>文中有段对比甚是有趣，摘录如下：“如果说印刷机的意义就在于将信息资源抽离物理世界的束缚，变为一种非竞争性资源，区块链则是起着与印刷机截然相反的作用，<strong>它以处理竞争性资源的方式来处理信息资源（非竞争性）</strong>，人们可以摆脱对可信第三方的依赖，在数字世界中自由地交换数字货币、知识产权、股权甚至不动产所有权。虽然两者处理资源的方式是相反的，但两者对话语结构的改变是一致的。”</p><h2 id="休闲">休闲</h2><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />《<a href="https://book.douban.com/subject/30243002/">食物与科学的美味邂逅</a>》</li></ul><p>高开低走的一本书，开篇吊足胃口后发现更多是稳固高中理化生知识，佐以一些生活例子为延展。</p><p>倒也没错，料理的科学本就不是高高在上的。</p><p>书中不少有趣的科普或故事：</p><ul><li>居然有人（埃尔韦·蒂斯）使用“食材状态（gas/water/etc.）+分子活动的状态（分散/并存/包含/复层）”来描述料理，饶是有趣。不仅给出新的分类体系，还为料理的创新提供了新路数——替换公式中的项；</li><li><em>食物搭配学</em>居然是门新兴学科，https://www.foodpairing.com/ 👈还存在着这样的食物搭配数据库；</li><li>高压锅已经走入我们的生活了，但<strong>超高压</strong>有更多料理的想象空间——通过超高压把食品的分子挤压为高密度的状态，致使分子发生物理性变化。比如，带壳的生鸡蛋在6500个静水压力的影响下，保留了生蛋的风味，蛋黄、蛋白却“凝固”成水煮蛋的状态。</li></ul><blockquote><p>但美味并不存在于食物本身，只有在食用者的大脑接收到美味信息时才会产生美味。因此，考虑食用者如何感受这道菜品，与考虑精选食物用料、严格按照食谱烹制食物时同等重要的。</p></blockquote><p>​ 所以，做好吃的料理，要让食物、环境、氛围，都传递出爱意呀。</p><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />《贪婪的多巴胺》</li></ul><blockquote><p>多巴胺追求更多，而不是追求道德；对多巴胺来说，武力和欺诈只不过是达成目的的工具。</p></blockquote><p>科普小品文，助人了解行为背后哦的生化动机。</p><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />《质数的孤独》</li></ul><blockquote><p>质数只能被一和它自身整除。在自然数的无穷序列中它们处于自己的位置上，和其他所有数字一样被前后两个数字挤着。但它们彼此间的距离却比其他数字更远一步。它们是多疑而又孤独的数字。</p></blockquote><p>难得感性起来——一旦开始阅读，仿佛被黑洞吞噬般卷入那孤寂中。</p><p>书中马蒂亚与身边人的距离，是非连续的，在0到某个或许无穷小的实数间，有个无法跨越的距离。</p><p>没有他那般数学天赋，却莫名的想起在武汉的那些孤寂时刻，是那种，被孤寂漫灌，浓稠的黑泥直钻鼻孔，附着在每寸皮肤，无法呼吸的感觉。</p><p>瑟缩在床上，床单的褶皱似鬼脸无情的嘲笑；反复的键入又删除，方块字规整依旧，却永无那笔下所描绘的质感；雨夜、酷暑、寒冬、湿热，相同点在于眼镜总是看不清楚。</p><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />《突然，响起一阵敲门声》</li></ul><p>很迅速在偷闲中看完了，很遗憾只偷闲了一周。本想作为睡前读物，每日小看一篇。却是在看完后哭笑不得，总忍不住再续上一篇。 尤其爱《其实，我最近勃起过两次，硬得就像根金刚棒》。虽然仍是年轻，却总觉自己的宝贝将要一蹶不振。没有晨勃的日子里，会有什么能让人金鸡独立呢？</p><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />《蛤蟆先生去看心理医生》</li></ul><blockquote><p>身处情绪的特殊时期看此书，像是借蛤蟆这一傀儡，去面见了心理医生一般。</p></blockquote><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />《乡村教师》</li></ul><blockquote><p>「上尉，你是个白痴吗？！」舰队统帅大怒，「你是想告诉我们，一种没有记忆遗传，相互间用声波进行信息交流，并且是以令人难以置信的每秒１至１０比特的速率进行交流的物种，能创造出５Ｂ级文明？！而且这种文明是在没有任何外部高级文明培植的情况下自行进化的？！」</p></blockquote><p>被大刘强行拉到星际文明的智慧高度来审视我们星球的文明，才意识到我们获取知识的方式那么缓慢低效。人类，便是这样迟缓却生生不息的进步着。</p><ul class="task-list"><li><input type="checkbox" disabled="" checked="" /><a href="https://book.douban.com/subject/35710421/">《老妓抄》</a></li></ul><blockquote><p>肿瘤上歪曲的独眼，像是在瞪视人间、嘲笑人间一般，看起来反而更具有深邃意义。这张冷眼旁观人生不如意与悲欢无常的人脸上，根本已经没有必要再添加任何一笔了。</p></blockquote><p>久违的日本文学，抚慰我囚禁于疫情荒诞防控下阴暗的灵魂。可以一无所成，但请珍惜自己所有的，如《花束般的恋爱》中所述——看少年漫画仍能痛哭流涕的稚气。</p><p>上述，无关此书，只是借机感叹罢了。因为所谓的疫情，只求活着的话，活着本事实在是无趣呢。</p><hr /><p>再加点bonus项吧，不求参透，不知道2022年能读多少呢。</p><ul class="task-list"><li><input type="checkbox" disabled="" />《毛选》</li><li><input type="checkbox" disabled="" />《资本论》</li><li><input type="checkbox" disabled="" />《史记》</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;2021年分明是较为清闲的一年，看得书却是近年来最少的一年。2022已至，决心在开年时列出今年的书单，年末再回首自己的完成情况吧。&lt;/p&gt;
&lt;p&gt;不高估自己，且算每月两本，一年读&lt;strong&gt;24本&lt;/strong&gt;已是小小的进步。闲时阅读，求广不求精，愿能涉猎各科，览阅人事。未必每本都有触动，暂且约定每读一本，于此留下至少百来字随感，若有触动，便是继续细书随笔吧。&lt;/p&gt;
&lt;p&gt;2022，许愿：&lt;strong&gt;无畏，求知&lt;/strong&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="生活" scheme="http://example.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="书单" scheme="http://example.com/tags/%E4%B9%A6%E5%8D%95/"/>
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
    <category term="打卡" scheme="http://example.com/tags/%E6%89%93%E5%8D%A1/"/>
    
  </entry>
  
  <entry>
    <title>MSL-16-匆匆2021又一年</title>
    <link href="http://example.com/2021/12/28/MSL-16-%E5%8C%86%E5%8C%862021%E5%8F%88%E4%B8%80%E5%B9%B4/"/>
    <id>http://example.com/2021/12/28/MSL-16-%E5%8C%86%E5%8C%862021%E5%8F%88%E4%B8%80%E5%B9%B4/</id>
    <published>2021-12-28T12:35:25.000Z</published>
    <updated>2022-01-01T03:25:38.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>总算考完一门硬核的试，抢下些许喘息时间。不知不觉年关又至，流水账般收集下今年尚能想起的记忆碎片吧。</p><p>试图手动统计些数据，量化将逝的2021。要是有时间，或许再来做点好看的可视化吧。</p></blockquote><span id="more"></span><h1 id="输出">1. 输出</h1><p>2020年彻底抛弃了个人公众号，扼住自己的咽喉，不再发声。2021年，换了这个私人角落，重新逼着自己输出。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;总数&quot;</span>: <span class="number">31</span>,</span><br><span class="line">    <span class="attr">&quot;分类&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;ML知识总结&quot;</span>: <span class="number">3</span>,</span><br><span class="line">        <span class="attr">&quot;随笔&quot;</span>: <span class="number">20</span>,</span><br><span class="line">        <span class="attr">&quot;论文笔记&quot;</span>: <span class="number">5</span>,</span><br><span class="line">        <span class="attr">&quot;算法实践&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">&quot;工具人&quot;</span>: <span class="number">2</span>,</span><br><span class="line">&#125;,</span><br><span class="line">    <span class="attr">&quot;总字数&quot;</span>: <span class="number">33024</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>总字数的统计有偏差有水分，一些读书笔记里包括着复制的内容，一些总结归纳的文字绘制在图片中无法计数。</p></blockquote><p>总体而言，持续撰写博客是个好的开端，但仍有广阔的发展空间。</p><p>每每想到要码稿，对事物的观察就会细致些。无论是论文的研读，还是生活中的种种体验，借着要输出的压力，更能挖掘出易忽略的细节。生活的感知能力随着写作，一点点被唤醒。虽然说来有点矫情，但仍为自己庆幸，寻到了几分对抗冷漠功利社会的“多情”——愿为黄叶驻足，看它摇摆地飘落，乐得雨夜阳台闭目，倾听雨珠敲打万物的声响。</p><p>从内容分布上看，呻吟、唠叨太多而干货太少。随笔与学习笔记将近二比一的比例，反映出今年学习总结得太少了些，对半开才是理想情况。此外，学习还主要停留在“集百家所长”的积累阶段，愿明年能厚积薄发，注重知行合一，除了“论文笔记”外，能有更多“算法实践”类别文章的产出。</p><h1 id="阅读">2. 阅读</h1><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;书&quot;</span>: <span class="number">12</span>,</span><br><span class="line">    <span class="attr">&quot;影视&quot;</span>: <span class="number">21</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如上，是在豆瓣中可追溯的记录。还有些许看了小半，或是阅后无感等等，未作标记。</p><p>少，太少了。堪称贫瘠的一年。</p><p>借口是有的，诸如上半年忙着毕设，又遇情感波澜；临了毕业，栽进《沙丘》大长篇里；开学后总算找回阅读的状态，却随着学业渐紧，阅读量像抛物线样起了又伏。</p><p>终究是借口。来年但求翻个倍吧，<strong>每月2本</strong>不是难事才对。</p><p>所读数量太少，不好意思分享书单。现时回忆起来，《沙丘》系列及《富爸爸，穷爸爸》应被提名——是马上能想起的书。《富爸爸，穷爸爸》催促着人积极入世，与人斗、与金钱为友，摆正心态积极入世。《沙丘》尽管能联系当今世界风云变幻，但仍被我孤立地当成科幻史诗欣赏。从此，脑中除了战火纷飞的三国，满是自由浪漫海贼的大海等外，又多了黄沙漫天的沙丘星可供游历、幻想。</p><p>文学作品读少的结果，是遣词造句都干瘪乏力，写这些博客都要绞尽脑汁才能勉强成篇散文。</p><p>今年印象最深的影视， 都与满腔热血相关——《觉醒年代》，宣告我们何以选择今日道路；《1950他们正年轻》，述说我们的道路何以延续。历史不可不知不能遗忘，时时回望来时鲜血浇筑的道路，才能更坚定前行的方向。愿能一直赤诚，仿效先人，怀揣大志大义，不被物欲盲目，不为五斗米折腰。</p><h1 id="运动">3. 运动</h1><p>自8月来的不完全统计数据如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;健身&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;俯卧撑&quot;</span>:&#123;</span><br><span class="line">            <span class="attr">&quot;标准&quot;</span>: <span class="number">2214</span>,</span><br><span class="line">            <span class="attr">&quot;标准慢速&quot;</span>: <span class="number">115</span>,</span><br><span class="line">            <span class="attr">&quot;窄距&quot;</span>: <span class="number">230</span>,</span><br><span class="line">            <span class="attr">&quot;宽距&quot;</span>: <span class="number">284</span>,</span><br><span class="line">            <span class="attr">&quot;偏重&quot;</span>: <span class="number">600</span>,</span><br><span class="line">            <span class="attr">&quot;偏重慢速&quot;</span>: <span class="number">20</span>,</span><br><span class="line">            <span class="attr">&quot;钻石&quot;</span>: <span class="number">1055</span>,</span><br><span class="line">            <span class="attr">&quot;钻石慢速&quot;</span>: <span class="number">100</span>,</span><br><span class="line">            <span class="attr">&quot;Total&quot;</span>: <span class="number">4618</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;撸铁&quot;</span>:&#123;</span><br><span class="line">            <span class="attr">&quot;哑铃弯举7kg&quot;</span>: <span class="number">1138</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃弯举8kg&quot;</span>: <span class="number">212</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃俯身肱三弯举8kg&quot;</span>: <span class="number">176</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃俯身划船5kg&quot;</span>: <span class="number">440</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃俯身划船7kg&quot;</span>: <span class="number">606</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃俯身划船8kg&quot;</span>: <span class="number">360</span>,</span><br><span class="line">            &#x27;哑铃前&amp;侧平举2.5kg&#x27;: <span class="number">1260</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;引体向上&quot;</span>:&#123;</span><br><span class="line">            <span class="attr">&quot;半引体&quot;</span>: <span class="number">470</span>,</span><br><span class="line">            <span class="attr">&quot;正手&quot;</span>: <span class="number">864</span>,</span><br><span class="line">            <span class="attr">&quot;反手&quot;</span>: <span class="number">38</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;举腿&quot;</span>: <span class="number">439</span>, </span><br><span class="line">        <span class="attr">&quot;卷腹&quot;</span>: <span class="number">470</span>,</span><br><span class="line">        <span class="attr">&quot;深蹲&quot;</span>: <span class="number">559</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;跑步&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;总距离/km&quot;</span>: <span class="number">1294.92</span>,</span><br><span class="line">        <span class="attr">&quot;总时间/min&quot;</span>: <span class="number">7497</span>,</span><br><span class="line">        <span class="attr">&quot;半马&quot;</span>: <span class="number">8</span>,</span><br><span class="line">        <span class="attr">&quot;全马&quot;</span>: <span class="number">2</span>,</span><br><span class="line">        <span class="attr">&quot;10km PB&quot;</span>: <span class="string">&quot;00:43:50&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;半马 PB&quot;</span>: <span class="string">&quot;01:43:44&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;全马 PB&quot;</span>: <span class="string">&quot;04:18:59&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>“欲文明其精神，先自野蛮其体魄。 苟野蛮其体魄矣，则文明之精神随之。 ”</p></blockquote><p>农历新年起开始重拾跑步，下半年开始自重健身。看了数据才知道，原来坚持一点点的锻炼，积少成多也有成百上千的数量，从5公里、十公里，到了能挑战全马的距离。</p><p>体型变化仍不甚明显，更多的是对心态的调节吧。不快时，换双跑鞋出门小跑个把小时，或是找出干净地方就地俯卧撑，练到双臂酸胀，整个人趴在地上，心头的烦扰杂念也消散不少。不像其他事物，运动的进步曲线大多平滑且平缓，最能获取一分耕耘一分收获的欢喜。以及胃口是真的好了很多，成“饭学长”了。</p><h1 id="其他">4. 其他</h1><p>情感方面，高低起伏动荡不安的一年，行至年关总算是到了心略安的时候。今年学业不敢说有何增进，亲密关系的处置方面绝对是学习良多。来到第四季度算是打点好自己重新出发了。</p><p>本科毕业的年份，因顺利的保研继续求学，显得平淡。仍是老地方，一点点推进所谓的“科研”吧。</p><hr /><p>匆匆，着实匆匆。跨了年后，欠下的文稿已不想再补。</p><p>总结与展望，以及新的FLAG，留待农历新年吧。总觉得《难忘今宵》唱响，一年才是真的到头了。</p><p>以及，虚岁已是二三，愿见贤思齐，多内省，多干实事。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;总算考完一门硬核的试，抢下些许喘息时间。不知不觉年关又至，流水账般收集下今年尚能想起的记忆碎片吧。&lt;/p&gt;
&lt;p&gt;试图手动统计些数据，量化将逝的2021。要是有时间，或许再来做点好看的可视化吧。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>GNN_STARGNN_Adaptive感受野</title>
    <link href="http://example.com/2021/12/18/GNN-STARGNN-Adaptive%E6%84%9F%E5%8F%97%E9%87%8E/"/>
    <id>http://example.com/2021/12/18/GNN-STARGNN-Adaptive%E6%84%9F%E5%8F%97%E9%87%8E/</id>
    <published>2021-12-18T02:49:16.000Z</published>
    <updated>2021-12-18T02:49:16.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="improving-graph-neural-networks-with-structural-adaptive-receptive-fields">Improving Graph Neural Networks with Structural Adaptive Receptive Fields</h1><blockquote><p>PDF: https://dl.acm.org/doi/10.1145/3442381.3449896</p><p>Conferences: WWW '21</p></blockquote><h2 id="abstract">1. Abstract</h2><p>现有GNN模型未能充分利用图结构信息，此工作提出STructural Adaptive Receptive fields (<strong>STAR-GNN</strong>)，适应性地构建每个节点的感受野(receptive field)以捕获结构信息。具体贡献如下：</p><ul><li>提出基于节点结构信息来自适应调节receptive field范围STAR-GNN；</li><li>将Anonymous Random Walks (ARWs)和互信息结合来捕获节点的结构信息，此外还提出针对receptive field的subgraph 聚合算子。</li></ul><span id="more"></span><h2 id="motivations">2. Motivations</h2><p><strong>大部分GNNs未能充分利用图结构信息，对邻居节点的重要性没有区分：</strong></p><ul><li>传统的GCN将邻居节点一视同仁，或者根据边权来分配权重，因而忽略了许多与邻居重要性有关的信息；</li><li>GAT使用soft attention，基于节点特征的相似度来学习权重，但其，① 忽略拓扑特征的相似度信息，② soft attention在邻居数量较大时可能遭遇过平滑问题。</li></ul><p>对此，希望能提出一种<strong>结合结构信息来适应性地构建节点receptive field</strong>的方法，该方法希望能 ①同时根据节点特征和结构特征来衡量邻居重要性，② receptive field聚合irregular neighborhoods 且避免过平滑问题。</p><p>遇到的挑战如下：</p><ol type="1"><li>图复杂的结构信息难捕获；</li><li>适应性地构建receptive field计算复杂度高。该adaptive构建过程是不可微的，因而难直接优化。此前使用强化学习及组合优化的方式计算复杂度都过高；</li><li>不能基于k-order邻居来建立receptive field。理想的receptive field是不规则的子图，可能有数量各异的各阶邻居，现有聚合算子难有效聚合这样的子图结构。</li></ol><h2 id="method">3. Method</h2><figure><img src="./STARGNN_01.png" alt="overview" /><figcaption aria-hidden="true">overview</figcaption></figure><h3 id="overview">3.1 Overview</h3><p>STAR-GNN主要分为3个部分：</p><ol type="1"><li><strong>Local Structural Distribution</strong>，使用ARWs来捕获节点的邻居分布，结合Mutual Information(MI)来计算注意力，得到包含节点特征和结构信息的structural embedding；</li><li><strong>Construction of Optimal Receptive Fields</strong>，用structural embedding计算节点对间MI，贪心地寻找optima receptive field；</li><li><strong>GNN with Sub-graph Structures</strong>，通过采样不规则subgraph（receptive field）中节点，进行聚合。</li></ol><h3 id="neighborhood-contributions-local-structural-distribution">3.2 Neighborhood Contributions Local Structural Distribution</h3><p>Attention score 计算，过往一些方法基于节点特征相似度，一些则引入了人为设计的结构信息patterns，都只能捕获有限结构信息且泛化性不佳。</p><p>本工作则使用ARWs刻画节点的邻居结构特征，认为ARWs能较好地描述节点的local structural distribution。ARWs定义如下：</p><p><img src="./STARGNN_03.png" style="zoom:50%;" /></p><p>进一步地，本工作引入互信息(MI)来辅助学习节点embedding <span class="math inline">\(U={u_i}\)</span>，希望最大化节点对间特征、结构信息。Loss设计有：</p><p><img src="./STARGNN_04.png" style="zoom:67%;" /></p><p>其中<span class="math inline">\(w_{i j}=\sigma\left(\mathbf{u}_{i}^{T} \mathbf{u}_{j}\right)\)</span>，<span class="math inline">\(\mathcal{N}_{i}\)</span>为节点<span class="math inline">\(i\)</span>的ARWs中所访问到的节点集合，<span class="math inline">\(I(·, ·)\)</span>为互信息，第一项衡量节点间特征相似度，第二项衡量结构相似度。</p><p><img src="./STARGNN_05.png" style="zoom:67%;" /></p><p>Attention score则由上述<span class="math inline">\(u\)</span>计算，</p><p><img src="./STARGNN_06.png" style="zoom:50%;" /></p><h3 id="construction-of-optimal-receptive-fields">3.3 Construction of Optimal Receptive Fields</h3><p>作者先前的工作说明GAT中的soft attention，在节点度较高时会遇到过平滑问题。因而构建receptive field时，应当“construct discrete adaptive receptive fields to avoid over-smoothing”(不是很理解，是否理解为需要筛选邻居，以减少聚合对象个数)。</p><p>作者认为，理想的receptive field应当<strong>为中心节点提供最多的信息</strong>，并希望用<strong>MI</strong>来衡量获取信息的多少。</p><p>因为MI≥0，故receptive field增大时MI和单调不减，故本工作将优化目标定为：以最小的receptive field取得满足阈值的MI：</p><p><img src="./STARGNN_07.png" style="zoom:67%;" /></p><p>本工作使用贪心算法求解上述优化问题。</p><h3 id="gnn-with-sub-graph-structures">3.4 GNN with Sub-graph Structures</h3><p>当前聚合算子如Mean, Max, LSTM针对k-hop邻居做聚合，对于不规则的subgraph，聚合时难以区分不同阶邻居信息。</p><p>本工作对如下聚合方式进行一系列证明，说明其满足permutation invariant。最后得到的聚合方式为：</p><p><img src="./STARGNN_08.png" style="zoom:67%;" /></p><p>模型loss则为</p><p><img src="./STARGNN_09.png" style="zoom:50%;" /></p><p>模型算法描述如下：</p><p><img src="./STARGNN_10.png" style="zoom:50%;" /></p><h2 id="exp">4. Exp</h2><ol type="1"><li><p>节点分类</p><ul><li>Transductive</li><li><img src="./STARGNN_11.png" style="zoom:80%;" /></li><li>Inductive</li><li><img src="./STARGNN_12.png" style="zoom:50%;" /></li></ul></li><li><p>Ablation study</p><p><img src="./STARGNN_13.png" style="zoom:50%;" /></p><p>相对而言，引入结构信息和选择optimal receptive field对性能帮助更大。</p></li></ol><h2 id="personal-thoughts">5. Personal Thoughts</h2><p>建模阶段：</p><ul><li>在base node embedding阶段，用ARWs来刻画节点的local structure。RW-based方法implicit捕获拓扑结构，相较于explicit的子图挖掘，泛化性更好，对边缘节点等刻画更清晰，但未必能准确刻画cohesive subgraph等子图结构；</li><li>（越看越奇怪，感觉没看懂）base node embedding依旧通过GNN在原图上(?)学习，不过在loss中加入MI构造的penalty，来捕获ARWs所刻画的结构信息，此处可算出attention scores，留给final embedding的聚合阶段使用；</li><li>optimal receptive field通过MI+贪心算法构建。它们不在聚合阶段做邻居的筛选，而是将receptive field的构建前置，从而减少噪音，思路值得借鉴；</li><li>final embedding由传统的邻居聚合+及<span class="math inline">\(\tilde{h_i}\)</span>构成，<span class="math inline">\(\tilde{h_i}\)</span>聚合了节点<span class="math inline">\(i\)</span>的感受野信息。其聚合方法符合个人为实现子图聚合的想法——<em>抽样聚合</em>，提供了理论证明；</li></ul><p>整体工作：</p><ul><li>可以发现，本工作实际的编码器只有两个分离的GNN及若干MLP，主要工作在于<strong>adaptively调整编码器的输入</strong>；</li><li>亮点：<ul><li>MI的引入比较系统，从loss设计到optimal感受野的选择都结合了MI；</li><li>理论的证明和实验做得比较齐全，模型在数据集上的F1表现优异；</li></ul></li><li>不足：<ul><li>为得到final embedding，过程中产生较多冗余变量来调整模型输入，模型整体性略差。更理想来说，通过模型架构和penalty来自动选择感受野更为理想，贪婪算法整体性不强；</li><li>模型的推理速度堪忧。</li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;improving-graph-neural-networks-with-structural-adaptive-receptive-fields&quot;&gt;Improving Graph Neural Networks with Structural Adaptive Receptive Fields&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;PDF: https://dl.acm.org/doi/10.1145/3442381.3449896&lt;/p&gt;
&lt;p&gt;Conferences: WWW &#39;21&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;abstract&quot;&gt;1. Abstract&lt;/h2&gt;
&lt;p&gt;现有GNN模型未能充分利用图结构信息，此工作提出STructural Adaptive Receptive fields (&lt;strong&gt;STAR-GNN&lt;/strong&gt;)，适应性地构建每个节点的感受野(receptive field)以捕获结构信息。具体贡献如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提出基于节点结构信息来自适应调节receptive field范围STAR-GNN；&lt;/li&gt;
&lt;li&gt;将Anonymous Random Walks (ARWs)和互信息结合来捕获节点的结构信息，此外还提出针对receptive field的subgraph 聚合算子。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="论文笔记" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="图神经网络" scheme="http://example.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    <category term="图表示学习" scheme="http://example.com/tags/%E5%9B%BE%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>MSL_15_夜与便利店</title>
    <link href="http://example.com/2021/12/13/MSL-15-%E5%A4%9C%E4%B8%8E%E4%BE%BF%E5%88%A9%E5%BA%97/"/>
    <id>http://example.com/2021/12/13/MSL-15-%E5%A4%9C%E4%B8%8E%E4%BE%BF%E5%88%A9%E5%BA%97/</id>
    <published>2021-12-12T16:08:37.000Z</published>
    <updated>2021-12-28T12:35:38.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>搬家的前一夜，一如往常，走进罗森。打算买两个茶叶蛋，和舍友一人一个分了——煮泡一天的蛋最为入味。却只见一锅红褐色的茶汤，蛋已售罄了。和那胖乎乎的年轻店员对视一眼，又走出店门。</p><p>大约很难再见他。</p></blockquote><p>没有所谓深夜食堂的热络，夜间的便利店，默默消化着每个独身过客。</p><span id="more"></span><p>总觉着，夜里的便利店，往来的人们总算能卸下一日的包袱或伪装，短暂地释放真实的自我。</p><p>它不是酒吧，并不能趁着酒意与人攀谈，彼此交换故事。大多时候，我只是在选购食物、付款间隙，瞄几眼货架前的人们，高脚凳上的人们——大多沉默，享受自己的独处时刻。</p><p>有见过：十一点的罗森，邻座四瓶AD钙一字排开，窄桌上再加一份咖喱炸鸡便当，只着手机看直播。一瓶、两瓶，吸管咕噜噜的声音与筷子扒拉米饭刮蹭盒底的声音相和。直到每瓶AD钙上都插了吸管，黑色塑料餐盒只留一点咖喱汁时，便起身离去。</p><p>也见过：情侣，大约是热恋期吧。深夜忙碌后，选好食物，不在暖烘烘的店内就餐，倒是寻了店门外的小石凳——女生坐在男生大腿上，团身靠在胸口。</p><p>更多的人，像我，不作逗留，一个普通的消费者罢了。进店奔向货架搜寻目标，偶尔的优惠组合会扰乱采购计划。有货，心满意足；售罄，摇摇头，叹气离开。</p><p>真正和便利店相伴的，是店员。没有顾客时应该会坐下休息吧，站一夜实在辛苦。夜晚顾客不多，却有其孤独的忙碌。货物补给总是晚上送抵，扫码入库上架，不得停息。</p><p>金玟岐17年写的《7-11》，不是我的故事，却照映着城市里的孤勇者们。</p><p>不算好吃的食物，不算美丽的价格，只因深夜它有唯一点亮的灯火，变得温暖可爱起来。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;搬家的前一夜，一如往常，走进罗森。打算买两个茶叶蛋，和舍友一人一个分了——煮泡一天的蛋最为入味。却只见一锅红褐色的茶汤，蛋已售罄了。和那胖乎乎的年轻店员对视一眼，又走出店门。&lt;/p&gt;
&lt;p&gt;大约很难再见他。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;没有所谓深夜食堂的热络，夜间的便利店，默默消化着每个独身过客。&lt;/p&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>GNN_利用边信息</title>
    <link href="http://example.com/2021/11/13/GNN-%E5%88%A9%E7%94%A8%E8%BE%B9%E4%BF%A1%E6%81%AF/"/>
    <id>http://example.com/2021/11/13/GNN-%E5%88%A9%E7%94%A8%E8%BE%B9%E4%BF%A1%E6%81%AF/</id>
    <published>2021-11-13T06:44:51.000Z</published>
    <updated>2021-11-13T06:44:51.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><strong>Abstract</strong>:</p><p>当前GNNs主要利用了节点特征，忽略了边上信息。本笔记对GNNs中利用边信息的方式进行小结。</p></blockquote><span id="more"></span><p>部分图片截取自[1]，感谢原创人员悉心的总结分享。</p><h2 id="backgrounds">1. Backgrounds</h2><p>图表示学习近年来取得巨大进展，以<strong>GCNs</strong>为代表的一系列图神经网络模型在节点分类、图分类、链接预测等图领域任务取得亮眼的成果。其中大部分模型基于<em>message-passing</em>方式构建，即“聚合邻居信息，更新节点自身状态”，在此范式中，节点特征得到充分的学习。而现实的许多图中，边上存在丰富的信息，它们在当前大多模型中未被充分利用。</p><p>Edge Features同样描述着网络，学习edge features能强化图神经网络的表达能力。</p><p>以下图为例：</p><p>社交网络中，edge features更具体地描述着用户(nodes)间关系。</p><p><img src="./01.png" /></p><h2 id="recently-works">2. Recently Works</h2><p>当前图神经网络对边信息主要有如下几种利用方式：</p><p><img src="./GNNs+Edge%20Features.png" /></p><h3 id="implicit-utilization">2.1 Implicit Utilization</h3><p>每个节点只aggregate其邻居的信息，这一聚合方式本身就基于节点间的边实现。此情况下只视作各个边为binary feature，只有“有边/无边”区别。</p><h3 id="naive-utilization">2.2 Naive Utilization</h3><p>对于边上特征为scalar的情况，最简单直接的方式是使用带权的邻接矩阵描述，与之对应的，使用支持edge weight的模型学习即可。</p><h3 id="aggregate-from-different-types-of-edge">2.3 Aggregate from Different Types of Edge</h3><p>在许多场景中，边上特征为类别标签，如社交网络中，边上可以标注两人为工作关系、家人等。</p><p>对于存在多种类型边的图（边异构），常见处理方法是<strong>依照边的类型分别聚合信息</strong>。</p><p>如早期工作<strong>Relational GCN</strong>[2]，</p><p>其只在GCN</p><p><span class="math display">\[h^{l+1}_i = \sum_{j \in \mathcal{N}_{i}} \frac{1}{norm} W^{(l)} h_{j}^{(l)}+W^{(l)} h_{i}^{(l)}\]</span></p><p>的基础上，增加了<span class="math inline">\(\sum_{r \in R}\)</span>.</p><p><img src="./02.png" /></p><p>其他模型也是类似思路，仅在聚合方式上做进一步细化。 如下图：</p><p><img src="./03.png" /></p><h3 id="multi-dimensional-edge-features">2.4 Multi-dimensional Edge Features</h3><p>上述3个方式并不能较好地处理边上多维特征。面对多维边特征，常见手段也是在aggregation阶段将边特征、邻居节点特征通过某种function结合在一起，再传给目标节点。</p><p>General Idea 如下图：</p><p><img src="./04.png" /></p><p>相关工作有<em>PNAConv</em>[3],<em>Crystal Graph Conv</em>[4]。</p><h3 id="learn-edge-embeddings">2.5 Learn Edge Embeddings</h3><p>与2.4区别在于，下述方法以多维边特征为输入，并在模型每层更新，类似学习node embedding一般，同时学习edge embeddings。其实现方式多为创建某种辅助图，在该图中将边也视作节点，再用现有GAT等模型学习边和节点的表示。</p><ol type="1"><li><p><em>EGNN</em> [5] <span class="math display">\[X^{l}=\sigma\left[\prod_{p=1}^{P}\left(\alpha_{\cdots p}^{l}\left(X^{l-1}, E_{\cdots p}^{l-1}\right) g^{l}\left(X^{l-1}\right)\right)\right]\]</span></p><p><span class="math inline">\(P\)</span> 为边特征维度数。</p><p>在GAT基础上，单独处理每一维的特征。聚合函数中加入节点特征，并为每一维特征单独学一组注意力权重，最后将各维输出concate。本文的edge embeddings，为每层所学的边多维特征注意力权重。</p><p><img src="./05.png" /></p></li><li><p><em>CensNet</em> [6]</p><p>使用line graph（原始图中节点变为line graph中的边，边变为节点）构建辅助图，在original graph和line graph上训练模型，交替更新node, edge embeddings。</p><p><img src="./06.png" /></p></li><li><p><em>NENN</em> [7]</p><p>以GAT为基础，提出Node-level Attention Layer, Edge-level Attention Layer。</p><p>每个layer区别主要在于输入的图的观察角度。</p><p>如下图中两矩形方框部分，分别以node、edge为视角，重新定义“邻居”，将边/节点视作新图中的节点，在新图中学习边和节点的embeddings。</p><p><img src="./07.png" /></p></li><li><p><em>EGAT</em> [8]</p><p>与<em>CensNet</em>类似，使用line graph+GAT学习节点和边的表示。</p><p><img src="./08.png" /></p></li></ol><h2 id="discussion">3. Discussion</h2><ol type="1"><li>2.5中多用GAT编码边特征信息，带来较大的计算开销，能否更轻量且优雅的编码边特征？</li><li>2.5中使用诸如line graph等构建辅助图，把原图中的边变换为辅助图中的节点，从而可以利用已有GNN进行边嵌入的学习。但是，对于“边的邻居边”，是否同样满足节点与其邻居相近的假设？</li><li>如何评估边特征与节点的关系，边特征如何切实的帮助图表示学习？</li></ol><h2 id="reference">Reference</h2><ol type="1"><li>https://www.youtube.com/watch?v=mdWQYYapvR8</li><li>Schlichtkrull M, Kipf T N, Bloem P, et al. Modeling relational data with graph convolutional networks[C]//European semantic web conference. Springer, Cham, 2018: 593-607.</li><li>Corso G, Cavalleri L, Beaini D, et al. Principal neighbourhood aggregation for graph nets[J]. arXiv preprint arXiv:2004.05718, 2020.</li><li>Xie T, Grossman J C. Crystal graph convolutional neural networks for an accurate and interpretable prediction of material properties[J]. Physical review letters, 2018, 120(14): 145301.</li><li>Gong L, Cheng Q. Exploiting edge features for graph neural networks[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 9211-9219.</li><li>Jiang X, Ji P, Li S. CensNet: Convolution with Edge-Node Switching in Graph Neural Networks[C]//IJCAI. 2019: 2656-2662.</li><li>Yang Y, Li D. Nenn: Incorporate node and edge features in graph neural networks[C]//Asian Conference on Machine Learning. PMLR, 2020: 593-608.</li><li>Chen J, Chen H. Edge-Featured Graph Attention Network[J]. arXiv preprint arXiv:2101.07671, 2021.</li></ol>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;当前GNNs主要利用了节点特征，忽略了边上信息。本笔记对GNNs中利用边信息的方式进行小结。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="ML知识总结" scheme="http://example.com/categories/ML%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="图神经网络" scheme="http://example.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    <category term="图表示学习" scheme="http://example.com/tags/%E5%9B%BE%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>MSL_14_星火不熄</title>
    <link href="http://example.com/2021/11/12/MSL-14-%E6%98%9F%E7%81%AB%E4%B8%8D%E7%86%84/"/>
    <id>http://example.com/2021/11/12/MSL-14-%E6%98%9F%E7%81%AB%E4%B8%8D%E7%86%84/</id>
    <published>2021-11-11T16:20:46.000Z</published>
    <updated>2021-11-15T17:53:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>长河无声奔去，唯爱与信念永存。</p><p>大约借贷了不少幸运，才得以有佳人相伴，赶上了这场舞剧——《永不消逝的电波》。</p></blockquote><span id="more"></span><p>我与舞剧，仿似若即若离。</p><p>看电影是轻松的，取了票往影院软凳一躺，兴致其高时说不定还揽一桶爆米花入场（虽然上一次吃爆米花看电影的记忆早已模糊）；观舞剧嘛，刻板印象里将它定义为风雅之事。刷豆瓣活动时总会看到些有趣的剧目，每每为其内容描述心动时，但或因无人作陪，或忧剧目高雅大老粗人难以体悟，总归是在购票界面迟疑许久后，默默地点下取消。</p><p>这回，总算是昂首步入了琴台剧院。</p><h2 id="无端联想">1. 无端联想</h2><p>且说观剧体验。</p><p>高坐三楼，俯瞰舞台，看不清舞者细微的神态与动作，却也一览群舞全貌。</p><p>虽说些许“一场论”了，但舞剧更有人世的风貌，而电影不过是被镜头捕获的局促视角。初次观剧，用目不暇接来概括最为恰当。舞台上。每位舞者都倾情演绎着自己的角色。携带的望远镜也无用武之地，剧场上各个角落，各个人物都尽心舞蹈着，以律动的肢体叙事——光饱览全貌已然耗尽心神，望远镜着实无法定下关注的焦点。恰似人世，大家都在自己一片时空中过活，时空不时交会，大多并行延申。全知全能如“神”，才能不错过分毫细节；一般人若俯瞰人世，怕也是如观舞剧般，粗览全局后，定睛瞅了这头，漏过了那头。</p><p>再谈舞蹈。</p><p>对舞蹈几近是白痴，脑中能有印象的舞，是《闻香识女人》里阿尔·帕西诺那曲探戈——和舞剧也不搭边就是了。此番观舞，难说有啥专业见解，只是深深地被曼妙的舞姿打动——举手投足间倾诉的情愫或溢出的力量。</p><p>记得一众身着旗袍的舞者，婀娜身姿甚至脱去了想象中民国上海纸醉金迷的脂粉气，约有几分”翩如兰苕翠，婉如游龙举“之貌；记得夜幕中的追捕与搏斗，没有拳拳到肉的实感，没有快切没有特写，但飞舞的黑色衣襟，高跳、翻滚、旋转，依旧描摹着激烈的生死斗争；记得昂首阔步舞至人生终章的豪迈；记得一众烈士步履艰难地带镣前进……</p><p>也还记得身边紧握的手。</p><p>不多的遗憾，是无法录影吧。恨自己双眼与脑瓜的记录能力有限，不能让我逐帧细致地回味。</p><p>舞美设计也与人震撼，奈何文字苍白，那些精巧的编排唯亲临现场才能体会。</p><p>便是略提一点有趣的观察吧：裁缝的店铺中，立着一扇镜子。仔细看去，发现镜面并非平整，照镜之人身形都被扭曲拉伸。或许借着反射，暗喻着那时代的光怪陆离罢。</p><h2 id="听不见的电波">2. 听不见的电波</h2><p>曾看过电影《听风者》，那故事更传奇些——盲人调音师识破敌台。《永不消逝的电波》，才来得真实些，更易设身处地遐想，更易动情。</p><p>如今再度富强的华夏，便是当年的同志们，各自坚守自己的一份职责，聚沙成塔，血肉叠铸而成。比起如今的我们，他们大多不会有更多的学识吧，甚至也无更多的阅历——那么多可爱的同志们，从年岁上看不过是个孩子。就像剧中的小裁缝学徒，无任务时蹦蹦跳跳玩乐才是天性，与相遇的卖花的女孩子本还有一段故事可以延展。他们多的，大约是对未来的信念，以及一腔热血吧。相信着中华民族五千年血脉不会中断，相信镰刀锤头能挥舞出光明，相信以自己的生命，做好分内事，便有星星之火，将见燎原。</p><p>因而，尤其看不得剧中小裁缝被害后，梦中还魂、道别的场景。一来，带大我、授童稚的我以人生原则的外公逝世后，每每梦见，醒来总是不免泪流，故也算是略知梦见逝者，醒后所感的悲恸、萧瑟；二来，最不忍见孩童生命的消逝。他们本有无穷条交汇、分叉的通往未来的道路，却横地被在主干道上插上此路不通的牌子，此后，再无路可走。</p><p>梦中小裁缝的谢幕，最让人动容——他越洒脱，越是安慰、鼓励生者，越使观者反思、自愧——坦然接受死亡的人能有几多，能使短暂人世经历重于泰山者又有几多。</p><p>身边的心跳声一个个沉寂下去，空气中总震荡着听不见的电波，夜晚，发报机仍不能停下。回望那段历史，总会满怀敬意。强大的信念与意志，让工作的接力棒在生死两界传递——可慨然赴死，也会负重继续前进。</p><h2 id="听不到的故事">3. 听不到的故事</h2><p>剧终时，黑底白字，投影出”长河无声奔去，唯爱与信念永存“。</p><p>奔涌的长江浪涛滚滚，怎会无声？沉默的，是翻卷浪花下，离去的人们，以及他们无人传述的故事。</p><p>遗憾惭愧是难免的，那么多生命无声暗淡了去，甚至连历史的尘埃都不是。</p><p>不过，故事大约不是必须的，信念才是。不需要留声机，需要长明的火把。</p><p>星火不熄，华夏长存。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;长河无声奔去，唯爱与信念永存。&lt;/p&gt;
&lt;p&gt;大约借贷了不少幸运，才得以有佳人相伴，赶上了这场舞剧——《永不消逝的电波》。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="随笔" scheme="http://example.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="日常" scheme="http://example.com/tags/%E6%97%A5%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>GNN_GIN论文笔记</title>
    <link href="http://example.com/2021/11/09/GNN-GIN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <id>http://example.com/2021/11/09/GNN-GIN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</id>
    <published>2021-11-09T07:06:09.000Z</published>
    <updated>2021-11-09T07:06:09.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>借结课展示的强制力，更新 <em>How Powerful Are Graph Neural Networks?</em> 论文阅读笔记如下。</p></blockquote><p>此工作发表于ICLR19，将GNN聚合邻居的方式与WL test做类比，理论上论证了GNN表达能力的上限为WL Subtree kernel，并根据分析提出<strong>GIN</strong>模型。论文提供了理解GNN表达能力的新思路，也启迪GNN模型架构发展的方向。</p><span id="more"></span><p><img src="./幻灯片1.png" /></p><p><img src="./幻灯片2.png" /></p><h2 id="background-contributions">1. Background &amp; Contributions</h2><p>GNN近年来来发展迅速，在图表示学习方向取得耀眼成果。但大部分模型的设计都基于经验或直觉，缺少对GNN性质的深入理解分析。</p><p><img src="./幻灯片4.png" /></p><p>本工作主要有4方面的贡献：(见下图)</p><p><img src="./幻灯片5.png" /></p><h2 id="preliminaries">2. Preliminaries</h2><p><img src="./幻灯片7.png" /></p><p>本工作讨论的为Message-Passing类的GNN模型，</p><p>此类模型每层进行<strong>AGGREGATE及COMBINE</strong>操作，分别负责收集邻居信息、结合邻居和节点自身信息更新hidden state。</p><p>若需要获得graph-level的图表示，则一般操作，是对网络最后一层的所有节点信息做聚合，即使用<strong>READOUT</strong>函数取得最后的图表示<span class="math inline">\(h_G\)</span>。READOUT函数需要满足permutation invariant，常用的简单函数有如<strong>求和SUM</strong>。</p><p><img src="./幻灯片8.png" /></p><p>本工作中涉及的WL Test是尝试判断图同构的经典方法。</p><p>图同构问题是图论中的经典问题，且是NP问题。若两个图是同构的，则存在双射函数，能将一个图中节点对应映射为另一图中对应节点。</p><p>如下图，图G、H为同构图，可通过双射的函数f找到两图中一一对应的节点。</p><p><img src="./幻灯片9.png" /></p><p>WL Test是图同构的一个<strong>必要非充分</strong>的条件。其算法迭代执行如下两步：</p><ol type="1"><li>每个节点收集一阶邻居的标签（是不是很像MPNN收集message的步骤）；</li><li>将聚合后的标签集合做hash，创建新的唯一标签；</li></ol><p>每轮迭代后比较两图节点标签集合异同，如使用Jaccard积，如果不同则能说明两图非同构，否则两图可能是同构的。</p><p>一轮迭代的例子如下图。</p><p><img src="./幻灯片10.png" /> <img src="./幻灯片11.png" /></p><h2 id="this-works">3. This works</h2><h3 id="gnn表达能力上界">3.1 GNN表达能力上界</h3><p>任何基于统计的表示学习模型，都想将同类样本映射到表示空间中相近甚至相同位置，不同类样本则尽量远离。</p><p>对于图表示学习，若说两个节点是一样的，则意味着节点的<strong>结构、特征</strong>都相同。具体的，则是两个节点导出的子树结构完全相同，且子树上的节点所有的特征也相同。</p><p>相应的，理想化的GNN能将上述相同节点映射到相同表示空间，不相似节点则映射至表示空间中彼此远离的位置。</p><p>实际上，满足上述要求的GNN，实质上是在解决<strong>图同构问题</strong>。</p><p><img src="./幻灯片13.png" /></p><p><strong>multiset</strong>为后文论证中常用概念，实质上用于描述每个节点所收到的邻居信息。</p><p><img src="./幻灯片14.png" /></p><p>从Section 2中GNN与WL Test介绍可以发现，二者聚合邻居信息更新自身节点hidden state/label的过程在方式上相近。</p><p>作者在一系列证明后给出结论：<strong>基于aggregation的GNN模型，在分辨不同图任务中的能力上界为WL Test</strong>。</p><p><img src="./幻灯片15.png" /></p><p>自然而然的问题，怎样构建GNN模型才能逼近表达能力上界呢？</p><p>作者进一步推导证明，模型的<strong>Aggregate, Combine, Readout函数都必须是单射函数</strong>。（与ideally GNN类似，单射函数保证了不同结构、特征的节点被映射为不同的嵌入表示）。</p><p><img src="./幻灯片16.png" /></p><h3 id="gin">3.2 GIN</h3><p><img src="./幻灯片17.png" /></p><p>基于上图结论，作者提出<strong>Graph Isomorphism Network(GIN)</strong>。</p><p>其中，<span class="math inline">\(f^{(k)}\)</span>为<strong>多层感知机MLP</strong>，ε为可学习的参数，二者再加上<strong>SUM</strong>共同保证了模型函数的单射性。</p><p><img src="./幻灯片18.png" /></p><p>对应的，READOUT函数也要使用<strong>SUM</strong>来保证单射性。 与通常做法不同，GIN为了把握全局的图结构，它的图表示<span class="math inline">\(h_G\)</span>聚合了网络<span class="math inline">\({1,..,k}\)</span>层的全部信息。</p><p><img src="./幻灯片19.png" /></p><p>对于传统基于一阶邻居聚合的GNN模型，本工作发现它们有如下问题： 1. 所使用的单层perceptron在一定场景中是非单射的，表达能力不如MLPs； 1. Mean 和 Max-pooling 算子是非单射的，在下图结构中，节点v和v'聚合所得邻居信息的结果可能一致，意味着使用这两个算子可能丢失更具体的结构信息。</p><p><img src="./幻灯片20.png" /></p><h3 id="experiments">3.3 Experiments</h3><p><img src="./幻灯片21.png" /></p><p>训练阶段，WL Subtree kernel为上界。可以看到GIN-0, GIN-eps都较好的逼近了WL Subtree kernel。而使用其他不满足单射性质的GNN variants则收敛较慢，或者无法收敛至理论上界。</p><p><img src="./幻灯片22.png" /></p><p>实验结果可见，在Graph Classification任务上GIN取得了耀眼成绩。</p><p><img src="./幻灯片23.png" /></p><h2 id="personal-thoughts">4. Personal Thoughts</h2><p><img src="./幻灯片25.png" /> <img src="./幻灯片26.png" /></p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;借结课展示的强制力，更新 &lt;em&gt;How Powerful Are Graph Neural Networks?&lt;/em&gt; 论文阅读笔记如下。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;此工作发表于ICLR19，将GNN聚合邻居的方式与WL test做类比，理论上论证了GNN表达能力的上限为WL Subtree kernel，并根据分析提出&lt;strong&gt;GIN&lt;/strong&gt;模型。论文提供了理解GNN表达能力的新思路，也启迪GNN模型架构发展的方向。&lt;/p&gt;</summary>
    
    
    
    <category term="论文笔记" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="图神经网络" scheme="http://example.com/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    <category term="图表示学习" scheme="http://example.com/tags/%E5%9B%BE%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
