<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>BOOK-02-资本的终结</title>
    <url>/2021/05/31/BOOK-02-%E8%B5%84%E6%9C%AC%E7%9A%84%E7%BB%88%E7%BB%93/</url>
    <content><![CDATA[<h1 id="book-02-资本的终结21世纪大众政治经济学">BOOK-02-资本的终结：21世纪大众政治经济学</h1>
<blockquote>
<p>事实上，剥削压迫现象的客观存在和自然界存在的弱肉强食等现象，往往被统治者解释为“普世价值”，并必然把那个时代的人们在精神和生活上不可或缺的生死攸关的东西推崇为崇拜物，以此控制和垄断人们的精神世界。结果，人所崇拜的正是禁锢人自身的精神枷锁，这是人类不发达、不自由的表现。宗教、权力和货币资本是迄今为止人类最为 推崇的三件“法器”，历代统治者均是以这个或者那个为核心，建立起一整套符合统治需要的政治思想、法律思想、道德、哲学、艺术、宗教等社会意识形态。不同时代的人们正是在自己那个时代的社会意识形态下进行着认识和思考的。</p>
</blockquote>
<span id="more"></span>
<h2 id="简短感想">1. 简短感想</h2>
<p><strong>单就书而言</strong>，说是政治经济学的入门读物不假。条理较为清晰，通过中外对比的方式，以资本发展的历史为主线，批判地回顾了资本主义的兴衰。不过论证主要靠罗列、分析数据，具体案例较少，可谓严谨但不通俗。</p>
<p><strong>再说随想</strong>，了解我们的政治经济学分析思路，从而加深了对资本剥削方式、本质的认知。公知们鼓吹的“自由民主市场资本主义”等等耀目的名词无法再蒙骗人民——瞧那“芝加哥学派”的爆红之路吧！然而，我们看见了资本主义丑恶残酷的嘴脸，却发现这副嘴脸不在大洋彼岸，不在大陆另一边，而真切的在你我身边。996乃至007的打工人们何时、如何能奋起抗争，取回被剥削的剩余价值呢？</p>
<p>或许该更进一步学习咱们的政治经济学，用理论武装自己。但，更进一步的，也要思索如何行动，斗争。“人民当家作主。”</p>
<h2 id="片段摘录">2. 片段摘录</h2>
<ol type="1">
<li><p>美帝的套路：借助资金和国际话语权吹捧起一套理论，该理论宣扬这某种“普世价值”，但实质是为资本增值服务。</p>
<p>到底哪些社科研究具备实际价值，哪些又仅是宣传输出？又或，还是要用屁股决定脑袋解释。</p></li>
</ol>
<blockquote>
<p>面对60年代后期开始并在70年代加剧的一系列经济问题，以金融资产阶级为首的美国统治阶级开始意识到必须打垮国内外的工人阶级力量，并摧毁社会主义国家和第三世界国家发展民族经济的努力，而芝加哥学派的经济学正好提供了相应的理论支持。因而，从70年代开始，大量的（政府和各种基金的）资金被投向芝加哥大学经济系，资助其研究、学术会议、杂志和招收留学生。美国的媒体则越来越多地给芝加哥学派的经济学家提供发表见解的机会。在这种背景下，哈耶克和弗里德曼分别在1974年和1976年获得诺贝尔经济学奖。随后，芝加哥学派的舒尔茨和斯蒂格勒又分别于1979年和1982年获得诺贝尔经济学奖。</p>
</blockquote>
<ol start="2" type="1">
<li>资本绑架国家，08次贷危机便是这般。</li>
</ol>
<blockquote>
<p>现代资本主义就形成了一种奇特的局面。一方面，生产资料仍然是私人所有，而且高度集中在少数最富有的资本家手中。这些资本家投资所得的利润自然也是全部据为己有。另一方面，资本家投资所造成的风险却要由全社会共同承担。利润是私有的、风险却是社会的。</p>
</blockquote>
<ol start="3" type="1">
<li>所以现今许多“成功企业家”的说教、福报论都那般刺耳、虚伪，他们无法反思自己的成功更源自国家方向，而过分归结、吹捧自己的不懈奋斗。</li>
</ol>
<blockquote>
<p>中国的资本积累是怎么建立的呢？首先，这是在世界资本主义进行产业转移的背景下成长起来的。这种历史条件使得新兴富人群体的成长异常的轻松，也在思想上极为排斥劳动者和任何代表劳动者的理论。其次，中国的这些“先富”们本身也处在世界经济的外围—半外围，拿不出足够的东西来减缓社会矛盾——就像英美等国曾经部分做到的那样。</p>
</blockquote>
<ol start="4" type="1">
<li></li>
</ol>
<blockquote>
<p>不可否认，普通群众的收入从货币数量上来说的确是增长了，购买普通消费品（如食品、服装、电子产品等）也都很容易，但是面对住房、医疗和教育这三座大山，大批群众不得不望洋兴叹。根据中国指数研究院所编制的“中房指数”，从1998年住房改革以来，全国主要城市住房价格平均来说增长了十多倍，而城镇居民的人均可支配收入在同一时期只增长了3.5倍。在教育上，曾经由国家承担的一部分教育支出变成了个人的负担，个人所缴纳的学杂费占全部教育经费的比重从1992年的5%增长到2010年的15%，最高曾接近19%。医疗卫生也是如此。个人所缴纳的费用占全部卫生费用的比重从1978年的20%增长到2011年的35%，而在2001年竟高达60%。<strong>面对这些生活必要支出的不断上涨，我们不禁要问：我们究竟富起来没有，或者说究竟富了谁？</strong></p>
</blockquote>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>书单</tag>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>BOOK-01-大癫狂:非同寻常的大众幻想与群众性癫狂</title>
    <url>/2021/04/15/BOOK-01-%E5%A4%A7%E7%99%AB%E7%8B%82-%E9%9D%9E%E5%90%8C%E5%AF%BB%E5%B8%B8%E7%9A%84%E5%A4%A7%E4%BC%97%E5%B9%BB%E6%83%B3%E4%B8%8E%E7%BE%A4%E4%BC%97%E6%80%A7%E7%99%AB%E7%8B%82/</url>
    <content><![CDATA[<h1 id="book-01-大癫狂非同寻常的大众幻想与群众性癫狂">BOOK-01-大癫狂:非同寻常的大众幻想与群众性癫狂</h1>
<blockquote>
<p>"这个计划在实质上是一种极大的罪恶，其目的是最大限度地激起大众的癫狂，并把这种狂热持续不断的保持下去。股票的价值被人随意操控，直到高到看不到顶，它那些口头承诺的红利，将永远不可能被兑现。"</p>
</blockquote>
<span id="more"></span>
<blockquote>
<p>"只要大众中间蔓延起怀疑的风潮，它就会慢慢地冰消瓦解，终至于无。"</p>
</blockquote>
<p>书名：<a href="https://book.douban.com/subject/3265233/">《大癫狂:非同寻常的大众幻想与群众性癫狂》</a></p>
<blockquote>
<p>内容简介 from 豆瓣：</p>
<p>本书给我们展现了一幅幅金融发展史上的经典场景：400年前，荷兰人为了郁金香球茎而神魂颠倒。随后，法国人为了一个虚假的“密西西比计划”而陷入了巨大的投机狂热之中； 300年前，以理智著称的英国人同样在“南海泡沫”事件中无力自拔。上自权贵公卿，下自庶民百姓，都随股市暴涨暴跌而不得安宁。</p>
<p>无论哪一个时代，无论是西方还是东方，人类群体中总会间歇性地出现某种癫狂情绪。它们或者发生在一场莫名其妙的运动中，或者发生在金融证券和商业市场上。无论是出于发财致富的冲动欲望，还是出于对他人行为亦步亦趋的效仿——“不必通过辛苦劳动就一夜暴富”是所有癫狂事件共有的人性根基。当美梦最终破灭，几乎所有人都将面临可笑、可叹或可悲的结局。</p>
</blockquote>
<p><strong>且先谈论书</strong>，它是当年现象忠诚的记录者，书里大多是当时群众的反应——大段的环境、小人物描写等。或许是抱错了期待，书对事件前因后果的分析比较细碎，更无对其金融经济意义的评论。大约还是要靠读者见微知著，自行总结了。只是缺少经济学知识的我，很期待着能就事件了解货币发行规律等，落下了遗憾。</p>
<p><strong>再谈感想</strong>，无论南海泡沫，密西西比计划，还是郁金香球茎事件，投机行为从地窖口吹出微风，到形成刮遍社会的飓风，潜移默化的，将暴富的谎言灌输给所有人。书中所描述，当暴富谎言到高潮时，无论商贾贵妇，又或是原本勤勤恳恳工作的农夫，都抵不住诱惑，将自身积蓄投入谎言中。不产生实际价值的投机行为，泡沫褪去之时侵吞国家财富，腐蚀个人精神。从投机暴富到赤贫的历程，将务实的人异化为只追求信息差、数字计算的的投机者，失去勤劳朴实的本质。</p>
<p>虽然现今回看，炒卖郁金香的行为略显荒诞可笑。但假设置身当时，当左邻右舍都在谈论郁金香球茎，昨天还 一起吃大排档吹水的哥们，再相见时就靠倒卖球茎开起了超跑住上了大豪斯，真能抵挡住心动吗。至少我很难抑制住“试一下水”的想法。看穿不难，抵挡大众里泛滥的盲目热潮很难。</p>
<p>所幸目前政府有强有力的监管与政策，未让大众层面的“幻想与癫狂”发生。然而小领域中，那么多所谓的“风口”依然在造就着“财富神话”，国内所谓的球鞋文化与畸形的球鞋倒卖市场便是一例。</p>
<p>对于个人而言，没有实际价值或收益期望绑定的商品/承诺，大约都是击鼓传花骗人入局的陷阱。看完此书，且让自己铭记两点吧：</p>
<ol type="1">
<li>没有足够的智慧前，保持理智，看不到长期价值的热闹市场，绝不入局；</li>
<li>若持续观察、学习，攒足知识及财力，想做弄潮儿时，做好风险防备，入局绝不加杠杆。毕竟，个人终究只是条鱼。</li>
</ol>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>书单</tag>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>BOOK-03-白鹿原+显微镜下的大明</title>
    <url>/2021/06/29/BOOK-03-%E7%99%BD%E9%B9%BF%E5%8E%9F-%E6%98%BE%E5%BE%AE%E9%95%9C%E4%B8%8B%E7%9A%84%E5%A4%A7%E6%98%8E/</url>
    <content><![CDATA[<h1 id="book-03-白鹿原显微镜下的大明">BOOK-03-白鹿原+显微镜下的大明</h1>
<blockquote>
<p>忙里偷闲看完两本书，抬头时，已是毕业散场时。</p>
</blockquote>
<span id="more"></span>
<h2 id="白鹿原">1. 白鹿原</h2>
<p>不曾看过影视作品，陈忠实仙逝之时也没能勾起阅读的欲望。</p>
<p>只是六月头暑热难耐，猛地拍脑子想寻一本能让人酣畅淋漓一口气读下来的长篇，能让人沉浸地忘了炎阳。而且，希望是国内作家的书，许久没品读道地的、带着中华地域味儿的文字了。</p>
<p>于是乎，《白鹿原》被翻出来，花三五天刷刷地看完——身心飘荡在那原上，浮沉半百年。</p>
<p>读完许久，回过神来，瞅见的是对小农经济、封建大家长的美化及一点点的追忆。表面记录着近代风云变幻的历史狂风刮到白鹿原上的风沙，实则在风啸声中有着低沉的叹息声。</p>
<p>未去查作者的生平、家族，单纯地从文字中如此感受罢。</p>
<p>不能共情，尤其是带着历史唯物主义去看待时：</p>
<blockquote>
<p>白嘉轩在思索人生奥秘的时候，总是想起自古流传着的一句咒语：白鹿村的人口总是冒不过一千，啥时候冒过了肯定就要发生灾难，人口一下子又得缩回到千人以下。他在自己的有生之年里，第一次经历了这个人口大回缩的过程而得以验证那句咒语，便从怀疑到认定：白鹿村上空的冥冥苍穹之中，有一双监视着的眼睛，掌握着白鹿村乃至整个白鹿原上各个村庄人口的繁衍和稀稠……</p>
</blockquote>
<p>是所谓的一双监视的眼睛吗，还是千百年来农耕模式下生产力的制约呢？</p>
<h2 id="显微镜下的大明">2. 显微镜下的大明</h2>
<p>何谓“苛政猛于虎”？非“苛政”时，由系统结构引发的，不可避免的上位者对下位者的剥削又是怎么一回事？</p>
<p>若罗列统计数据、或是以“横尸遍野”“民怨鼎沸等词汇概述，总归是来得不真切——那距离仿佛是观察着土堆上的蚁群。</p>
<p>于是，这本书以几个事件呈现底层群众的生活态势。</p>
<p>借作者的序言吧：</p>
<blockquote>
<p>我相信，只有见到这些最基层的政治生态，才能明白庙堂之上的种种抉择，才能明白历史大势传递到每一个神经末梢时的嬗变。</p>
</blockquote>
<p>看完书后，不由感叹，</p>
<ul>
<li><p>王朝的腐朽总是如暗流，直至积重难返。</p>
<p>强如明太祖朱元璋，精心设计的兼顾效率与公平的黄册制度，亦随执政者变更导致的执行力下降、存储规模激增等，沦为废纸。与黄册制度一起消散为尘埃的，还有曾经强盛的大明。</p></li>
<li><p>为官者，“稳定”永远是保守且正确的选择。</p>
<p>各式腐败、冤案难以解决，或是赖成了糊涂账，总是不难见到其中有求“多一事不如少一事”的官员身影。当官者不能于一地执政过长的要求，隐性地促使他们将案件往小的办、往迅速解决的方式办——不求百分百公平公正，但求任期内无大乱。有胆识、求真的官员总是少的，搅在一堆保守者中，也未必能将案件掀起小浪花。</p>
<p>话又说回来，“稳定”绝对不是贬义——只是看到一些活生生的冤案，深感无奈。</p></li>
<li><p>故事着实有趣。可曾想所谓一地的“龙脉与风水”，真能惹得当地人上访斗争几代。（第二章《笔与灰的抉择 婺源龙脉保卫战》）</p></li>
</ul>
<p>最后，摘录关于大明黄册库毁灭的片段吧：</p>
<blockquote>
<p>大批士兵跳上湖中五岛，踹开库房大门。他们顾不上感叹卷帙浩繁，把那些曾经悉心晾晒的黄册一摞一摞地搬了出去，粗暴地扔上小船运走。中国古代有造纸甲之法，把软纸一层层相叠捶实，剪裁成甲，防御效果不错。黄册都是上好绵纸所制，正是做纸甲的好材料。另外明军装备了大量火器、火箭，将绵纸搓成细条蘸上火药，即是上好的药捻和引火折。 这是一幕极具象征意味的画面。曾令大明江山永固的黄册，在风雨飘摇中被一一扯碎。漫天的纸屑飞舞于后湖之上，万亿大明子民的户籍化为甲胄和火器，以毁灭自己的方式，试图成为挽救这个王朝的最后希望。</p>
</blockquote>
<p>沧桑历史。</p>
<p>这好比，未来地球陷落时，存储着互联网数据的偌大服务器被一一拆解、熔断成钢铁，冶炼为武器的场景吧。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>书单</tag>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>BOOK-04-AI极简经济学</title>
    <url>/2021/07/14/BOOK-04-AI%E6%9E%81%E7%AE%80%E7%BB%8F%E6%B5%8E%E5%AD%A6/</url>
    <content><![CDATA[<h1 id="book-04-ai极简经济学-来自黑盒子外的凝视">BOOK-04-AI极简经济学 来自黑盒子外的凝视</h1>
<blockquote>
<p>它来到孤峰脚下，用触须摸了摸这顶天立地的存在，发现孤峰的表面坚硬光滑，但能爬上去，于是它向上爬去。没 有什么且的，只是那小小的简陋神经网络中的一次随机扰动所致。——《三体》</p>
</blockquote>
<p>在和AI相关的领域学习着，就像是蚂蚁在无尽的迷宫里寻求着出路——试图推动一点点科研的进展。不过，有些时候也该直起身子，低头瞅瞅脚下的迷宫，看看我们从何而来，出口又通往何方。</p>
<p>说得玄乎罢了。前些日子，论文看不进的时间里，翻阅了本《AI极简经济学》。</p>
<span id="more"></span>
<h2 id="讲了些啥">1. 讲了些啥</h2>
<p>吐槽在先：大约是经济学家写的缘故，大约是我经济学知识浅薄的缘故，大约也是太极简的缘故，看完后并不能将书中大多内容与经济学联系在一起。不过，不少观点还是值得借鉴的。</p>
<p>（另，书中”AI“大多指深度学习算法模型，少部分指模型与机器人结合的产物。）</p>
<ul>
<li><p>老生常谈，深度学习发展和约束</p>
<p>书第一部分刨去算法的实现细节，把模型视作黑箱，从数据的输入和结果的输出介绍了AI的功能与可能。</p></li>
<li><p><strong>预测变得廉价，判断越显昂贵</strong></p>
<p>技术乃至生产力的变革，将推动某些事物成本的极具下降，进而该事物迅速推广，改变人们的行为方式。此前的工业革命，不止带来动力，而是连带着重塑着人们的生活习惯。比如，廉价的照明改变着人们的作息。</p>
<p>如今的AI，使<strong>“预测”变得廉价</strong>，能基于输入的数据，轻松地给出<strong>行动建议</strong>。</p>
<p>与之相对的，有两个事物会变得昂贵。一来，“预测”的互补品——数据，这无需多言，毕竟现今的算法大多基于统计推断；另外，廉价意味着广泛使用，面对充斥生活的行动建议，高效高质地<strong>“判断”</strong>便显得愈发昂贵。</p>
<p>是否遵从预测行动？是否能在预测的基础上改进行动？更进一步的，能思索有了“预测”的能力后，在自己的业务场景中能否扩展乃至变革行动模式？</p>
<p>人的判断力显得愈发昂贵——这类判断力源自终身的、综合的学习，对社会的认知，而非算法从大数据中归纳的规律。</p></li>
<li><p>站在企业管理者的角度</p>
<ul>
<li><p>“工程再造”</p>
<p>AI的能力不仅仅是通过迅速的预测简化工作。作为管理者，当意识到其对生成流程的影响。书中以“预测MBA申请人排名的模型”为例：</p>
<blockquote>
<p>它能预测所有MBA申请人的排名。为了从这台预测机器中获得全部好处，学校必须重新设计其工作流程。这就需要把<strong>人工排序的任务取消</strong>，并且扩大该MBA课程的营销范围，因为人工智能会提高申请人范围扩大所带来的回报（对什么人能成功做出更好的预测，降低评估申请人的成本）。学校将修改奖励举措（如奖学金和经济补助），并提高潜在优等生的入学率。最后，学校还会调整工作流程的其他环节，善加利用能提供即时的录取决策所带来的优势。</p>
</blockquote>
<p>工作流程被重塑，以基于AI预测实现效益最大化。</p>
<p>更多的，AI未来的发展甚至有机会变革商业模式。</p>
<blockquote>
<p>人工智能预测的准确度跨越了某个临界值，以至于改变了亚马逊的商业模式。这种预测准确到，直接把它预测你想要购买的商品寄送给你（甚至不用等到你下订单）。</p>
<p>……</p>
<p>如果这是一种更好的商业模式，为什么亚马逊还没有这么做呢？因为如果现在执行它，收集和处理退货商品的成本将远远超出从顾客那里多赚到的钱。比方说，如今我们要退掉寄来的95%的商品。这对我们来说会很烦人，对亚马逊来说也代价高昂。这样的预测，对亚马逊而言还不够好。</p>
</blockquote></li>
<li><p>管理者的视野</p>
<p>体现判断力的时候到了。管理者需要学会分解当前工作流程，于合适的环节引入AI预测技术；再者，了解技术发展动向，对未来可能的模式变革做出准备。</p></li>
</ul></li>
<li><p>社会变化</p>
<p>廉价的预测必然带来就业岗位的变化。大趋势来看，许多<strong>现有进行“预测”的工作会消失或改头换面——岗位仍存</strong>，技能要求已变化。一如当年Excel等电子表格出现时，熟练执行复杂计算填表的技能不再被需要，取代的，是针对表格数据分析能力的要求。</p>
<p>而值得思考的现象，在于：</p>
<blockquote>
<p>其他与判断有关的工作会更为普遍，但它们对技术的要求或许不如人工智能所取代的岗位高。当今许多高薪职业的核心技能都包括了预测，如医生、金融分析师和律师。正如机器对于方位的预测减少了伦敦出租车司机相对较高的收入，却增加了收入相对低的优步司机的人数那样，我们预测，医疗和金融方面也会出现相同的现象。随着任务的预测部分逐渐能自动完成，更多的人可填补这些岗位，其<strong>所需的技能也收窄到与判断相关的技能内。</strong>如果预测不再是约束性的限制条件，对更广泛的互补性技能的需求或许会增加，这会带来<strong>更多低薪</strong>的就业机会。</p>
</blockquote>
<p>尽管从一个AI研究人员的角度（姑且算是吧），AI发展还远不及上述假设的程度。但警示是，<strong>注意培养“判断型”能力，以提升个人竞争力。</strong></p>
<p><em>TODO：抽空再补上个人对“判断型”能力的理解吧。</em></p></li>
</ul>
<h2 id="随记的感叹">2. 随记的感叹</h2>
<ul>
<li><blockquote>
<p>2017年3月，谷歌首席执行官桑达尔·皮查伊（Sundar Pichai）在年度I/O活动的主题演讲中宣布，该公司正从“以移动优先的世界转向以人工智能优先的世界。”</p>
</blockquote>
<p>短短4年若沧海桑田，移动App百花齐放的年代逝去了，当年没事就找各种新奇App把玩的时光一去不返。现今触屏手机上App的交互体验基本被开采透彻，常驻手机的应用已经成长为巨头。</p></li>
<li><blockquote>
<p>实体店不能预测单个客户的需求，但他们可以预测一群客户可能的需求。把到访某一地点的客户汇聚起来，实体店对冲了单个客户的需求不确定性。要转向以个别家庭为基础的先寄后买模式，需要更多有关单个客户需求的信息，从而消解实体店的竞争优势。</p>
</blockquote>
<p>除了实体店”触摸实体，直观体验“的优势外，为实体店与网店间差异提供了新的解读视角。</p></li>
</ul>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>书单</tag>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>BOOK-05-富爸爸穷爸爸</title>
    <url>/2021/10/07/BOOK-05-%E5%AF%8C%E7%88%B8%E7%88%B8%E7%A9%B7%E7%88%B8%E7%88%B8/</url>
    <content><![CDATA[<h1 id="book-05-富爸爸穷爸爸">BOOK-05-富爸爸穷爸爸</h1>
<span id="more"></span>
<h2 id="小结">1. 小结</h2>
<p>久闻大名却迟迟未拜读。览毕深感惭愧，为自己过往逃避、不作为的穷人心态而耻；亦倍感振奋，行动总是为时未晚的。</p>
<p>那么，纸上得来终觉浅，绝知此事要躬行。接下来的日子，开始罗列计划去实践吧。</p>
<h2 id="文章摘录随感">2. 文章摘录&amp;随感</h2>
<blockquote>
<ul>
<li><p>我的一个爸爸总是习惯说“我可付不起”，而另一个爸爸则禁止我们说这样的话，他坚持让我这样说：“我怎样才能付得起？”这两句话，一句是陈述句，另一句是疑问句。一句让你放弃，而另一句则促使你去想办法。</p></li>
<li><p>我的穷爸爸也会说“我对钱不感兴趣”或“钱对我来说并不重要”，而我的富爸爸则说“金钱就是力量”。</p></li>
<li><p>富爸爸继续说：“如果你是那种没有勇气的人，生活每次推动你，你都会选择放弃。如果你是这种人，你的一生会过得稳稳当当，不做错事、假想着有事情发生时自救，然后慢慢变老，在无聊中死去。你会有许多朋友，他们很喜欢你，因为你真的是一个努力工作的好人。你的一生过得很安稳，处世无误。但事实是，你向生活屈服了，不敢承担风险。你的确想赢，但失败的恐惧超过了成功的兴奋。只有你知道，在你内心深处，你始终认为你不可能赢，所以你选择了稳定。”</p></li>
</ul>
</blockquote>
<p>观念潜移默化的力量——尝试改变自我吧，安贫乐道不是懒惰的借口。若对物质确实有所追求，便应正视金钱，追求金钱。并且，跳出旧有“打工人”的思维。</p>
<blockquote>
<ul>
<li>“富人获得资产，而穷人和中产阶级获得负债，只不过他们以为那些负债就是资产。”</li>
<li>资产是能把钱放进你口袋里的东西。 负债是把钱从你口袋里取走的东西。</li>
<li>最重要的规则是弄清资产与负债的区别，一旦你明白了这种区别，你就会竭尽全力只买入能带来收入的资产，这是你走上致富之路的最好办法。坚持下去，你的资产就会不断增加。同时还要注意降低负债和支出，这也会让你有更多的钱投入资产项。很快，你就会有钱来考虑进行一些投资了，这些投资能给你带来100％，甚至是无限的回报</li>
<li>失去受教育的机会。人们经常把他们的房子、储蓄和退休金计划作为他们资产项的全部内容。因为没钱投资，也就不去投资，这就使他们无法获得投资经验，并永远不会成为被投资界称为“成熟投资者”的人。而最好的投资机会往往都是先给那些“成熟投资者”的，再由他们转手给那些谨小慎微的投资者，当然，在转手时他们已经拿走了绝大部分的利益。</li>
</ul>
</blockquote>
<p>逃离消费主义的陷阱！请用投资的收益来适当奖赏自己，而非将金钱兑换为负债。</p>
<blockquote>
<ul>
<li>他们混淆了他们的职业和事业，他们可以在银行工作，但他们仍应有自己的事。</li>
<li>从事你所学的专业的可怕后果在于，它会让你忘记关注自己的事业。人们耗尽一生去关注别人的事业并使他人致富。</li>
<li>当我说关注自己的事业时，我的意思是建立自己牢固的资产。一旦把1美元投入了资产项，就不要让它出来。你应该这么想，这1美元进了你的资产项，它就成了你的雇员。关于钱，最妙的就是让它可以一天24小时不间断工作，还能为你的子孙后代服务。你要照常去工作，做个努力的雇员，但要不断构筑你的资产项。</li>
</ul>
</blockquote>
<p>说来惭愧，至今仍未思考清自己所欲追求的事业。愿持续的思索追寻，能在2021年完结前找到所爱。</p>
<blockquote>
<ul>
<li>​ 第一是会计，也就是我说的财务知识。如果你想建立一个自己的商业帝国，财务知识是非常重要的。你管理的钱越多，就越要精确，否则这幢大厦就会倒塌。这需要左脑来处理，是细节的部分。财务知识能帮助你读懂财务报表，还能让你辨别一项生意的优势和劣势。 ​ 第二是投资，我把它称为钱生钱的科学。投资涉及策略和方案，这要右脑来做，是属于创造的部分。 ​ 第三是了解市场，它是供给与需求的科学。这要求了解受感情驱动的市场的“技术面”。</li>
</ul>
</blockquote>
<p>除了学术能力，综合地提升个人财商对人生有大作用。</p>
<blockquote>
<ul>
<li><strong>忙碌的人常常是最懒惰的人。</strong></li>
<li>在今天这个快速变化的社会中，你学到的东西再多都不算多，因为当你学到时往往就已经过时了。问题在于你学得有多快，这种技能是无价之宝。</li>
<li>停下你手头的活儿。换句话说，就是先停下来，评估一下你的做法中哪些有效，哪些无效。做同一件事情却希望有不同的结果是神志不清的表现。不要做那些无效的事情，找一些有效的事情去做。</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>书单</tag>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>BOOK-06-投资书籍小览</title>
    <url>/2021/10/20/BOOK-06-%E6%8A%95%E8%B5%84%E4%B9%A6%E7%B1%8D%E5%B0%8F%E8%A7%88/</url>
    <content><![CDATA[<h1 id="book-06-投资书籍小览">BOOK-06-投资书籍小览</h1>
<blockquote>
<p>持续更新。近来闲暇开始慢慢阅读投资理念相关的书籍。</p>
</blockquote>
<span id="more"></span>
<h2 id="投资中最简单的事">1. 投资中最简单的事</h2>
<p>投资理念为道，他人之道可借鉴学习打开眼界，更需经个人实践总结验证，最终归纳出个人投资之道；</p>
<p>投资策略为术，作为投资小白， 太多术语未了解。</p>
<p>纸上得来终觉浅，绝知此事要躬行。一句话，看多一本后抓紧下场实践吧。</p>
<p><img src="./1.png" /></p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>书单</tag>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>BOOK-07-工作消费主义和新穷人</title>
    <url>/2022/03/25/BOOK-07-%E5%B7%A5%E4%BD%9C%E6%B6%88%E8%B4%B9%E4%B8%BB%E4%B9%89%E5%92%8C%E6%96%B0%E7%A9%B7%E4%BA%BA/</url>
    <content><![CDATA[<blockquote>
<p>武汉夜雨狂泻，狂躁的雨滴砸落地面。哦不，该称之为水面了。持续一日的雨水，在柏油路上新铺一层水面。</p>
<p>听闻“麻豆传媒”的一个摄影团队被抓获，翻看知乎里对事件的评价，产业链的介绍、情色作品的科普。总是会错过些“艺术”，错过了汤不热时代，一如曾经错过了快播的便捷。</p>
<p>如今，大约大部分人已是<strong>笑贫不笑娼</strong>了。</p>
</blockquote>
<span id="more"></span>
<p>一直提醒自己用发展的眼光观察、评析事物，却不时忘记亦要时常回顾历史，看看我们是如何一步步走成今天的道路。</p>
<ul>
<li>关于劳动</li>
</ul>
<p>这本书，回顾随生产力进步与社会发展的需要，人们如何一步步丢失职业自豪，被塑造成机械化的部件，进而一步步被挖去朴素的道德，被灌输用不断的消费来填充自己.</p>
<blockquote>
<p>越来越多的人认为，从工匠变成工人时失去的人的尊严，只有通过赢得更多盈余才能恢复。这种变迁中，努力工作能使人们道德升华的呼声日益衰弱。现在，衡量人们声望和社会地位的是工资的差别，而不是勤于工作的道德或惰于工作的罪恶。</p>
</blockquote>
<ul>
<li>关于穷人</li>
</ul>
<p>同时，还残酷地揭露着某些国家对穷人的“污名化”——生产力进步不再需要本国劳工时，穷人不再是失业，而是单纯的<strong>过剩</strong>人口。</p>
<blockquote>
<p>“失业者”虽然暂时没有工作，但一旦环境好转，他们就有望回到“生产者”的行列，一切也将回到正轨。“过剩”的人则不同，他们是多余的、编外的，不被需要。他们要么出生在一个“饱和”的社会里（即社会的续存无需更多的人从事生产），要么由于经济和技术进步（即有了新的生产力，较少的人员参与就能满足日益增长的商品和服务需求），变得不再必要。</p>
</blockquote>
<p>过剩的穷人开始背负各种污蔑，成为各种社会负面情绪转嫁的出口。媒体不断吹风造势，让大众逐渐接受人穷必是其自身有罪过，合理化对穷人的冷漠。以至于确实能见到身边有人，抱着书中所提态度：</p>
<blockquote>
<p>他们确实有一个共同点：在其他人看来，他们没有存在的必要，正是因为完全无用才会被归入社会底层——若他们消失，其他人会生活得更好。他们无疑是美丽风景线中的污渍，是丑陋又贪婪的杂草，他们对园林的和谐之美没有任何贡献，还偷走了其他植物的养分。如果他们消失，所有人都会获益。</p>
</blockquote>
<p>这般冷漠蔓延，剩下保有对生命基本尊重与对人类良知的人将如《狂人日记》中一般，道“我疯了”吧。</p>
<p>穷人们真是那般懒散罪恶吗，更多时候只是他们的故事被改写，从<strong>被剥夺</strong>的故事被叙述为自甘堕落的故事。</p>
<ul>
<li>关于消费</li>
</ul>
<blockquote>
<p>如果消费是衡量成功人生的标准，衡量幸福的标准，甚至是衡量尊严的标准，那么人类欲望的潘多拉之盒已经打开，再多的购买和刺激的感觉，都不能唤回过去“达到标准”带来的满足感：现在根本就没有标准可言。终点线和参赛者一起前行，人们力图到达的目标永远领先一步之遥。</p>
</blockquote>
<p>为人嘛，求给自己立下标准，反抗下动物性的欲望吧。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>书单</tag>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>BOOK-08-蛤蟆先生去看心理医生</title>
    <url>/2022/06/09/BOOK-08-%E8%9B%A4%E8%9F%86%E5%85%88%E7%94%9F%E5%8E%BB%E7%9C%8B%E5%BF%83%E7%90%86%E5%8C%BB%E7%94%9F/</url>
    <content><![CDATA[<p>把问题留在这里，时时回顾思索吧。</p>
<span id="more"></span>
<blockquote>
<ul>
<li>“心理咨询向来是一个自发的过程，咨询师和来访者双方都得出于自愿。所以这就意味着，只有当你是为自己而不是为取悦朋友们才想咨询的时候，我们才能真正合作。</li>
<li>如果你要更好地理解自己，就需要跟自己的情绪做联结，并理解这些情绪。如果你否认它们，不论是用无视还是压抑的方式，结果都像是做了截肢，就如身体的重要部位被切掉了一样，你在某种程度上成了一个残缺的人。</li>
<li>能帮你的人是你自己，也只有你自己。有许多问题需要你向自己发问。比如你能停止自我批判吗？你能对自己好一些吗？也许最重要的问题是，你能开始爱自己吗？</li>
<li>如果你为自己负责，就会认识到你对自己是有自主权的。因此你就知道自己有力量来改变处境，更重要的是，有力量改变你自己。</li>
<li>第一个问题是 我是怎么看自己的？我好吗？第二个问题是：我是怎么看别人的？他们好吗？</li>
<li>一旦我们在童年决定用哪种态度和观点，我们就会在随后的人生里始终坚持自己的选择。这些态度和观点，变成我们存在的底层架构。从那以后，我们便建构出一个世界，不断确认和支持这些信念和个预期。换一个词来说，我们把自己的人生变成了一个’自证预言'。</li>
<li>有些人会竭尽所能地选择记住那些悲伤和不快乐的事件，而忘记或忽略美好的时光。这种活法看起来很容易让人抑郁。</li>
<li>我觉得我比过去更能顺应生活了。可我不会忘记自己曾经是那么消沉，那段记忆会永远留在那儿，或许就是对我的提醒，告诉我，<strong>滑落到生活边缘的人生</strong>是什么样的。</li>
<li>人们太容易让重要的事件就这么过去，忘记关注或为它们庆祝，也许是因为我们通常都只在事后才明白它们有多重要。</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>书单</tag>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>CLion_自定义WSL路径配置</title>
    <url>/2021/07/13/CLion-%E8%87%AA%E5%AE%9A%E4%B9%89WSL%E8%B7%AF%E5%BE%84%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="clion中对自定义路径安装wsl的配置">CLion中对自定义路径安装WSL的配置</h1>
<blockquote>
<p>CLion 中 WSL常规安装配置流程如下：</p>
<ul>
<li>官方文档 https://www.jetbrains.com/help/clion/how-to-use-wsl-development-environment-in-product.html#wsl-tooclhain</li>
<li>知乎 https://zhuanlan.zhihu.com/p/272522594</li>
</ul>
</blockquote>
<h2 id="问题描述">问题描述</h2>
<p>本人的WSL并非通过MS Store安装在C盘的默认目录，而是自定义了WSL安装的路径。</p>
<p>当前版本的CLion很愚蠢（见下图），<strong>Environment</strong>栏不支持手动填写路径，只会自动检测WSL默认安装路径下是否存在可用环境。这意味着我们无法手动指向自定义安装路径下的ubuntu.exe。</p>
<span id="more"></span>
<p><img src="./problem.jpg" /></p>
<h2 id="解决方案">解决方案</h2>
<p>CLion无法选择自定义路径WSL的<a href="https://intellij-support.jetbrains.com/hc/en-us/community/posts/360004135320-CLion-not-picking-up-WSL">issue</a>已经提了两三年了，也没见JetBrains fix😒</p>
<p>我只能取巧，不走<strong>WSL一栏</strong>配置，而是选择<strong>Remote host</strong>迂回实现配置，见下图：</p>
<p><img src="./solution.png" /></p>
<p>假定已经按照官方文档完成ubuntu_setup_env.sh的运行，我们直接把WSL中跑着的进程当远程服务器访问就好。</p>
]]></content>
      <categories>
        <category>工具人</category>
      </categories>
      <tags>
        <tag>环境配置</tag>
        <tag>WSL</tag>
      </tags>
  </entry>
  <entry>
    <title>Crawler_Elsevier Abstract爬取</title>
    <url>/2022/09/07/Crawler-Elsevier-Abstract%E7%88%AC%E5%8F%96/</url>
    <content><![CDATA[<blockquote>
<p>机缘巧合，需要帮朋友爬取些论文摘要。遂将任务探索过程及解决方案记录如下。</p>
<p>初次接触Requests，代码较为稚嫩，多多包涵。</p>
</blockquote>
<span id="more"></span>
<h1 id="需求描述">1. 需求描述</h1>
<p>在<strong>Elsevier</strong>数据库中，给定<strong>查询条件</strong>（如，搜索“题目、摘要、关键词中包含<code>Target</code>的论文”），检索论文，并存取论文标题及<strong>摘要</strong>。</p>
<h1 id="解决方案">2. 解决方案</h1>
<h2 id="前期准备">2.1 前期准备</h2>
<ul>
<li><p>python环境</p></li>
<li><p>创建个人API-Key <a href="https://dev.elsevier.com/apikey/manage">link</a></p>
<figure>
<img src="./image-20220908003127528.png" alt="image-20220908003127528" /><figcaption aria-hidden="true">image-20220908003127528</figcaption>
</figure></li>
<li><p>下载<em>Elsapy</em> 源码 <a href="https://github.com/ElsevierDev/elsapy">Github</a></p>
<figure>
<img src="./image-20220908003348189.png" alt="image-20220908003348189" /><figcaption aria-hidden="true">image-20220908003348189</figcaption>
</figure></li>
</ul>
<h2 id="摘要相关api一览">2.2 摘要相关API一览</h2>
<blockquote>
<p>注：<em>Elsapy</em>封装了对相关api的request（虽然要魔改下）。</p>
</blockquote>
<ul>
<li><p><a href="https://dev.elsevier.com/documentation/ScopusSearchAPI.wadl">Scopus Search API</a></p>
<p>通过向此API发起请求，我们能得到<em>Scopus</em>数据库中符合检索条件的摘要的<strong>URL</strong>。</p>
<figure>
<img src="./image-20220908003940929.png" alt="image-20220908003940929" /><figcaption aria-hidden="true">image-20220908003940929</figcaption>
</figure>
<p>后续<em>Elsapy</em>将此<strong>query</strong>参数进行了封装。</p>
<figure>
<img src="./image-20220908004250354.png" alt="image-20220908004250354" /><figcaption aria-hidden="true">image-20220908004250354</figcaption>
</figure>
<p>API 返回结果的文档在此： <a href="https://dev.elsevier.com/guides/ScopusSearchViews.htm">Scopus Search Views</a></p>
<p>可惜不够尊贵，个人版的返回json中不包括abstract</p>
<figure>
<img src="./image-20220908005338776.png" alt="image-20220908005338776" /><figcaption aria-hidden="true">image-20220908005338776</figcaption>
</figure>
<p>实际返回项如下图：</p>
<p><img src="./image-20220908005405331.png" alt="image-20220908005405331" style="zoom:67%;" /></p>
<p>故我们需要使用<strong>prism:url</strong>进行abstract的提取。</p>
<p><img src="./image-20220908005443232.png" alt="image-20220908005443232" style="zoom:67%;" /></p></li>
<li><p><a href="https://dev.elsevier.com/documentation/AbstractRetrievalAPI.wadl">Abstract Retrieval API</a></p>
<p>用上述的<strong>prism:url</strong>做参数，调用Abstract Retrieval API就可以得到目标文章的摘要信息了。</p>
<figure>
<img src="./image-20220908005754680.png" alt="image-20220908005754680" /><figcaption aria-hidden="true">image-20220908005754680</figcaption>
</figure>
<p>返回的<a href="https://dev.elsevier.com/guides/AbstractRetrievalViews.htm">Abstract Retrieval Views</a>.链接在此，其中的<strong>dc:description</strong>即为我们所需的摘要，<strong>dc:title</strong>为标题。</p></li>
</ul>
<h2 id="elsapy-开发">2.3 Elsapy 开发</h2>
<p><em>Elsapy</em>使用<em>Requests</em>，封装了对Elsevier各个api访问的类及方法。不过其在Exception handling等方面很不完善。好在其本身代码简单，结构清晰，个人便对其做简单的定制。</p>
<ul>
<li><p>基本使用</p>
<ol type="1">
<li><p>提供API-Key构建<code>ElsClient</code>对象，该对象负责向Elsevier发起请求；</p></li>
<li><p>再根据需求构建想访问的API的对象，如<code>ElsSearch</code>；</p></li>
<li><p>调用API对象的方法，进行访问。</p></li>
</ol>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> elsapy.elsclient <span class="keyword">import</span> ElsClient</span><br><span class="line"><span class="keyword">from</span> elsapy.elssearch <span class="keyword">import</span> ElsSearch</span><br><span class="line"><span class="keyword">import</span> time </span><br><span class="line"></span><br><span class="line">query_str = <span class="string">&quot;your_query&quot;</span></span><br><span class="line">user_key = <span class="string">&#x27;your_key&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    client = ElsClient(user_key)</span><br><span class="line">    doc_src = ElsSearch(query_str, <span class="string">&#x27;scopus&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; Start crawling.\t Time: &quot;</span> + time.asctime())</span><br><span class="line">    doc_src.custom_execute(client, get_num=<span class="number">20000</span>, save_json=query_str+<span class="string">&quot;.json&quot;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>改动</p>
<p>原本的<code>ElsSearch.execute</code>缺少异常处理，致使爬取中断。此外，我希望能指定爬取文章的数量，以及存储json的文件名。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">custom_execute</span>(<span class="params">self, els_client = <span class="literal">None</span>, get_num = <span class="literal">None</span>, get_all = <span class="literal">False</span>, save_json=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Executes the search. If get_all = False (default), this retrieves</span></span><br><span class="line"><span class="string">        the default number of results specified for the API. If</span></span><br><span class="line"><span class="string">        get_all = True, multiple API calls will be made to iteratively get </span></span><br><span class="line"><span class="string">        all results for the search, up to a maximum of 5,000.&quot;&quot;&quot;</span></span><br><span class="line">    api_response = els_client.exec_request(self._uri)</span><br><span class="line">    self._tot_num_res = <span class="built_in">int</span>(api_response[<span class="string">&#x27;search-results&#x27;</span>][<span class="string">&#x27;opensearch:totalResults&#x27;</span>])</span><br><span class="line">    self._results = api_response[<span class="string">&#x27;search-results&#x27;</span>][<span class="string">&#x27;entry&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> get_all <span class="keyword">is</span> <span class="literal">True</span> <span class="keyword">or</span> get_num <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> get_num <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:     </span><br><span class="line">            quota = get_num <span class="keyword">if</span> get_num &lt; self._tot_num_res <span class="keyword">else</span> self._tot_num_res</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            quota = self._tot_num_res</span><br><span class="line">  </span><br><span class="line">        failed_flag = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">while</span> self.num_res &lt; quota <span class="keyword">and</span> <span class="keyword">not</span> failed_flag:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&gt; Executing &#123;cur&#125; | &#123;total&#125;&quot;</span>.<span class="built_in">format</span>(cur = self.num_res, total = quota))</span><br><span class="line">            <span class="keyword">for</span> e <span class="keyword">in</span> api_response[<span class="string">&#x27;search-results&#x27;</span>][<span class="string">&#x27;link&#x27;</span>]:</span><br><span class="line">                <span class="keyword">if</span> e[<span class="string">&#x27;@ref&#x27;</span>] == <span class="string">&#x27;next&#x27;</span>:</span><br><span class="line">                    next_url = e[<span class="string">&#x27;@href&#x27;</span>]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>): <span class="comment"># if failed, retry up to 5 times</span></span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    api_response = els_client.exec_request(next_url)</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">except</span> RequestException <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="built_in">print</span>(e)</span><br><span class="line">                    <span class="keyword">if</span> i &lt; <span class="number">4</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; retry: &#123;t&#125; times&quot;</span>.<span class="built_in">format</span>(t= i + <span class="number">1</span>))</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; TASK FAILED. Save current results.&quot;</span>)</span><br><span class="line">                        failed_flag = <span class="literal">True</span></span><br><span class="line">  </span><br><span class="line">            self._results += api_response[<span class="string">&#x27;search-results&#x27;</span>][<span class="string">&#x27;entry&#x27;</span>]</span><br><span class="line">    name = save_json <span class="keyword">if</span> save_json <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="string">&#x27;dump.json&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(name, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(json.dumps(self._results))</span><br><span class="line">    self.results_df = recast_df(pd.DataFrame(self._results))</span><br></pre></td></tr></table></figure>
<p>此外，实际爬取过程中遇到 <code>ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接</code>问题。尽管原<code>ElsClient</code>已经按照Elsevier限定的每秒1次访问设定了interval，我仍在此基础上增加0.5s间隔，从而解决上述问题。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">time.sleep( self.__min_req_interval - interval + <span class="number">0.5</span> ) <span class="comment"># sleep 0.5 more second	</span></span><br></pre></td></tr></table></figure>
<h2 id="完整代码">2.4 完整代码</h2></li>
<li><p>Scopus search</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> elsapy.elsclient <span class="keyword">import</span> ElsClient</span><br><span class="line"><span class="keyword">from</span> elsapy.elssearch <span class="keyword">import</span> ElsSearch</span><br><span class="line"><span class="keyword">import</span> time </span><br><span class="line"></span><br><span class="line">query_str = <span class="string">&quot;YOUR_QUERY&quot;</span></span><br><span class="line">user_key = <span class="string">&#x27;YOUR_KEY&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    client = ElsClient(user_key)</span><br><span class="line">    doc_src = ElsSearch(query_str, <span class="string">&#x27;scopus&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; Start crawling.\t Time: &quot;</span> + time.asctime())</span><br><span class="line">    doc_src.custom_execute(client, get_num=<span class="number">20000</span>, save_json=query_str+<span class="string">&quot;.json&quot;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>Abstract retrieval</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> elsapy.elsclient <span class="keyword">import</span> ElsClient</span><br><span class="line"><span class="keyword">from</span> elsapy.elsdoc <span class="keyword">import</span> AbsDoc</span><br><span class="line"></span><br><span class="line">abs_field = <span class="string">&#x27;dc:description&#x27;</span></span><br><span class="line">title_field = <span class="string">&#x27;dc:title&#x27;</span></span><br><span class="line">publication_field = <span class="string">&#x27;prism:publicationName&#x27;</span></span><br><span class="line"></span><br><span class="line">user_key = <span class="string">&#x27;YOUR_KEY&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_json2pd</span>(<span class="params">file</span>):</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        data = json.load(f)</span><br><span class="line">    <span class="keyword">return</span> pd.json_normalize(data)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crawl_abstracts</span>(<span class="params">df, client</span>):</span></span><br><span class="line">    failed_list = []</span><br><span class="line">    abstracts = []</span><br><span class="line">    titles = []</span><br><span class="line">    publications = []</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&gt;&gt;&gt; Start crawling.\t Time: &quot;</span> + time.asctime())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, url <span class="keyword">in</span> <span class="built_in">enumerate</span>(df[<span class="string">&#x27;prism:url&#x27;</span>]):</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&gt; Parsing &#123;cur&#125; / &#123;total&#125;&quot;</span>.<span class="built_in">format</span>(cur = i + <span class="number">1</span>, total = <span class="built_in">len</span>(df[<span class="string">&#x27;prism:url&#x27;</span>])))</span><br><span class="line">        abs_doc = AbsDoc(url)</span><br><span class="line">        rst = abs_doc.read(client)</span><br><span class="line">        <span class="keyword">if</span> rst:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                abstracts.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][abs_field])</span><br><span class="line">                titles.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][title_field])</span><br><span class="line">                publications.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][publication_field])</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&gt; &#123;cur&#125; - th failed.&quot;</span>.<span class="built_in">format</span>(cur = i + <span class="number">1</span>))</span><br><span class="line">            failed_list.append(url)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(failed_list) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&gt; Retry failed url...&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> failed_list:</span><br><span class="line">            abs_doc = AbsDoc(url)</span><br><span class="line">            <span class="keyword">if</span> abs_doc.read(client):</span><br><span class="line">                <span class="keyword">try</span>: </span><br><span class="line">                    abstracts.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][abs_field])</span><br><span class="line">                    titles.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][title_field])</span><br><span class="line">                    publications.append(abs_doc.data[<span class="string">&#x27;coredata&#x27;</span>][publication_field])</span><br><span class="line">                <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Completed. Total crawled abstracts: &quot;</span>, <span class="built_in">len</span>(abstracts))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> titles, abstracts, publications</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    client = ElsClient(user_key)</span><br><span class="line">    json_file = <span class="string">&#x27;TITLE-ABS-KEY(inorganic compounds).json&#x27;</span></span><br><span class="line">    csv_path = json_file[:-<span class="number">5</span>] + <span class="string">&#x27;_2&#x27;</span> + <span class="string">&#x27;.csv&#x27;</span></span><br><span class="line"></span><br><span class="line">    df = load_json2pd(json_file)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 一点点来爬</span></span><br><span class="line">    cut_l, cut_r = <span class="number">1000</span>, <span class="number">5000</span></span><br><span class="line"></span><br><span class="line">    titles, abstracts, publications = crawl_abstracts(df[cut_l:cut_r], client) </span><br><span class="line">    abs_df = pd.concat([pd.DataFrame(titles),</span><br><span class="line">                        pd.DataFrame(abstracts),</span><br><span class="line">                        pd.DataFrame(publications)],</span><br><span class="line">                        axis=<span class="number">1</span>)</span><br><span class="line">    abs_df.to_csv(csv_path, header=<span class="literal">False</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="相关资料">3. 相关资料</h1>
<p>除上文中包含的链接外，</p>
<ul>
<li><p><a href="https://dev.elsevier.com/sc_search_tips.html">Scopus Search Guide</a></p>
<p>介绍所支持<strong>Query</strong>的关键词，表达式（基本上用户进行advanced search时的条件都可以实现）；</p></li>
<li><p><a href="https://dev.elsevier.com/api_key_settings.html">How much data can I retrieve with my APIKey?</a></p>
<p><img src="./image-20220908100750603.png" alt="image-20220908100750603" style="zoom:50%;" /></p></li>
<li><p><a href="https://dev.elsevier.com/support.html">Frequently Asked Questions</a></p>
<figure>
<img src="./image-20220908100837747.png" alt="image-20220908100837747" /><figcaption aria-hidden="true">image-20220908100837747</figcaption>
</figure></li>
</ul>
<h1 id="可优化点">4. 可优化点</h1>
<ul>
<li><p>多线程爬取</p>
<p>现在受制于Elsevier限制，每秒只能发送1次请求，导致爬虫龟速。或可申请多个API-Key，进行多线程爬取。</p></li>
</ul>
]]></content>
      <categories>
        <category>工具人</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker01-镜像/容器/仓库</title>
    <url>/2021/05/09/Docker01-%E9%95%9C%E5%83%8F-%E5%AE%B9%E5%99%A8-%E4%BB%93%E5%BA%93/</url>
    <content><![CDATA[<h1 id="docker01--镜像容器仓库-概念区分">Docker01- 镜像/容器/仓库 概念区分</h1>
<blockquote>
<p>摘录自：https://yeasy.gitbook.io/docker_practice/basic_concept/image</p>
</blockquote>
<h2 id="image-镜像">1. Image 镜像</h2>
<p>我们都知道，操作系统分为 <strong>内核</strong> 和 <strong>用户空间</strong>。对于 <code>Linux</code> 而言，内核启动后，会挂载 <code>root</code> 文件系统为其提供用户空间支持。而 <strong>Docker 镜像</strong>（<code>Image</code>），就相当于是一个 <code>root</code> 文件系统。比如官方镜像 <code>ubuntu:18.04</code> 就包含了完整的一套 Ubuntu 18.04 最小系统的 <code>root</code> 文件系统。</p>
<p><strong>Docker 镜像</strong> 是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像 <strong>不包含</strong> 任何动态数据，其内容在构建之后也不会被改变。</p>
<span id="more"></span>
<h3 id="分层存储">分层存储</h3>
<p>因为镜像包含操作系统完整的 <code>root</code> 文件系统，其体积往往是庞大的，因此在 Docker 设计时，就充分利用 <a href="https://en.wikipedia.org/wiki/Union_mount">Union FS</a> 的技术，将其设计为<strong>分层存储</strong>的架构。所以严格来说，镜像并非是像一个 <code>ISO</code> 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。</p>
<p>镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。</p>
<p>分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。</p>
<h2 id="container容器">2. Container容器</h2>
<p>镜像（<code>Image</code>）和容器（<code>Container</code>）的关系，就像是面向对象程序设计中的 <code>类</code> 和 <code>实例</code> 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。</p>
<p>容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 <a href="https://en.wikipedia.org/wiki/Linux_namespaces">命名空间</a>。因此容器可以拥有自己的 <code>root</code> 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。</p>
<p>每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为 <strong>容器存储层</strong>。</p>
<p>容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。</p>
<p>按照 Docker 最佳实践的要求，<mark>容器不应该向其存储层内写入任何数据</mark>，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 <a href="https://yeasy.gitbook.io/docker_practice/data_management/volume">数据卷（Volume）</a>、或者 <a href="https://yeasy.gitbook.io/docker_practice/data_management/bind-mounts">绑定宿主目录</a>，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。</p>
<p>数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。</p>
<h2 id="registry仓库">3. Registry仓库</h2>
<p>镜像构建完成后，可以很容易的在当前宿主机上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，<a href="">Docker Registry</a> 就是这样的服务。</p>
<p>一个 <strong>Docker Registry</strong> 中可以包含多个 <strong>仓库</strong>（<code>Repository</code>）；每个仓库可以包含多个 <strong>标签</strong>（<code>Tag</code>）；每个标签对应一个镜像。</p>
<p>通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 <code>&lt;仓库名&gt;:&lt;标签&gt;</code> 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 <code>latest</code> 作为默认标签。</p>
]]></content>
      <categories>
        <category>工具人</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>FLAG2021-1-马拉松gogogo</title>
    <url>/2021/02/28/FLAG2021-1-%E9%A9%AC%E6%8B%89%E6%9D%BEgogogo/</url>
    <content><![CDATA[<h1 id="flag2021-1-马拉松gogogo">FLAG2021-1-马拉松gogogo</h1>
<blockquote>
<p>来到2021，立下今年的第一个FLAG，年内持续训练，跑下一场42.193公里的马拉松。（要是能抽中今年汉马就好了）</p>
<p>持续更新ing</p>
</blockquote>
<p>2021-02-21开练前状态：</p>
<ul>
<li>63.5KG</li>
<li>平均半个月跑次步，5km，配速5'45</li>
</ul>
<span id="more"></span>
<h2 id="跑步日常">跑步日常</h2>
<ul>
<li><p>Day 2 体能的恢复还是要循序渐进的。连续两日的5km慢跑训练，已经让大腿隐隐酸痛。 这回准备马拉松，可是该更认真，科学的研究跑步了。</p></li>
<li><p>Day 3</p>
<p>尽管在外浪了一日，九点半还是换上短裤夜跑。前些日子大腿攒下的酸痛仍未褪去，只得勉强磨蹭着慢跑，约莫630的配速熬过了5km。 跑时庆幸明天总算迎来休息日，但打字的此时此刻，总觉得明天还是该撒丫子奔跑一回才是。</p></li>
<li><p>Day 7</p>
<p>跑者up主陆续进驻关注列表。正在学习前掌跑法。 话说，新手总是忍不住买装备[Lol]，下单了puma的ultraride，作为休息日的短距离慢跑鞋。</p>
<p>返校当日，例行来了圈环湖跑。</p>
<p><img src="./day07.jpg" style="zoom:30%;" /></p>
<p>杂谈几点：</p>
<ol type="1">
<li><p>跑鞋</p>
<p>此前买的<strong>Reebok Floatride RS ULTK</strong>偏大，但一直将就着。这回细细体验，深感自己以前跑时的容忍度之高——内长过长，跑时脚在鞋中“前不着村后不着店”。无后跟港宝提供的锁定感，脚趾又无法被鞋头包裹，跑时就像海盗船在风浪中闯荡😂。也正因鞋码不合适，只得用后掌滚动跑法，一点点磨蹭前行。</p></li>
<li><p>雨跑</p>
<p>第一回雨跑，日常的打底裤、短裤、上衣三件套外随手抄起件戴帽的拉链卫衣就出门了。好在有帽子护着，中雨里行进不至于被浇个透心凉。却是雨势渐小后，浑身衣物吸饱水分，将卫衣围在腰间，沉甸甸的。至于鞋袜，早就泡透了，鞋款并不透气，袜子也非专业，只能强忍着湿润的脚感跑完全程。</p>
<p>途中遇到专业跑者，一身装备好不潇洒专业，激起了我研究之心哈。</p>
<blockquote>
<p>雨跑装备总结：</p>
<ol type="1">
<li>空顶/全顶帽</li>
<li>速干袜</li>
<li>不冷的天——皮肤衣</li>
<li>寒冷且一定要跑的天——压缩臂套手套腿套来保温</li>
</ol>
<p>最后留个跑步装备<a href="https://www.zhihu.com/question/21790313/answer/1129045780">参考链接</a>：</p>
</blockquote></li>
<li><p>风景与心境</p>
<p>此前看张艺谋的《影》，觉得黑白墨色不过后期特效。真正置身水雾中时，惊觉水墨山水意境并不遥远。</p>
<p>天地茫茫，生机寥寥，除去不多的游人外，偶尔掠过的飞鸟或者水面啪嗒啪嗒的鸭子是不多的生气。</p>
<p><img src="./day07_2.jpg" /></p></li>
</ol></li>
<li><p>Day 52</p>
<p>武汉的3月属实不讨喜，气温在寒冷与湿冷间徘徊，见不着几日晴天。相应的，跑步的计划也被连绵的雨水打断了。瞧着一周的天气🤦‍♂️。</p>
<p><img src="./day52_01.jpg" style="zoom:30%;" /></p>
<p>来到四月，总算能偶尔逮住几个清爽的日子了。这不，刚入了新装备——韶音AS660骨传导耳机😁，迫不及待出门试用了。（具体使用体验，待过些日子再记录吧）</p>
<p><img src="./day52_03.jpg" style="zoom:50%;" /></p>
<p>配合先前购入的跑步腰带和导汗带，越来越像模像样了。一路跑着，甚至收到路过骑手的加油——一个人的跑步路上，暖心的便是短暂的会面与鼓励吧。</p>
<p>第52天，小有进步，跑出了东湖路线的个人距离和速度PB。</p>
<p><img src="./day52_02.jpg" style="zoom:30%;" /></p></li>
<li><p>Day 73</p>
<p>参加了“长江超级半程马拉松-嘉鱼站”。</p>
<p>第一个半马，来到了咸宁市属的县城——嘉鱼。小地方的马拉松，感觉出动了全城的大妈给跑者加油打气：见到穿旗袍的，穿白色练功服舞扇的，腰系红绸打腰鼓的，当然还少不了跳广场舞的……路线中，甚至包括了公路——水泥路滚烫，热气蒸腾。却也是在这样的道路上，收到路边观众、志愿者的加油，而动力倍增。 惯常都是夜跑，突然大清早起来跑半马着实不适应。早餐吃的晚了，跑的时候一直胀气。没准备帽子，太阳日渐升起，晒得人发晕。仍旧是坚持下来了：前十八公里，听着《细节的力量》，回顾新中国历史。路上瞅见在建的工厂，开垦的农田，感慨建国、发展之不易。后三公里，切换到李克勤和容祖儿的演唱会，试图用大音量激振起疲倦的双腿。</p>
<p><img src="./day74_02.jpg" style="zoom:70%;" /></p>
<p>顺利完赛，留下了充足的PB空间。</p>
<p><img src="./day74_01.jpg" style="zoom:30%;" /></p>
<p>半马大约成了这县城的节日。结束后的次日，选手大多离去，县城又回归安静。</p>
<p>祈祷能抽中个全马的签吧，感觉630配速蠕动过全马是有希望的哈哈。</p></li>
</ul>
<h2 id="day-x-全马">Day X 全马</h2>
<p>2021.11.19回来补个更新。</p>
<p>此间的日子：五月尝试了越野跑，剁手了二三双跑鞋，回校后加入跑协一同训练，各式抽签不中，靠手速总算抢到合肥全马的资格，踌躇满志备赛，末了遇上疫情，21年全部的赛事通通延期（取消）。</p>
<p>大约那些抽不中的签、跑不了的马，说是不幸，全是因为幸运都用在了遇上位可交心的读者，以及恋人——顺理成章又偷懒了半个月，11月跑量骤降。不过，年头立下的Flag可不能倒了。再拖下去，武汉的寒冬与雾霾可真把人封锁在室内无法出行了。</p>
<p>十三度，阴，AQI128，七点四十出头，开跑。中断了训练，又无正式赛事的补给与呐喊，便打算以6分配巡航，但求安全完赛。</p>
<p>起跑后，发现脑中只剩下不断缩减的数字，空荡荡的，不像村上或他人，奇思妙想不断涌上。</p>
<p>前15公里运动饮料，20公里盐丸，25公里能量胶，30公里盐丸。Pretty Crazy演唱会照常播着，低速慢摇，些许劳累，但精神亢奋。行至35km，自觉状态大好，剩下不过区区7.195公里，说不定还能再加加速——能量胶什么的，不用补给了。</p>
<p>不料跑到39公里处，像是被早早蹲守预瞄的狙击手点中一般，体能撞墙了。</p>
<p>从未跑过如此漫长的3公里，</p>
<p>似油料耗尽的柴油机，哼哧哼哧的发动机空响着，转速却越来越慢。步伐逐渐收窄，步频渐渐降低。头脑是清醒的，顺着神经元和突触，不断抽打、命令着双腿“给我动起来！”，双腿却不听使唤。不得已，只靠尽量倾斜的上身，甩着手臂，嘴里骂骂咧咧，努力跑过最后的距离——如果那样子也算跑的话。</p>
<p>最后二百米是最难忘的。口中断断续续念叨着各种精神力量源泉，Mamba Mentality，☀等等，拖着步子移动。双腿是全全然抽筋了的，从下到上感觉那筋像古筝的弦，不停抖动着，又感觉仿佛有条小蛇在腿上上下窜动。</p>
<p>然而，话说回来，总归是顺利完赛的了——一人跑的全马。愿能坚持冬训，愿明年能，真正的踏上赛道跑一回啊。</p>
<p><img src="./dayx_01.jpg" style="zoom:70%;" /></p>
<p>P.S. FLAG拔了，这篇大约到此停笔刚好。</p>
<p>P.S.2 信念约是累时瞅见腕上的手链，幸福约是赛后收到庆祝的花束。</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>日常</tag>
        <tag>打卡</tag>
      </tags>
  </entry>
  <entry>
    <title>FLAG2022-1-阅读书单</title>
    <url>/2022/01/09/FLAG2022-1-%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95/</url>
    <content><![CDATA[<p>2021年分明是较为清闲的一年，看得书却是近年来最少的一年。2022已至，决心在开年时列出今年的书单，年末再回首自己的完成情况吧。</p>
<p>不高估自己，且算每月两本，一年读<strong>24本</strong>已是小小的进步。闲时阅读，求广不求精，愿能涉猎各科，览阅人事。未必每本都有触动，暂且约定每读一本，于此留下至少百来字随感，若有触动，便是继续细书随笔吧。</p>
<p>2022，许愿：<strong>无畏，求知</strong>。</p>
<span id="more"></span>
<h1 id="书单1525">书单(15/25)</h1>
<h2 id="历史">历史</h2>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
《<a href="https://book.douban.com/subject/24316346/">美帝国的崩溃 : 过去、现在与未来</a>》</li>
<li><input type="checkbox" disabled="" />
《<a href="https://book.douban.com/subject/34869500/">被统治的艺术</a>》</li>
<li><input type="checkbox" disabled="" checked="" />
《<a href="https://book.douban.com/subject/3580750/">潜规则</a>》</li>
</ul>
<blockquote>
<p>出门上班，满眼小商小贩雇主雇员，下班上路，到处是行色匆匆的路人和讨价还价的顾客。想叫一声同志，招呼一声兄弟，真不知冲谁开口。</p>
</blockquote>
<p>不曾想，现时常用的“潜规则”一词，居然源自此书。</p>
<p>能直视现实里潜在运行的规则，约莫是放下书生意气的理想年华，行到经世为人识相的标志吧。</p>
<p>有史以来，有人群居处，自有不便置于台面的规则运行，或遵循，或抗拒，或自立新规。</p>
<h2 id="经管">经管</h2>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
《<a href="https://book.douban.com/subject/5346110/">穷查理宝典</a>》</li>
<li><input type="checkbox" disabled="" checked="" />
《<a href="https://book.douban.com/subject/21331443/">中国是部金融史 : 透过金融读懂中国三千年</a>》</li>
<li><input type="checkbox" disabled="" checked="" />
《<a href="https://book.douban.com/subject/10773362/">随机漫步的傻瓜 : 发现市场和人生中的隐藏机遇</a>》</li>
</ul>
<blockquote>
<ul>
<li>记者那一行中还是有不少懂得深思熟虑的人，只是主流媒体新闻依然不动大脑，只顾提供引人注意的噪声，而且没有什么机制能够区分两者。事实上，聪明的新闻记者反而遭到了惩罚。</li>
<li>投资人基于情感因素，采取的策略也会让他们偶尔才承受波动，但只要一有波动，幅度都很大。这叫做掩耳盗铃，把随机性塞到地毯底下。</li>
<li>“看好”或“看坏”这两个名词，是不必在不确定性状况下做事的人，例如电视评论员，或没有处理风险经验的人使用的。投资人和企业要赚的不是概率，而是白花花的钞票。因此对他们来说，某个事件发生的可能性多大并不重要，重要的是那件事发生时能赚多少钱。利润出现的频率有多高并不重要，结果多少才重要。</li>
</ul>
</blockquote>
<p>明辨噪音与真正的信息，意识到生活中的随机性，对事物不只考虑其发生概率更应计算其收益的<strong>期望</strong>。 知易行难。</p>
<h2 id="社会">社会</h2>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
《<a href="https://book.douban.com/subject/21966353/">贫穷的本质</a>》</li>
</ul>
<blockquote>
<p>贫穷并不仅仅意味着缺钱，它会使人丧失挖掘自身潜力的能力。</p>
</blockquote>
<p>人们生来并无无可跨越的差异，但贫富差异导致了人成长后彻头彻尾的分化。贫富差异下最大的差异之一，便是信息差。</p>
<blockquote>
<p>我们应该认识到，谁也没有那么明智、耐心或博学到能够为自己的健康做出正确的决定。同样，对于那些生活在富裕国家的人来说，他们周围充满了<strong>无形的助推力</strong>。</p>
</blockquote>
<p>贫穷存在陷阱，同样的才智，穷人不知道如何得到更廉价的贷款、更高营养的食物、无法计算投资教育的收益，视野只局限于对周身环境的认知——不止穷人，你我也是如此。穷人往往选择尽可能多的生育，反映的是他们的智慧。利用已知信息和家庭资源，养育更多子女才可能获得更高收益。</p>
<p>不过书中种种的实验表明，我们并非全然无能为力。一点点小的指点信息、微小的资金输入和政策扶持等，都能敲下阻隔阶级的厚墙上的砖头。</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
《社会学的想象力》</li>
<li><input type="checkbox" disabled="" checked="" />
《<a href="https://book.douban.com/subject/35593780/">工作、消费主义和新穷人</a>》</li>
</ul>
<p>见《BOOK-07-工作消费主义和新穷人》</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
《失控》</li>
</ul>
<h2 id="cs">CS</h2>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
《<a href="https://book.douban.com/subject/35084616/">隐私简史</a>》</li>
<li><input type="checkbox" disabled="" checked="" />
《史蒂夫·乔布斯传》</li>
<li><input type="checkbox" disabled="" checked="" />
《<a href="https://book.douban.com/subject/26297606/">从0到1 : 开启商业与未来的秘密</a>》</li>
</ul>
<p><strong>大胆尝试胜过平庸保守</strong>。且行且思。</p>
<p>摘录一些句子吧：</p>
<blockquote>
<ul>
<li>一旦你认为自己在抽奖，你就已经做好了亏损的心理准备。</li>
<li>创立公司前，能否回答下列七个问题：
<ol type="1">
<li>工程问题： 你的技术具有突破性，而不仅仅是稍有改进吗？</li>
<li>时机问题： 现在开创事业，时机合适吗？</li>
<li>垄断问题： 开创之初，是在一个小市场抢占大份额吗？</li>
<li>人员问题： 你有合适的团队吗？</li>
<li>销售问题： 除了创造产品，你有没有办法销售产品？</li>
<li>持久问题： 未来10年或20年，你能保住自己的市场地位吗？</li>
<li>秘密问题： 你有没有找到一个其他人没有发现的独特机会？</li>
</ol></li>
</ul>
</blockquote>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
《<a href="https://book.douban.com/subject/35641088/">计算之魂 : 计算科学品位和认知进阶</a>》</li>
<li><input type="checkbox" disabled="" />
《程序员修炼之道（第2版）》</li>
<li><input type="checkbox" disabled="" />
《<a href="https://book.douban.com/subject/25930025/">只是为了好玩 : Linux之父林纳斯自传</a>》</li>
<li><input type="checkbox" disabled="" />
《数据科学家访谈录》</li>
<li><input type="checkbox" disabled="" checked="" />
<a href="https://book.douban.com/subject/22993903/">《区块链：从数字货币到信用社会》</a></li>
</ul>
<blockquote>
<p>在区块链的信用评价中，信用其实是一个数学问题。</p>
</blockquote>
<p><img src="./区块链从数字货币到信用社会.png" /></p>
<p>出于了解web3技术基础的需求，略读此书。前三章生动入微，后续章节务虚难解。</p>
<p>区块链技术为互联网中的信息赋予了绑定在数据本身上的价值。然而该价值如何和现实社会桥接，仍有一段长路要走。</p>
<p>文中有段对比甚是有趣，摘录如下：“如果说印刷机的意义就在于将信息资源抽离物理世界的束缚，变为一种非竞争性资源，区块链则是起着与印刷机截然相反的作用，<strong>它以处理竞争性资源的方式来处理信息资源（非竞争性）</strong>，人们可以摆脱对可信第三方的依赖，在数字世界中自由地交换数字货币、知识产权、股权甚至不动产所有权。虽然两者处理资源的方式是相反的，但两者对话语结构的改变是一致的。”</p>
<h2 id="休闲">休闲</h2>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
《<a href="https://book.douban.com/subject/30243002/">食物与科学的美味邂逅</a>》</li>
</ul>
<p>高开低走的一本书，开篇吊足胃口后发现更多是稳固高中理化生知识，佐以一些生活例子为延展。</p>
<p>倒也没错，料理的科学本就不是高高在上的。</p>
<p>书中不少有趣的科普或故事：</p>
<ul>
<li>居然有人（埃尔韦·蒂斯）使用“食材状态（gas/water/etc.）+分子活动的状态（分散/并存/包含/复层）”来描述料理，饶是有趣。不仅给出新的分类体系，还为料理的创新提供了新路数——替换公式中的项；</li>
<li><em>食物搭配学</em>居然是门新兴学科，https://www.foodpairing.com/ 👈还存在着这样的食物搭配数据库；</li>
<li>高压锅已经走入我们的生活了，但<strong>超高压</strong>有更多料理的想象空间——通过超高压把食品的分子挤压为高密度的状态，致使分子发生物理性变化。比如，带壳的生鸡蛋在6500个静水压力的影响下，保留了生蛋的风味，蛋黄、蛋白却“凝固”成水煮蛋的状态。</li>
</ul>
<blockquote>
<p>但美味并不存在于食物本身，只有在食用者的大脑接收到美味信息时才会产生美味。因此，考虑食用者如何感受这道菜品，与考虑精选食物用料、严格按照食谱烹制食物时同等重要的。</p>
</blockquote>
<p>​ 所以，做好吃的料理，要让食物、环境、氛围，都传递出爱意呀。</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
《贪婪的多巴胺》</li>
</ul>
<blockquote>
<p>多巴胺追求更多，而不是追求道德；对多巴胺来说，武力和欺诈只不过是达成目的的工具。</p>
</blockquote>
<p>科普小品文，助人了解行为背后哦的生化动机。</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
《质数的孤独》</li>
</ul>
<blockquote>
<p>质数只能被一和它自身整除。在自然数的无穷序列中它们处于自己的位置上，和其他所有数字一样被前后两个数字挤着。但它们彼此间的距离却比其他数字更远一步。它们是多疑而又孤独的数字。</p>
</blockquote>
<p>难得感性起来——一旦开始阅读，仿佛被黑洞吞噬般卷入那孤寂中。</p>
<p>书中马蒂亚与身边人的距离，是非连续的，在0到某个或许无穷小的实数间，有个无法跨越的距离。</p>
<p>没有他那般数学天赋，却莫名的想起在武汉的那些孤寂时刻，是那种，被孤寂漫灌，浓稠的黑泥直钻鼻孔，附着在每寸皮肤，无法呼吸的感觉。</p>
<p>瑟缩在床上，床单的褶皱似鬼脸无情的嘲笑；反复的键入又删除，方块字规整依旧，却永无那笔下所描绘的质感；雨夜、酷暑、寒冬、湿热，相同点在于眼镜总是看不清楚。</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
《突然，响起一阵敲门声》</li>
</ul>
<p>很迅速在偷闲中看完了，很遗憾只偷闲了一周。本想作为睡前读物，每日小看一篇。却是在看完后哭笑不得，总忍不住再续上一篇。 尤其爱《其实，我最近勃起过两次，硬得就像根金刚棒》。虽然仍是年轻，却总觉自己的宝贝将要一蹶不振。没有晨勃的日子里，会有什么能让人金鸡独立呢？</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
《蛤蟆先生去看心理医生》</li>
</ul>
<blockquote>
<p>身处情绪的特殊时期看此书，像是借蛤蟆这一傀儡，去面见了心理医生一般。</p>
</blockquote>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
《乡村教师》</li>
</ul>
<blockquote>
<p>「上尉，你是个白痴吗？！」舰队统帅大怒，「你是想告诉我们，一种没有记忆遗传，相互间用声波进行信息交流，并且是以令人难以置信的每秒１至１０比特的速率进行交流的物种，能创造出５Ｂ级文明？！而且这种文明是在没有任何外部高级文明培植的情况下自行进化的？！」</p>
</blockquote>
<p>被大刘强行拉到星际文明的智慧高度来审视我们星球的文明，才意识到我们获取知识的方式那么缓慢低效。人类，便是这样迟缓却生生不息的进步着。</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" checked="" />
<a href="https://book.douban.com/subject/35710421/">《老妓抄》</a></li>
</ul>
<blockquote>
<p>肿瘤上歪曲的独眼，像是在瞪视人间、嘲笑人间一般，看起来反而更具有深邃意义。这张冷眼旁观人生不如意与悲欢无常的人脸上，根本已经没有必要再添加任何一笔了。</p>
</blockquote>
<p>久违的日本文学，抚慰我囚禁于疫情荒诞防控下阴暗的灵魂。可以一无所成，但请珍惜自己所有的，如《花束般的恋爱》中所述——看少年漫画仍能痛哭流涕的稚气。</p>
<p>上述，无关此书，只是借机感叹罢了。因为所谓的疫情，只求活着的话，活着本事实在是无趣呢。</p>
<hr />
<p>再加点bonus项吧，不求参透，不知道2022年能读多少呢。</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
《毛选》</li>
<li><input type="checkbox" disabled="" />
《资本论》</li>
<li><input type="checkbox" disabled="" />
《史记》</li>
</ul>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>书单</tag>
        <tag>日常</tag>
        <tag>打卡</tag>
      </tags>
  </entry>
  <entry>
    <title>GNN-GATv2</title>
    <url>/2022/05/20/GNN-GATv2/</url>
    <content><![CDATA[<h1 id="论文笔记how-attentive-are-graph-attention-networks">论文笔记：HOW ATTENTIVE ARE GRAPH ATTENTION NETWORKS?</h1>
<blockquote>
<p>PDF: https://openreview.net/pdf?id=F72ximsx7C1</p>
<p>OpenReview：https://openreview.net/forum?id=F72ximsx7C1</p>
<p>ICLR 2022</p>
</blockquote>
<h2 id="abstract">1. Abstract</h2>
<p>认为GAT是static attention，仅实现了对节点重要度的静态ranking，而未实现对不同query给出不同key的设想；提出GATv2，通过调整LeakyReLU和linear unit计算顺序，实现dynamic attention，即对不同query能给出不同key。</p>
<span id="more"></span>
<h2 id="motivations">2. Motivations</h2>
<p>GAT已成为图神经网络发展历程中的标志性架构，但本文观察发现，GAT的attention对于相同的keys实现的其实是ranking。</p>
<p>假设有如下二部图，求解 <em>Dictionary Lookup</em> 问题：</p>
<p><img src="./gatv2_01.png" style="zoom:67%;" /></p>
<p>使用GAT所得的attention scores如下：</p>
<p><img src="./gatv2_02.png" style="zoom:38%;" /></p>
<p>可以看到，对于不同的query，key的scores排序实际是一样的（<strong>静态</strong>的）。这限制了GAT的表达能力。</p>
<p>而本文认为，attention的初衷应该是：给定不同的query，能找到不同的key（即不同query，ranking结果应该不同，<strong>动态</strong>的）。</p>
<h2 id="method">3. Method</h2>
<h3 id="definitions">3.1 Definitions</h3>
<p>注意力机制其实是求解给定query时keys的注意力得分分布。</p>
<ul>
<li><p><strong>Static Attention</strong></p>
<p>设有计算注意力得分的函数族<span class="math inline">\(\mathcal{F}\)</span>, 对于任意 <span class="math inline">\(f \in \mathcal{F}\)</span>，给出 key <span class="math inline">\(\mathbb{K}=\left\{\boldsymbol{k}_{1}, \ldots, \boldsymbol{k}_{n}\right\} \subset \mathbb{R}^{d}\)</span> 和 query <span class="math inline">\(\mathbb{Q}=\left\{\boldsymbol{q}_{1}, \ldots, \boldsymbol{q}_{m}\right\} \subset \mathbb{R}^{d}\)</span>，若存在一个“得分最高”的 key <span class="math inline">\(k_{j_f}\)</span> 使得 <span class="math inline">\(f\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{j_{f}}\right) \geq f\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{j}\right)\)</span>，则称 <span class="math inline">\(\mathcal{F}\)</span> 为静态注意力；</p></li>
<li><p><strong>Dynamic Attention</strong></p>
<p>设有计算注意力得分的函数族<span class="math inline">\(\mathcal{F}\)</span>, <span class="math inline">\(f \in \mathcal{F}\)</span>，给出 key <span class="math inline">\(\mathbb{K}=\left\{\boldsymbol{k}_{1}, \ldots, \boldsymbol{k}_{n}\right\} \subset \mathbb{R}^{d}\)</span> 和 query <span class="math inline">\(\mathbb{Q}=\left\{\boldsymbol{q}_{1}, \ldots, \boldsymbol{q}_{m}\right\} \subset \mathbb{R}^{d}\)</span>，对于任意的映射 <span class="math inline">\(\varphi:[m] \rightarrow[n]\)</span>，存在 <span class="math inline">\(f \in \mathcal{F}\)</span>，使任意的 query 及任意的 key <span class="math inline">\(j_{\neq \varphi(i)} \in[n]\)</span>，有<span class="math inline">\(f\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{\varphi(i)}\right)&gt;f\left(\boldsymbol{q}_{i}, \boldsymbol{k}_{j}\right)\)</span>，则称 <span class="math inline">\(\mathcal{F}\)</span> 为动态注意力。</p></li>
</ul>
<h2 id="gat有限的表达能力及修正">3.2 GAT有限的表达能力及修正</h2>
<ul>
<li><p><strong>GAT 分析</strong></p>
<p>首先回顾GAT中attention score计算方式，有： <span class="math display">\[
e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j}\right)=\text { LeakyReLU }\left(\boldsymbol{a}^{\top} \cdot\left[\boldsymbol{W} \boldsymbol{h}_{i} \| \boldsymbol{W} \boldsymbol{h}_{j}\right]\right)
\]</span></p>
<p><span class="math display">\[
\alpha_{i j}=\operatorname{softmax}_{j}\left(e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j}\right)\right)=\frac{\exp \left(e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j}\right)\right)}{\sum_{j^{\prime} \in \mathcal{N}_{i}} \exp \left(e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j^{\prime}}\right)\right)}
\]</span></p>
<p>对于式子(1)，我们令 <span class="math inline">\(\boldsymbol{a}=\left[\boldsymbol{a}_{1} \| \boldsymbol{a}_{2}\right] \in \mathbb{R}^{2 d^{\prime}}\)</span>，可得： <span class="math display">\[
e\left(\boldsymbol{h}_{i}, \boldsymbol{h}_{j}\right)=\text { LeakyReLU }\left(\boldsymbol{a}_{1}^{\top} \boldsymbol{W} \boldsymbol{h}_{i}+\boldsymbol{a}_{2}^{\top} \boldsymbol{W} \boldsymbol{h}_{j}\right)
\]</span> 可以发现，对于有限的节点集合 <span class="math inline">\(\mathcal{V}\)</span>，存在一个节点 <span class="math inline">\(j_{max}\)</span>，使 <span class="math inline">\(\boldsymbol{a}_{2}^{\top} \boldsymbol{W} \boldsymbol{h}_{j_{max}}\)</span> 最大，即GAT计算的为 <em>static attention</em>。节点重要程度排序是确定的，和 query node 无关。Query node 只能影响注意力得分分布的 "sharpeness"。</p>
<blockquote>
<p>关于 <strong>multi-head</strong> ：上述结论对每个head仍适用，只是每个head的 <span class="math inline">\(j_{max}\)</span> 节点未必相同。</p>
</blockquote></li>
<li><p><strong>改进</strong></p>
<p>本文核心内容，将 <span class="math inline">\(\boldsymbol{a}\)</span> 移动到非线性激活外，使GAT成为 <em>dynamic attention</em>。</p>
<p><img src="./gatv2_03.png" /></p>
<p>证明较长，见文章appendix。</p></li>
</ul>
<h2 id="exp">4. Exp</h2>
<ul>
<li><em>Dictionary Lookup</em></li>
</ul>
<p>对于上文中二部图问题，使用改进后的GAT能有效实现<em>dynamic attention</em>。</p>
<p><img src="./gatv2_04.png" style="zoom:50%;" /></p>
<ul>
<li><p>Robustness to Noise</p>
<p>本文发现<em>dynamic attention</em>能更好抵抗噪声（不过没有进一步分析原因）。</p>
<p><img src="./gatv2_05.png" style="zoom:38%;" /></p></li>
<li><p>Node / Graph / Link Prediction</p>
<p><img src="./gatv2_06.png" style="zoom:50%;" /></p>
<p><img src="./gatv2_07.png" style="zoom:50%;" /></p>
<p><img src="./gatv2_08.png" style="zoom:50%;" /></p>
<p>值得注意的是，节点预测中 单头的 GATv2 在两个数据集上有更佳表现。作者解释为单头的GATv2已经有足够的表达能力，使用8头时反而由于过强的表达能力，遭遇了过拟合。</p></li>
</ul>
<h2 id="其他">其他</h2>
<p>twitter和openreview上的讨论很有意思，截取一些在此。</p>
<ul>
<li><p>GAT原作者</p>
<p><img src="./gatv2_09.png" style="zoom:38%;" /></p></li>
<li><p>关于GATv1, v2表达能力与参数数量的讨论 (二者参数数量相同，表达能力不同)</p>
<p><img src="./gatv2_10.png" style="zoom:50%;" /></p></li>
<li><p>作者关于 <em>dynamic attention</em> 的思考</p>
<p><img src="./gatv2_11.png" /></p></li>
</ul>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>图神经网络</tag>
        <tag>图表示学习</tag>
      </tags>
  </entry>
  <entry>
    <title>GNN_GIN论文笔记</title>
    <url>/2021/11/09/GNN-GIN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<blockquote>
<p>借结课展示的强制力，更新 <em>How Powerful Are Graph Neural Networks?</em> 论文阅读笔记如下。</p>
</blockquote>
<p>此工作发表于ICLR19，将GNN聚合邻居的方式与WL test做类比，理论上论证了GNN表达能力的上限为WL Subtree kernel，并根据分析提出<strong>GIN</strong>模型。论文提供了理解GNN表达能力的新思路，也启迪GNN模型架构发展的方向。</p>
<span id="more"></span>
<p><img src="./幻灯片1.png" /></p>
<p><img src="./幻灯片2.png" /></p>
<h2 id="background-contributions">1. Background &amp; Contributions</h2>
<p>GNN近年来来发展迅速，在图表示学习方向取得耀眼成果。但大部分模型的设计都基于经验或直觉，缺少对GNN性质的深入理解分析。</p>
<p><img src="./幻灯片4.png" /></p>
<p>本工作主要有4方面的贡献：(见下图)</p>
<p><img src="./幻灯片5.png" /></p>
<h2 id="preliminaries">2. Preliminaries</h2>
<p><img src="./幻灯片7.png" /></p>
<p>本工作讨论的为Message-Passing类的GNN模型，</p>
<p>此类模型每层进行<strong>AGGREGATE及COMBINE</strong>操作，分别负责收集邻居信息、结合邻居和节点自身信息更新hidden state。</p>
<p>若需要获得graph-level的图表示，则一般操作，是对网络最后一层的所有节点信息做聚合，即使用<strong>READOUT</strong>函数取得最后的图表示<span class="math inline">\(h_G\)</span>。READOUT函数需要满足permutation invariant，常用的简单函数有如<strong>求和SUM</strong>。</p>
<p><img src="./幻灯片8.png" /></p>
<p>本工作中涉及的WL Test是尝试判断图同构的经典方法。</p>
<p>图同构问题是图论中的经典问题，且是NP问题。若两个图是同构的，则存在双射函数，能将一个图中节点对应映射为另一图中对应节点。</p>
<p>如下图，图G、H为同构图，可通过双射的函数f找到两图中一一对应的节点。</p>
<p><img src="./幻灯片9.png" /></p>
<p>WL Test是图同构的一个<strong>必要非充分</strong>的条件。其算法迭代执行如下两步：</p>
<ol type="1">
<li>每个节点收集一阶邻居的标签（是不是很像MPNN收集message的步骤）；</li>
<li>将聚合后的标签集合做hash，创建新的唯一标签；</li>
</ol>
<p>每轮迭代后比较两图节点标签集合异同，如使用Jaccard积，如果不同则能说明两图非同构，否则两图可能是同构的。</p>
<p>一轮迭代的例子如下图。</p>
<p><img src="./幻灯片10.png" /> <img src="./幻灯片11.png" /></p>
<h2 id="this-works">3. This works</h2>
<h3 id="gnn表达能力上界">3.1 GNN表达能力上界</h3>
<p>任何基于统计的表示学习模型，都想将同类样本映射到表示空间中相近甚至相同位置，不同类样本则尽量远离。</p>
<p>对于图表示学习，若说两个节点是一样的，则意味着节点的<strong>结构、特征</strong>都相同。具体的，则是两个节点导出的子树结构完全相同，且子树上的节点所有的特征也相同。</p>
<p>相应的，理想化的GNN能将上述相同节点映射到相同表示空间，不相似节点则映射至表示空间中彼此远离的位置。</p>
<p>实际上，满足上述要求的GNN，实质上是在解决<strong>图同构问题</strong>。</p>
<p><img src="./幻灯片13.png" /></p>
<p><strong>multiset</strong>为后文论证中常用概念，实质上用于描述每个节点所收到的邻居信息。</p>
<p><img src="./幻灯片14.png" /></p>
<p>从Section 2中GNN与WL Test介绍可以发现，二者聚合邻居信息更新自身节点hidden state/label的过程在方式上相近。</p>
<p>作者在一系列证明后给出结论：<strong>基于aggregation的GNN模型，在分辨不同图任务中的能力上界为WL Test</strong>。</p>
<p><img src="./幻灯片15.png" /></p>
<p>自然而然的问题，怎样构建GNN模型才能逼近表达能力上界呢？</p>
<p>作者进一步推导证明，模型的<strong>Aggregate, Combine, Readout函数都必须是单射函数</strong>。（与ideally GNN类似，单射函数保证了不同结构、特征的节点被映射为不同的嵌入表示）。</p>
<p><img src="./幻灯片16.png" /></p>
<h3 id="gin">3.2 GIN</h3>
<p><img src="./幻灯片17.png" /></p>
<p>基于上图结论，作者提出<strong>Graph Isomorphism Network(GIN)</strong>。</p>
<p>其中，<span class="math inline">\(f^{(k)}\)</span>为<strong>多层感知机MLP</strong>，ε为可学习的参数，二者再加上<strong>SUM</strong>共同保证了模型函数的单射性。</p>
<p><img src="./幻灯片18.png" /></p>
<p>对应的，READOUT函数也要使用<strong>SUM</strong>来保证单射性。 与通常做法不同，GIN为了把握全局的图结构，它的图表示<span class="math inline">\(h_G\)</span>聚合了网络<span class="math inline">\({1,..,k}\)</span>层的全部信息。</p>
<p><img src="./幻灯片19.png" /></p>
<p>对于传统基于一阶邻居聚合的GNN模型，本工作发现它们有如下问题： 1. 所使用的单层perceptron在一定场景中是非单射的，表达能力不如MLPs； 1. Mean 和 Max-pooling 算子是非单射的，在下图结构中，节点v和v'聚合所得邻居信息的结果可能一致，意味着使用这两个算子可能丢失更具体的结构信息。</p>
<p><img src="./幻灯片20.png" /></p>
<h3 id="experiments">3.3 Experiments</h3>
<p><img src="./幻灯片21.png" /></p>
<p>训练阶段，WL Subtree kernel为上界。可以看到GIN-0, GIN-eps都较好的逼近了WL Subtree kernel。而使用其他不满足单射性质的GNN variants则收敛较慢，或者无法收敛至理论上界。</p>
<p><img src="./幻灯片22.png" /></p>
<p>实验结果可见，在Graph Classification任务上GIN取得了耀眼成绩。</p>
<p><img src="./幻灯片23.png" /></p>
<h2 id="personal-thoughts">4. Personal Thoughts</h2>
<p><img src="./幻灯片25.png" /> <img src="./幻灯片26.png" /></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>图神经网络</tag>
        <tag>图表示学习</tag>
      </tags>
  </entry>
  <entry>
    <title>GNN_STARGNN_Adaptive感受野</title>
    <url>/2021/12/18/GNN-STARGNN-Adaptive%E6%84%9F%E5%8F%97%E9%87%8E/</url>
    <content><![CDATA[<h1 id="improving-graph-neural-networks-with-structural-adaptive-receptive-fields">Improving Graph Neural Networks with Structural Adaptive Receptive Fields</h1>
<blockquote>
<p>PDF: https://dl.acm.org/doi/10.1145/3442381.3449896</p>
<p>Conferences: WWW '21</p>
</blockquote>
<h2 id="abstract">1. Abstract</h2>
<p>现有GNN模型未能充分利用图结构信息，此工作提出STructural Adaptive Receptive fields (<strong>STAR-GNN</strong>)，适应性地构建每个节点的感受野(receptive field)以捕获结构信息。具体贡献如下：</p>
<ul>
<li>提出基于节点结构信息来自适应调节receptive field范围STAR-GNN；</li>
<li>将Anonymous Random Walks (ARWs)和互信息结合来捕获节点的结构信息，此外还提出针对receptive field的subgraph 聚合算子。</li>
</ul>
<span id="more"></span>
<h2 id="motivations">2. Motivations</h2>
<p><strong>大部分GNNs未能充分利用图结构信息，对邻居节点的重要性没有区分：</strong></p>
<ul>
<li>传统的GCN将邻居节点一视同仁，或者根据边权来分配权重，因而忽略了许多与邻居重要性有关的信息；</li>
<li>GAT使用soft attention，基于节点特征的相似度来学习权重，但其，① 忽略拓扑特征的相似度信息，② soft attention在邻居数量较大时可能遭遇过平滑问题。</li>
</ul>
<p>对此，希望能提出一种<strong>结合结构信息来适应性地构建节点receptive field</strong>的方法，该方法希望能 ①同时根据节点特征和结构特征来衡量邻居重要性，② receptive field聚合irregular neighborhoods 且避免过平滑问题。</p>
<p>遇到的挑战如下：</p>
<ol type="1">
<li>图复杂的结构信息难捕获；</li>
<li>适应性地构建receptive field计算复杂度高。该adaptive构建过程是不可微的，因而难直接优化。此前使用强化学习及组合优化的方式计算复杂度都过高；</li>
<li>不能基于k-order邻居来建立receptive field。理想的receptive field是不规则的子图，可能有数量各异的各阶邻居，现有聚合算子难有效聚合这样的子图结构。</li>
</ol>
<h2 id="method">3. Method</h2>
<figure>
<img src="./STARGNN_01.png" alt="overview" /><figcaption aria-hidden="true">overview</figcaption>
</figure>
<h3 id="overview">3.1 Overview</h3>
<p>STAR-GNN主要分为3个部分：</p>
<ol type="1">
<li><strong>Local Structural Distribution</strong>，使用ARWs来捕获节点的邻居分布，结合Mutual Information(MI)来计算注意力，得到包含节点特征和结构信息的structural embedding；</li>
<li><strong>Construction of Optimal Receptive Fields</strong>，用structural embedding计算节点对间MI，贪心地寻找optima receptive field；</li>
<li><strong>GNN with Sub-graph Structures</strong>，通过采样不规则subgraph（receptive field）中节点，进行聚合。</li>
</ol>
<h3 id="neighborhood-contributions-local-structural-distribution">3.2 Neighborhood Contributions Local Structural Distribution</h3>
<p>Attention score 计算，过往一些方法基于节点特征相似度，一些则引入了人为设计的结构信息patterns，都只能捕获有限结构信息且泛化性不佳。</p>
<p>本工作则使用ARWs刻画节点的邻居结构特征，认为ARWs能较好地描述节点的local structural distribution。ARWs定义如下：</p>
<p><img src="./STARGNN_03.png" style="zoom:50%;" /></p>
<p>进一步地，本工作引入互信息(MI)来辅助学习节点embedding <span class="math inline">\(U={u_i}\)</span>，希望最大化节点对间特征、结构信息。Loss设计有：</p>
<p><img src="./STARGNN_04.png" style="zoom:67%;" /></p>
<p>其中<span class="math inline">\(w_{i j}=\sigma\left(\mathbf{u}_{i}^{T} \mathbf{u}_{j}\right)\)</span>，<span class="math inline">\(\mathcal{N}_{i}\)</span>为节点<span class="math inline">\(i\)</span>的ARWs中所访问到的节点集合，<span class="math inline">\(I(·, ·)\)</span>为互信息，第一项衡量节点间特征相似度，第二项衡量结构相似度。</p>
<p><img src="./STARGNN_05.png" style="zoom:67%;" /></p>
<p>Attention score则由上述<span class="math inline">\(u\)</span>计算，</p>
<p><img src="./STARGNN_06.png" style="zoom:50%;" /></p>
<h3 id="construction-of-optimal-receptive-fields">3.3 Construction of Optimal Receptive Fields</h3>
<p>作者先前的工作说明GAT中的soft attention，在节点度较高时会遇到过平滑问题。因而构建receptive field时，应当“construct discrete adaptive receptive fields to avoid over-smoothing”(不是很理解，是否理解为需要筛选邻居，以减少聚合对象个数)。</p>
<p>作者认为，理想的receptive field应当<strong>为中心节点提供最多的信息</strong>，并希望用<strong>MI</strong>来衡量获取信息的多少。</p>
<p>因为MI≥0，故receptive field增大时MI和单调不减，故本工作将优化目标定为：以最小的receptive field取得满足阈值的MI：</p>
<p><img src="./STARGNN_07.png" style="zoom:67%;" /></p>
<p>本工作使用贪心算法求解上述优化问题。</p>
<h3 id="gnn-with-sub-graph-structures">3.4 GNN with Sub-graph Structures</h3>
<p>当前聚合算子如Mean, Max, LSTM针对k-hop邻居做聚合，对于不规则的subgraph，聚合时难以区分不同阶邻居信息。</p>
<p>本工作对如下聚合方式进行一系列证明，说明其满足permutation invariant。最后得到的聚合方式为：</p>
<p><img src="./STARGNN_08.png" style="zoom:67%;" /></p>
<p>模型loss则为</p>
<p><img src="./STARGNN_09.png" style="zoom:50%;" /></p>
<p>模型算法描述如下：</p>
<p><img src="./STARGNN_10.png" style="zoom:50%;" /></p>
<h2 id="exp">4. Exp</h2>
<ol type="1">
<li><p>节点分类</p>
<ul>
<li>Transductive</li>
<li><img src="./STARGNN_11.png" style="zoom:80%;" /></li>
<li>Inductive</li>
<li><img src="./STARGNN_12.png" style="zoom:50%;" /></li>
</ul></li>
<li><p>Ablation study</p>
<p><img src="./STARGNN_13.png" style="zoom:50%;" /></p>
<p>相对而言，引入结构信息和选择optimal receptive field对性能帮助更大。</p></li>
</ol>
<h2 id="personal-thoughts">5. Personal Thoughts</h2>
<p>建模阶段：</p>
<ul>
<li>在base node embedding阶段，用ARWs来刻画节点的local structure。RW-based方法implicit捕获拓扑结构，相较于explicit的子图挖掘，泛化性更好，对边缘节点等刻画更清晰，但未必能准确刻画cohesive subgraph等子图结构；</li>
<li>（越看越奇怪，感觉没看懂）base node embedding依旧通过GNN在原图上(?)学习，不过在loss中加入MI构造的penalty，来捕获ARWs所刻画的结构信息，此处可算出attention scores，留给final embedding的聚合阶段使用；</li>
<li>optimal receptive field通过MI+贪心算法构建。它们不在聚合阶段做邻居的筛选，而是将receptive field的构建前置，从而减少噪音，思路值得借鉴；</li>
<li>final embedding由传统的邻居聚合+及<span class="math inline">\(\tilde{h_i}\)</span>构成，<span class="math inline">\(\tilde{h_i}\)</span>聚合了节点<span class="math inline">\(i\)</span>的感受野信息。其聚合方法符合个人为实现子图聚合的想法——<em>抽样聚合</em>，提供了理论证明；</li>
</ul>
<p>整体工作：</p>
<ul>
<li>可以发现，本工作实际的编码器只有两个分离的GNN及若干MLP，主要工作在于<strong>adaptively调整编码器的输入</strong>；</li>
<li>亮点：
<ul>
<li>MI的引入比较系统，从loss设计到optimal感受野的选择都结合了MI；</li>
<li>理论的证明和实验做得比较齐全，模型在数据集上的F1表现优异；</li>
</ul></li>
<li>不足：
<ul>
<li>为得到final embedding，过程中产生较多冗余变量来调整模型输入，模型整体性略差。更理想来说，通过模型架构和penalty来自动选择感受野更为理想，贪婪算法整体性不强；</li>
<li>模型的推理速度堪忧。</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>图神经网络</tag>
        <tag>图表示学习</tag>
      </tags>
  </entry>
  <entry>
    <title>GNN_利用边信息</title>
    <url>/2021/11/13/GNN-%E5%88%A9%E7%94%A8%E8%BE%B9%E4%BF%A1%E6%81%AF/</url>
    <content><![CDATA[<blockquote>
<p><strong>Abstract</strong>:</p>
<p>当前GNNs主要利用了节点特征，忽略了边上信息。本笔记对GNNs中利用边信息的方式进行小结。</p>
</blockquote>
<span id="more"></span>
<p>部分图片截取自[1]，感谢原创人员悉心的总结分享。</p>
<h2 id="backgrounds">1. Backgrounds</h2>
<p>图表示学习近年来取得巨大进展，以<strong>GCNs</strong>为代表的一系列图神经网络模型在节点分类、图分类、链接预测等图领域任务取得亮眼的成果。其中大部分模型基于<em>message-passing</em>方式构建，即“聚合邻居信息，更新节点自身状态”，在此范式中，节点特征得到充分的学习。而现实的许多图中，边上存在丰富的信息，它们在当前大多模型中未被充分利用。</p>
<p>Edge Features同样描述着网络，学习edge features能强化图神经网络的表达能力。</p>
<p>以下图为例：</p>
<p>社交网络中，edge features更具体地描述着用户(nodes)间关系。</p>
<p><img src="./01.png" /></p>
<h2 id="recently-works">2. Recently Works</h2>
<p>当前图神经网络对边信息主要有如下几种利用方式：</p>
<p><img src="./GNNs+Edge%20Features.png" /></p>
<h3 id="implicit-utilization">2.1 Implicit Utilization</h3>
<p>每个节点只aggregate其邻居的信息，这一聚合方式本身就基于节点间的边实现。此情况下只视作各个边为binary feature，只有“有边/无边”区别。</p>
<h3 id="naive-utilization">2.2 Naive Utilization</h3>
<p>对于边上特征为scalar的情况，最简单直接的方式是使用带权的邻接矩阵描述，与之对应的，使用支持edge weight的模型学习即可。</p>
<h3 id="aggregate-from-different-types-of-edge">2.3 Aggregate from Different Types of Edge</h3>
<p>在许多场景中，边上特征为类别标签，如社交网络中，边上可以标注两人为工作关系、家人等。</p>
<p>对于存在多种类型边的图（边异构），常见处理方法是<strong>依照边的类型分别聚合信息</strong>。</p>
<p>如早期工作<strong>Relational GCN</strong>[2]，</p>
<p>其只在GCN</p>
<p><span class="math display">\[h^{l+1}_i = \sum_{j \in \mathcal{N}_{i}} \frac{1}{norm} W^{(l)} h_{j}^{(l)}+W^{(l)} h_{i}^{(l)}\]</span></p>
<p>的基础上，增加了<span class="math inline">\(\sum_{r \in R}\)</span>.</p>
<p><img src="./02.png" /></p>
<p>其他模型也是类似思路，仅在聚合方式上做进一步细化。 如下图：</p>
<p><img src="./03.png" /></p>
<h3 id="multi-dimensional-edge-features">2.4 Multi-dimensional Edge Features</h3>
<p>上述3个方式并不能较好地处理边上多维特征。面对多维边特征，常见手段也是在aggregation阶段将边特征、邻居节点特征通过某种function结合在一起，再传给目标节点。</p>
<p>General Idea 如下图：</p>
<p><img src="./04.png" /></p>
<p>相关工作有<em>PNAConv</em>[3],<em>Crystal Graph Conv</em>[4]。</p>
<h3 id="learn-edge-embeddings">2.5 Learn Edge Embeddings</h3>
<p>与2.4区别在于，下述方法以多维边特征为输入，并在模型每层更新，类似学习node embedding一般，同时学习edge embeddings。其实现方式多为创建某种辅助图，在该图中将边也视作节点，再用现有GAT等模型学习边和节点的表示。</p>
<ol type="1">
<li><p><em>EGNN</em> [5] <span class="math display">\[
X^{l}=\sigma\left[\prod_{p=1}^{P}\left(\alpha_{\cdots p}^{l}\left(X^{l-1}, E_{\cdots p}^{l-1}\right) g^{l}\left(X^{l-1}\right)\right)\right]
\]</span></p>
<p><span class="math inline">\(P\)</span> 为边特征维度数。</p>
<p>在GAT基础上，单独处理每一维的特征。聚合函数中加入节点特征，并为每一维特征单独学一组注意力权重，最后将各维输出concate。本文的edge embeddings，为每层所学的边多维特征注意力权重。</p>
<p><img src="./05.png" /></p></li>
<li><p><em>CensNet</em> [6]</p>
<p>使用line graph（原始图中节点变为line graph中的边，边变为节点）构建辅助图，在original graph和line graph上训练模型，交替更新node, edge embeddings。</p>
<p><img src="./06.png" /></p></li>
<li><p><em>NENN</em> [7]</p>
<p>以GAT为基础，提出Node-level Attention Layer, Edge-level Attention Layer。</p>
<p>每个layer区别主要在于输入的图的观察角度。</p>
<p>如下图中两矩形方框部分，分别以node、edge为视角，重新定义“邻居”，将边/节点视作新图中的节点，在新图中学习边和节点的embeddings。</p>
<p><img src="./07.png" /></p></li>
<li><p><em>EGAT</em> [8]</p>
<p>与<em>CensNet</em>类似，使用line graph+GAT学习节点和边的表示。</p>
<p><img src="./08.png" /></p></li>
</ol>
<h2 id="discussion">3. Discussion</h2>
<ol type="1">
<li>2.5中多用GAT编码边特征信息，带来较大的计算开销，能否更轻量且优雅的编码边特征？</li>
<li>2.5中使用诸如line graph等构建辅助图，把原图中的边变换为辅助图中的节点，从而可以利用已有GNN进行边嵌入的学习。但是，对于“边的邻居边”，是否同样满足节点与其邻居相近的假设？</li>
<li>如何评估边特征与节点的关系，边特征如何切实的帮助图表示学习？</li>
</ol>
<h2 id="reference">Reference</h2>
<ol type="1">
<li>https://www.youtube.com/watch?v=mdWQYYapvR8</li>
<li>Schlichtkrull M, Kipf T N, Bloem P, et al. Modeling relational data with graph convolutional networks[C]//European semantic web conference. Springer, Cham, 2018: 593-607.</li>
<li>Corso G, Cavalleri L, Beaini D, et al. Principal neighbourhood aggregation for graph nets[J]. arXiv preprint arXiv:2004.05718, 2020.</li>
<li>Xie T, Grossman J C. Crystal graph convolutional neural networks for an accurate and interpretable prediction of material properties[J]. Physical review letters, 2018, 120(14): 145301.</li>
<li>Gong L, Cheng Q. Exploiting edge features for graph neural networks[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 9211-9219.</li>
<li>Jiang X, Ji P, Li S. CensNet: Convolution with Edge-Node Switching in Graph Neural Networks[C]//IJCAI. 2019: 2656-2662.</li>
<li>Yang Y, Li D. Nenn: Incorporate node and edge features in graph neural networks[C]//Asian Conference on Machine Learning. PMLR, 2020: 593-608.</li>
<li>Chen J, Chen H. Edge-Featured Graph Attention Network[J]. arXiv preprint arXiv:2101.07671, 2021.</li>
</ol>
]]></content>
      <categories>
        <category>ML知识总结</category>
      </categories>
      <tags>
        <tag>图神经网络</tag>
        <tag>图表示学习</tag>
      </tags>
  </entry>
  <entry>
    <title>ML汇总-不平衡数据集</title>
    <url>/2021/01/06/ML%E6%B1%87%E6%80%BB-%E4%B8%8D%E5%B9%B3%E8%A1%A1%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    <content><![CDATA[<h1 id="关于不平衡数据集的总结汇总">关于不平衡数据集的总结汇总</h1>
<h2 id="从样本分布看问题根源">1. 从样本分布看问题根源</h2>
<p>资料来源:<a href="https://zhuanlan.zhihu.com/p/56960799">机器学习中如何处理不平衡数据？</a></p>
<blockquote>
<p>链接中通过例子重点分析unbalanced dataset的分布问题</p>
</blockquote>
<p>往往由于现实因素限制，我们得到数据集中正负样例比例相差悬殊，可能导致如下情况：</p>
<span id="more"></span>
<p><img src="./ML_02_02.png" style="zoom:50%;" /></p>
<p>如上图所示，尽管正负样例的实际分布不同（虚线部分），但由于采样比例悬殊（实线部分），若模型<strong>仅仅追求高Accuracy</strong>，模型则倾向于给出<code>predict=1</code>的结果。</p>
<p>不过，若正负样例的实际分布相差较大，就算数据集不平衡，模型也可能得到较好的分辨能力：</p>
<p><img src="./ML_02_01.png" style="zoom:50%;" /></p>
<p>若想从根本上解决不平衡数据集问题，还是需要<strong>采集更多负样本</strong>。</p>
<h2 id="改进方式">2. 改进方式</h2>
<p><a href="https://www.jianshu.com/p/f170d72f6fb6">详细资料参考</a></p>
<p>基本思路如下：</p>
<h3 id="采样方式">2.1 采样方式</h3>
<ol type="1">
<li>欠采样/过采样</li>
<li>数据合成（对负样本进行微小扰动等实现负样本合成）</li>
</ol>
<h3 id="建模方式">2.2 建模方式</h3>
<ol type="1">
<li>模型训练中，<strong>分配类别权重</strong>或者样本权重；</li>
<li>将问题视作看成一分类(One Class Learning)或者<strong>异常检测</strong>(Novelty Detection)问题；</li>
<li>Ensemble集成算法;</li>
</ol>
<h3 id="特征工程">2.3 特征工程</h3>
<p>从上文图2中可以发现，如果能创建出新特征，使各类样本的分布尽可能分离，也有可能提升分类器性能。</p>
<h2 id="其他问题">3. 其他问题</h2>
<p>在面对不平衡数据集时需要选择合适的指标，</p>
<p><code>Accuracy</code>, <code>AUC</code> 的结果不能真实反映分类器性能，关注<code>PR</code>曲线等能更好理解分类器在对不同类别样本的分类能力。</p>
<hr />
<p>参考资料：</p>
<ol type="1">
<li>https://www.jianshu.com/p/f170d72f6fb6</li>
<li>https://zhuanlan.zhihu.com/p/56960799</li>
<li>https://blog.csdn.net/qidailiming1994/article/details/100159842</li>
<li>https://www.zhihu.com/question/323518703</li>
</ol>
]]></content>
      <categories>
        <category>算法实践</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL-01-Preview</title>
    <url>/2020/12/06/MSL-01-Preview/</url>
    <content><![CDATA[<h1 id="msl-01-preview真正成为研究生前的一窥">MSL-01-Preview：真正成为研究生前的一窥</h1>
<blockquote>
<p>随记点想法，或许略负能量吧。</p>
</blockquote>
<p>写在去实验室机位贴标签条后。</p>
<span id="more"></span>
<p>和朋友出街路过网吧，总是挂在嘴边：这辈子还没在里面开过机位。 一间房里，空调费劲咳嗽般吐出暖气，吸干空气中一点一丝的湿气，从进门时便感到干燥的嘴唇似要破裂。低头瞅见，门旁的小小垃圾桶，垃圾摞成了麦当劳甜筒的模样。一长条桌子用隔板分割，每个位置塞个约莫19寸的屏幕。狭小逼仄，双屏想来无法摆下。</p>
<p>如果这是件网吧的设备，我一定扭头便走——2020年居然还以这般破败姿态来开网吧？</p>
<p>未曾想，这是未来三年研究生时光的位置。 曾经想，实验室大约该宽敞明亮，不求双屏+人体工学椅，好歹有套性能强劲的主机吧。没想到这台式的内存，居然才8G。</p>
<p>也罢，多记负能量无用。<strong>且记住，哪怕是在自己认为像乡村网吧的实验室里，也正不断产出可能改变世界的成果。</strong></p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>科研心声</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL-02-团建</title>
    <url>/2020/12/20/MSL-02-%E5%9B%A2%E5%BB%BA/</url>
    <content><![CDATA[<h1 id="团建后的随记">团建后的随记</h1>
<p>开始敲打键盘时已经是零点又二十分了，距离德州扑克结束3小时又20分，距离晚餐用毕有约六小时。</p>
<span id="more"></span>
<p>团建是从下午两点时开始的，一场四小时的剧本杀。</p>
<p>剧本杀总能暴露我的话痨属性。尽管努力参与游戏，但笨拙且直白的交谈技巧，未能玩出尔虞我诈的精髓。大约是所谓涉世太浅，恰似白板一眼看穿吧。</p>
<p>晚饭时，听学长们探讨互联网企业是非与职业发展路径，打破了些许学生思维：</p>
<ul>
<li>纯做技术出头的人才总是有限，何况考虑到现实情况（自己连🐔都未必是哈哈）所限。</li>
<li>最初时选到合适的大船，着眼于个人发展，诸如团队、项目管理，技术规划等，远好于冲着一个大package跑去，锁死了晋升的天花板。</li>
</ul>
<p>饭后的德州属实上头，装神弄鬼后把自己完成了“无产阶级”——输光筹码。</p>
<p><img src="./texas_poker.jpg" /></p>
<p>想来自己还是不够沉稳，开局小胜几局后便沉不住气，把把不计概率而博运气。</p>
<p>最后一局毕业的学长一把翻盘——隐忍了一整晚后抓了个Ace同花，换来大额入账。做人嘛，不能没有富贵的命得了富贵的命，属实该学会静候真正时机。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>MSL-03-南昌行</title>
    <url>/2021/01/05/MSL-03-%E5%8D%97%E6%98%8C%E8%A1%8C/</url>
    <content><![CDATA[<h1 id="出差南昌的若干夜">出差南昌的若干夜</h1>
<h2 id="第一夜">第一夜</h2>
<p>社交媒体上，尽是“拼多多的恶”——所谓奋斗的旗号送走了年轻的生命，在社交媒体上还为”剥削的正当性“叫嚣。</p>
<p>奈何那些996、大小周的互联网公司仍是围城，城内的打工人难堪种种压榨，城外的人羡慕那用命博来的巨额财富——尽管对于真正获利的资本家而言不过九牛一毛。</p>
<p>乘着高铁来到了南昌，江西的省会城市。</p>
<span id="more"></span>
<p>天空灰蒙蒙地，甚至发黄。所谓老城区的商业区，步行街晚上八点时却人影寥寥，马路宽敞却残破。那种第一眼的破败感，仿佛一下置身《铳梦》那废土赛博世界。</p>
<p>到了办公场地，仿佛置身计算机博物馆。早就知道银行数据安全重要，却不曾想要依靠一次性的光盘进行资料传输——每张4G，每秒传输数据峰值不超4M；在维护OA软件的程序员那边，看到了win XP，还是未破解的版本。</p>
<p>场地逼仄，三人共享一张办公桌，有的人还要在铁货架上写代码。</p>
<p>却问办公时间，休闲异常：早八点半到十一点半，悠哉游哉睡个午觉，下午两点上班，匆匆到五点又要下班了。</p>
<p>要去互联网公司吗，扛得住那般作息吗？</p>
<p>要来国企养老吗，休闲而落后，落袋没有几个子。</p>
<p>不是二选一的选择呵。现在更该做的，不是看到矛盾、苦涩的现实就倦怠、懒惰，反倒是更应耕耘自我跃升到更上的平台吧。</p>
<h2 id="第二夜">第二夜</h2>
<p>拼多多股价又涨了，资本果然冷血而逐利。</p>
<p>个人体验而言，有限、合理的工作时长带啦的效宜远胜996啊。</p>
<p>晚上不过7点就不让继续在办公室干活了。</p>
<p>此刻的我刚停下”自主加班“的脚步，思索如何提高办公效率。</p>
<h2 id="末夜">末夜</h2>
<p>受限于银行那边的硬件资源，模型没能完成就撤退了。</p>
<p>三小时车程，返汉后已然十一点。</p>
<p>寒冬冷风中的小确幸，莫过于大老远看到校门口的店铺还亮着灯。</p>
<p>一杯绿豆汤，一张鲜肉锅魁，是对自己最大的犒赏。</p>
<p>悦纳自己不过是个小人物的现状，开怀于每点温暖的片段罢了。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>MSL-04-失意与自我重建</title>
    <url>/2021/03/22/MSL-04-%E5%A4%B1%E6%84%8F%E4%B8%8E%E8%87%AA%E6%88%91%E9%87%8D%E5%BB%BA/</url>
    <content><![CDATA[<h1 id="msl---04---失意与自我重建">MSL - 04 - 失意与自我重建</h1>
<blockquote>
<p>写于22岁生日后。希望自敲下此行字起，负面情绪逐渐退散，重建起丰富而又充盈的自我。</p>
</blockquote>
<span id="more"></span>
<h2 id="苦闷的生日">0. 苦闷的生日</h2>
<p>这篇随笔本应配有封图，然而当日没有留下任何照片——在智能手机让人们能随时随地拍照的年代。</p>
<p>当日除了家人外，未曾收到任何友人的祝福。这倒不令我诧异，毕竟往常都小心谨慎地藏起自己的生日，也许久未主动记忆、祝贺他人生日快乐。于情于理，没人知道薛三的生日属实正常。</p>
<p>只是不曾想，对自己重要异常的人——女朋友，期盼着能成为日后伴侣的人，也似乎遗忘了我的生日。微信上未收到祝福，仅仅是接机后，才匆匆地搜索着何处有蛋糕售卖。</p>
<p>点到为止吧，再叙说下去，负面情感怕是又要翻涌而上了。</p>
<p>至少当日，还是听到了女朋友唱的生日快乐歌，吃上了一口切件蛋糕。</p>
<h2 id="说不出的情话">1. 说不出的情话</h2>
<p>博客更应作为知识和思考分享的平台，而非肆意宣泄情绪的出口。</p>
<p>于是，面对可能是行到水穷处的感情，也不适合在此倾倒太多苦水。</p>
<p>姑且记录几条总结的箴言，敦促自己铭记吧：</p>
<ul>
<li><strong>不成熟并非妄为的借口，所作所为自要担负其代价。</strong></li>
<li><strong>每人对感情的期待与底线各不相同，切莫以己度人，情人间多坦诚交流方为正道。</strong></li>
<li><strong>爱人者当先自尊自爱，卑微到尘土里并不能兑换为情侣关系。</strong></li>
<li><strong>珍惜当下，莫计较彼此投入、得失，用心爱便是。</strong></li>
</ul>
<p>何妨坐看云起时呢？或许能柳暗花明又一村呢？</p>
<h2 id="丢失的自我">2. 丢失的自我</h2>
<p>谈一场恋爱，自以为是的付出很多：兴趣的取舍、往昔友人的生疏、自我投资（金钱开销）的拮据。</p>
<p>殊不知，个人魅力并不全然取决于付出，而更多的由自身的素质、修养、见识构建。</p>
<p>曾经爱玩高达模型，出于开销的限制，变成了云玩家。</p>
<p>曾经喜欢阅读阅片，罢了写影评书评，不知怎地就断了，自我语言组织与表达能力日渐退化。</p>
<p>曾经也会吹侃时政，却在思维层次的差异前瑟缩起来，变得只敢闲聊家常，纯然一副管家模样。</p>
<p>曾经自律专注，现在却是陪着熬过几轮夜后，错乱了自己的生物钟。</p>
<p>……</p>
<p>如今的我，并非是可持续发展的自我。似个空壳，了无真正的兴趣与理想。</p>
<h2 id="自我重建">3. 自我重建</h2>
<p>22岁了，搭上了继续求学的班车，还未真正投身社会的钢铁洪流迎接历练。处于温床，但不应再躺平酣睡。</p>
<p>当是该进行轮<strong>自我重建</strong>了。</p>
<ul>
<li><strong>自律、自信</strong>，这是拾回曾有的状态；</li>
<li><strong>勤思、求知</strong>，这是面向大千世界的态度；</li>
<li><strong>求真、持续输出</strong>，私以为，此是通向“丰富自我”的捷径。</li>
</ul>
<p>那，明年生日时，再回看我的成果吧。与诸位共勉。</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL-05-五四之觉醒</title>
    <url>/2021/05/03/MSL-05-%E4%BA%94%E5%9B%9B%E4%B9%8B%E8%A7%89%E9%86%92/</url>
    <content><![CDATA[<h1 id="当代青年之觉醒">当代青年之觉醒</h1>
<blockquote>
<p>"自主的而非奴隸的！進步的而非保守的！進取的而非退隱的！世界的而非鎖國的！實利的而非虛文的！科學的而非想像的"</p>
<p>——《敬告青年》陈独秀</p>
</blockquote>
<p>距《敬告青年》发表已百年有多，世界业已天翻地覆。中国，已不复巴黎和会时的弱小无助，逐步迈向富强复兴，平视着美国，平静地告诉世界“美国没有资格在中国面前，说从实力地位出发同中国谈话”。</p>
<p>百年前觉醒的青年，是烛光、星火，照亮沉睡、黑暗的中华大地。当代之青年，已无家国存亡之忧虑，却也需要自我之觉醒。</p>
<span id="more"></span>
<p>须知，当下世界更加复杂多变，繁杂的信息流与精巧的算法诱导着人的认知，富而不均给社会染上焦虑，国际亦随新冠疫情迎来前所未有之大变局。</p>
<p>一点拙见，当前青年之觉醒，应有：</p>
<ul>
<li><p>自知的而非盲从的</p>
<p>以往谈独立之人格，讲求破除宗法礼教束缚。今呼吁青年求自知，盖期盼青年能独立思考、独立求证，而非盲从某某名人言论，又或某常言、经验。遇事能自主求索，而非听凭送到嘴边的信息流，以他人之观点代替个人思考。更多的，自知要求透彻的了解自我的认知、决策流程。信息时代下，每个人的认知都受被投喂的信息影响。求自知，则能辨何为真正自我需求、思考，何是外界灌输、催眠。</p></li>
<li><p>全面的而非偏激的</p>
<p>青年者，年少好学为常态，世事、学识储蓄不足亦是事实，易陷入片面偏激之囹圄。当探求更全面的认知，主动求索，刻画事物全貌，突破信息茧房。更当求知行合一，身体力行的实践，达全面后才有深刻。</p></li>
<li><p>坚定的而非浮躁的</p>
<p>于意识上探求一坚定信仰，于认知上定坚定求学之心态，于生活上坚定个人需求，是为浮躁年代中奋进的良药。物质的丰富伴随着物欲的流淌，客观存在的不公平现象扰乱着青年的心神，此时更当怀揣坚定的信念——不满意更当去击碎，不平静更当守执着。</p></li>
</ul>
<p>所谓光明的未来，未必是个人的，但觉醒的青年将像前辈一般，将光明传递。</p>
<p>——五四前夜，看罢《觉醒年代》，内心激荡澎湃不已，提笔随记粗浅见解如上。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL_06_偶尔中二-观《普罗米亚》</title>
    <url>/2021/06/20/MSL-06-%E5%81%B6%E5%B0%94%E4%B8%AD%E4%BA%8C-%E8%A7%82%E3%80%8A%E6%99%AE%E7%BD%97%E7%B1%B3%E4%BA%9A%E3%80%8B/</url>
    <content><![CDATA[<h1 id="msl_06_偶尔中二观普罗米亚">MSL_06_偶尔中二——观《普罗米亚》</h1>
<blockquote>
<p>还在慢慢过渡，去接受单身的日子。兴起了，跑来看夜场的&lt;<普罗米亚>&gt;。</p>
</blockquote>
<p>上回专程看动画电影，是一两年前的海贼王剧场版了，而曾经钻研动画分镜、作画的日子，已是模糊不清的高中年代了。 为什么想来看呢。</p>
<span id="more"></span>
<p>听闻是极致的作画与运镜，新时代的艳丽色彩与技术，剧情简单高燃。恰好和我这窝在实验室打工人的胃口——不太想用脑，想体验下动画的新发展（其实知道它19年就已经在日放送）。</p>
<p>购票时厅里只有三人，没想到放映时，居然前前后后来了十来人——出乎所料。</p>
<p><img src="./01.jpg" /></p>
<p>以下写于观影后：</p>
<p>看High了。</p>
<ul>
<li>剧情逻辑不需要一一吐槽，毕竟也不是冲着它来。只是要感叹，编剧的格局真是越来越小了。背景设定略微有阿西莫夫《神们自己》的影子，剧情却发力于一个城市里消防队和反派财团的斗争。以往涉及全球乃至星辰大海的狂想已然逝去了吧，映照出日本现今受资本绑架的羸弱现状。</li>
<li>对我而言，诱发联想的细节好多，全程偷笑：反派的咪咪眼——眯眯眼都是怪物吗&amp;睁眼时就输了； 断掉的左臂——“我把左手赌在新时代了！”；机甲也做了招牌的飞踢——经典的飞踢场景太多了，夏亚的飞踢、骑士踢；中二又羞耻的热血战斗传统——出击摆造型、吼招式、打完一本正经解释技能，真是输赢无所谓，帅就完事了；机甲还是男人的浪漫——燃族的机设头部联想起EVA，以及日本武士盔甲，可惜灭火队用的是三头身的机甲，往可爱方向去靠了；明显的致敬也挺多——天元突破的钻头、博士给的初始机甲与日本机甲动画始祖《铁人28号》。</li>
<li>人设和配音属实符合近来日漫的常见设定啊——有神经大条男主角、鬼马机灵小萝莉、可靠大叔等等。</li>
<li>虽然不知道用得什么新技术或者画风，纯色的矩形和三角形充斥着画面，大面积的荧光色有点晃眼且让我感到细节缺失，但打斗果然很燃。战斗部分的节奏控制的很好，适当插入调皮的笑点调节情绪，到战斗高潮部分佐以泽野弘之一如既往高水准的配乐，让人在观影时的中二之魂复燃了。</li>
<li>可恶啊又被日本悄咪咪地进行文化传播了。日本古时的消防队文化、能剧、各式服装、落语等等，融合在电影里。</li>
</ul>
<p>原来自己的二次元属性未曾褪去啊😂。</p>
<hr />
<p>睡醒后补充：</p>
<p>过去一夜，冷静后再回味。其实电影有许多地方不对味，比如：男儿中性的外貌及恶趣味的人工呼吸长镜头。之所以昨夜能燃起那般兴致，约莫是太久未看动画，各项阈值都降低了吧——未抱着批评家的态度观影，一点点联想、致敬都足以唤起兴奋。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>MSL-07-试了试精酿</title>
    <url>/2021/07/13/MSL-07-%E8%AF%95%E4%BA%86%E8%AF%95%E7%B2%BE%E9%85%BF/</url>
    <content><![CDATA[<h1 id="msl-07-试了试精酿">MSL-07-试了试精酿</h1>
<blockquote>
<p>周末了，被拉出来喝了晚不像啤酒的啤酒——所谓精酿。</p>
</blockquote>
<span id="more"></span>
<p><img src="./msl07_2.jpg" /></p>
<p>没有喝醉，也没酒后艳遇，出门上楼的故事。食斋的罗汉局，四个还逗留校内的哥们出来吹水。</p>
<p>所以没啥段子，没啥故事。</p>
<p>那我写这干嘛？<del>大约是饭后无聊，论文看不进吧。</del>想起刚读过的《反对本本主义》，来随记一点生活体验罢了。</p>
<p>精酿是许久前就知晓的，谁还不是个年薪百万的B乎人呢？然而相关的分享看过不少，各种历史乃至不同产地的风味都略知一二，此前却从未真正跑去喝过。</p>
<p>麦芽、啤酒花香气？泡沫悠长？纸上得来终觉浅罢了。</p>
<p>喝了便知。</p>
<p>简而言之，与往常所接触的工业水啤截然不同。原来啤酒可以含果泥，浓稠到喝完后杯壁上仍挂着一层；加入樱桃等等原料酿造的啤酒，口味又与干红有几分相似……</p>
<p>不把玩文字进行描述了，尝过的酒水不多，难以精确描述。</p>
<p>人嘛，有时间的话还是在法律范围内多亲身体验体验新事物吧。</p>
<p><img src="./msl07_1.jpg" /></p>
<p>废话随记一篇。没有<strong>idea</strong>真是头大唉。</p>
<p>教员说调查就像“十月怀胎”，解决问题就像“一朝分娩”，大约科研也是如此吧，要熬住，要不懈探索。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>MSL-08-假日生活碎片</title>
    <url>/2021/08/13/MSL-08-%E5%81%87%E6%97%A5%E7%94%9F%E6%B4%BB%E7%A2%8E%E7%89%87/</url>
    <content><![CDATA[<h1 id="msl-08-假日生活碎片">MSL-08-假日生活碎片</h1>
<h2 id="科技">科技</h2>
<p>奶奶哭了。</p>
<p>进门，奶奶坐在小板凳上摘菜，哭泣。</p>
<span id="more"></span>
<p>从来没见过奶奶哭。</p>
<p>问起原因，一来，手机怎么捣鼓都打不出、接不进电话，自己搞不懂，家里座机还拆掉了。</p>
<p>更重要的，奶奶亲手抄了几个月的圣经相关的册子，想让爸爸转成电子版，再打印分发给教友们，没办成。不能怪爸爸，毕竟大几万字的手稿，平日工作繁忙，怎有时间一点点敲录。奶奶手头那原始的打印版，印刷的也是模糊不清，无法直接扫描识别录入。</p>
<p>我去了，把手机卡调整下，好了。看到那文稿，上网查下，找到原版pdf，回头抽空打印出来给奶奶送去，就好了。</p>
<p>可是哭泣这事，好不了。</p>
<p>几十年后，说不定也会被科技甩在身后吧。</p>
<p>那时候，互联网说不定过时了，跟晚辈们抱怨怎么上网，消息收不到，资讯搜不出了。新的工具也未必能学会了吧，回忆着自己熟悉的笔记本，哽咽地瞅着新式的高科技。</p>
<h2 id="增肌失败">增肌失败</h2>
<p>大约是意志薄弱的又一体现吧。</p>
<p>返校将至，过去的一个多月，尝试着增肌，不算成功——至少体型上来看是如此。</p>
<p>七月底，体重61kg，九月头，体重在64kg上下浮动，照片对比体型没有显著的肌肉轮廓增长。想着研究生开学时惊艳旧友的计划，怕是泡汤了罢。</p>
<p>有所坚持——每日的徒手训练计划、蛋白质摄入，却又有许多未做——充分的休息、充足的碳水。以及，有氧运动实在是过度了。总是忍不住，去跑个几公里。</p>
<p><img src="./msl_08_01.jpg" /></p>
<p>尽管体型变化不大，肌肉力量还是有所增长的。更为关键的，是跑步，以及徒手健身，提供了纯粹的精神力量——去运动，出汗，感受肌肉的拉伸，乳酸积聚的酸痛时，脑海中的平静。</p>
<p>尤其是在这，朋友聚散分离，各种观念立场矛盾，总被“看不懂但大受震撼”的事件冲击的时段，简单纯粹的运动，一点一滴的进步，予我心安。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>MSL_09_潇洒与猪肉佬</title>
    <url>/2021/09/25/MSL-09-%E6%BD%87%E6%B4%92%E4%B8%8E%E7%8C%AA%E8%82%89%E4%BD%AC/</url>
    <content><![CDATA[<h1 id="msl-09-潇洒与猪肉佬">MSL-09-潇洒与猪肉佬</h1>
<blockquote>
<p>Dry Martini与其说是不如意日子里的倔强与标榜格调的勋章，不如说是风尘掩盖后不小心露出的一点潇洒。</p>
</blockquote>
<p>不用喊“Cheers”，dry martini一人独饮就好。</p>
<p>若说《星际牛仔》演绎了最理想写意的日子的话，《国产凌凌漆》则诙谐地讲述平凡日常里的潇洒。</p>
<span id="more"></span>
<p><img src="./01.png" /></p>
<p>寻常的周六，悠悠闲啃掉三个肉汁丰盈但肉团小的可怜包子后，对着论文发呆。白底黑字，英文不过二十六个字母，排列组合起来愣是让人参不透字段后的想法。</p>
<p>舍友还在睡觉，拉着的窗帘透入薄纱一样淡淡的阳光。这是个该奋斗的早晨，只是遇上了犯懒的我们。</p>
<p>“恼春风</p>
<p>我心因何恼春风</p>
<p>说不出 借酒相送……”</p>
<p>称为歌神是实至名归的，开口几句，便被带入冷雨打蕉叶的凄清冷境。</p>
<p>索性不学了，看《国产凌凌漆》吧。原因无他，只是想起星爷在片中也少见的深情献唱——恰恰是这首《李香兰》。</p>
<p>根正苗红，受过专业训练的特工，哪怕目标在贴面的距离，也无法持枪命中，以卖猪肉为生——听起来，是十足的失败者吧。其实他也有一技傍身，枪械年代下掌握着或许要失传的小李飞刀，还能将把杀猪刀舞得虎虎生风。</p>
<p>要是没这突发的意外任务，凌凌漆同志怕是要卖一辈子猪肉了吧（其实任务后，他也还是做着猪肉佬）。操着神乎其神的杀猪刀片开一块块肉，收工后啜饮一杯干马天尼。</p>
<p>电影总藏着艺术化后的生活碎片。你我又何尝未是个受过专业训练、各自怀揣独有屠龙之技的能人呢。只是时运大多不济，所学未有所展之境罢了。日子过得庸庸碌碌，心中那点小小的坚信不必丢掉，和寻常旁人嬉笑怒骂不恭些也罢。干马天尼是脱离周遭环境的意象，坚守承诺取下白玫瑰的潇洒是其中醉人的酒精。</p>
<p>至于拍摄年代导致影片的背景设定异常，便不必去讨论了吧。</p>
<hr />
<p>跑完长距离，写下随感已是夜阑。细碎唠叨，唠叨得似乎太无章法了啊，改日再做修订吧。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>MSL_10_国庆杂记</title>
    <url>/2021/10/01/MSL-10-%E5%9B%BD%E5%BA%86%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="msl-10-国庆杂记">MSL-10-国庆杂记</h1>
<blockquote>
<p>这就来到第10篇了啊，个人的小角落堆积逐渐丰富。</p>
</blockquote>
<span id="more"></span>
<h2 id="长江二桥上的长跑">长江二桥上的长跑</h2>
<p>两侧高楼林立，夜幕时分，恰是江城灯光秀时。桥下江滩，或排兵列阵跳着广场舞，或小年轻们成双成对迎江风说情话。</p>
<p>不似长江大桥，那边行人穿梭如织。长江二桥上，人行道不过两人并肩宽度，沿着道望去，不见行人，只有身旁川流不息的车。</p>
<p>跑到二桥时，十八公里有多了，右小腿微微有点抽筋。换作在东湖，早就止步休息了吧。偏偏在这桥上，步伐再沉重，也不想歇停——钢筋铁骨的大桥，却似断点，隔绝了两岸的繁华和喧腾，我只需要奔跑，奔跑，不止步。桥上这一公里多，尘世烦扰与我无关，仿若数轴上一动点，纯粹地移动便可。</p>
<p><img src="./01.jpg" /></p>
<p>这也算是孤独长跑的乐事之一吧。</p>
<h2 id="关于我和我的父辈">关于《我和我的父辈》</h2>
<p>为祖国庆生系列电影来到第三部了，显露出疲态。</p>
<p>抗日骑兵团的故事，《乘风》，真诚动人。那段血泪历史，不过分藻饰夸张时，总是以真实的力量冲击着泪腺。</p>
<p>《诗》所述的火箭研究人员达摩边疆奉献青春的故事，以小家庭中两位“爸爸”的逝去，渲染那段奉献的燃情岁月。叙事没能打动我，唯独那诗，让人印象深刻——“宇宙，让死亡变得渺小”。与故事无关，与对深邃宇宙的无尽遐想相关。</p>
<p>随后的两个喜剧单元，感到陌生、无趣。</p>
<p>前两单元的时代是史书、资料、纪录片中所了解的，后两单元的时代是有所经历，但又堪称擦肩而过的。前二单元的先人们，换来了和平的年代；后两单元的人们，共同构建着盛世。上海、深圳呵，毕竟改革开放排头兵，政策试验田。小学生们，也已积极探索科学实验了。挺好，路一步步走。</p>
<p>我们的父辈，只能交给自己去记忆了。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>MSL-11-杂记</title>
    <url>/2021/10/15/MSL-11-%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="杂记没有标题">杂记，没有标题</h1>
<blockquote>
<p>本来是没有标题的，却不知不觉地变成跑步的随想集了。约莫近来生活，跑步成了主旋律吧。</p>
<p>Update：写了3节，这篇杂记可以去掉“To be continued"，换上"The End"了。</p>
</blockquote>
<span id="more"></span>
<h2 id="跑跑跑">1. 跑！跑！跑！</h2>
<blockquote>
<p>村上的《舞！舞！舞！》早已记不清其内容，只剩有力的标题不时闯入脑海。</p>
</blockquote>
<p>左腿！右腿！提膝送髋！跑！跑！跑！不要停！</p>
<p>只为努力咬住前面的人，不要掉队。努力挑战着略超出自己能力的训练时，无暇他想，仿佛所有的脑细胞都被占用——用来向全身肌肉嘶吼、下令：给我动起来，不要掉速。</p>
<p>前面领跑的其实是位女生，男生组的训练更是暂时超出现在个人跑力了。饶是这样，10公里也再次刷新了个人PB。</p>
<p><img src="./01.jpg" /></p>
<p>拉伸后想想，被她拉爆属实正常——人家可是要在汉马冲330完赛的人嘛。</p>
<p>离场时，夜色渐浓，下午短暂歇停的雨水又再洒落，朱红色橡胶场地水洼中摇曳着梧桐叶影。奔跑时，周遭事物都一闪而过；停下脚步，喘息散步时，人事景如一张张胶片般被定格。</p>
<h2 id="免不了的寂寞">2. 免不了的寂寞</h2>
<p>与跑协一同训练，只需咬牙坚持不被拉爆；雨夜独自环山，别有一番意境；唯独是于热闹的操场上刷圈时，免不了的感到寂寞。</p>
<p>下午五点未到，连绵雨后总算放晴的蓝天点缀着鱼鳞般的碎云。绿茵场上赛事正踢得热闹，跑道旁的空地也进行着拔河、跳绳等赛事。我的训练计划，便是在人群和喧闹中穿过，10公里的有氧动力跑再加3公里的乳酸阈值跑——不多，也就绕操场个33圈罢了。</p>
<p>怎么就突然感觉寂寞了呢？或许是有氧跑相对轻松，给了大脑太多运转的空闲；或许是校园操场上，成双成对的同学们较多的原因吧。还是会间断式的不习惯单身——其实也就是当遇到趣事想分享，却发现缺失了可无保留对白的对象。</p>
<p>不过扪心自问，现在的自己似乎还没调整到合适谈恋爱的状态呢。所期盼的，大约是成长为能愉悦地充实自己生活的人先吧。待到那时再谈，也少些患得患失，多些洒脱诗意。</p>
<p>一人赏花，人便是赏花；两人赏花，花依旧，人依旧。</p>
<p>嘿薛三，别瞎想了，你还不够格遇到桃花呢，接着完善自己吧。</p>
<p>所幸，十一月中的合肥马拉松提供了短期的动力与期待。课余闲暇总是忍不住翻阅别人的完赛分享，愈发的跃跃欲试。十月稍稍加大强度的训练，真实地感到实力的提升，不再忧虑无法完赛，反倒添了个人记录的期待——愿首马能破4吧。</p>
<p>村上说希望自己的墓志铭这样写，确实曼妙：</p>
<blockquote>
<p>村上春树 作家（兼跑者） 1949-20XX 他至少是跑到了最后</p>
</blockquote>
<h2 id="难得听回讲座">3. 难得听回讲座</h2>
<blockquote>
<p>论气温，武汉由夏入冬。出街时，瞅见叶红了，柚子又上梢头，才觉有些秋意。</p>
</blockquote>
<p>课不算密集，科研任务尚算可控。忍不住地，想拾起本科时错过的各式讲座。恰巧遇上北大教授谈拉斐尔作品，粗人也能去提升下审美。</p>
<p>文艺复兴三杰之一的拉斐尔，已然去世501年了。艺术之美，约莫在于经得起时间的磨洗吧——再加上一位领路人来导览。</p>
<p>最令人惊奇的，是那位被局促在历史书字段间的康有为，1898年戊戌维新失败后，“遍游四洲，经三十一国，行六十万里路”，寻览全部拉斐尔作品。本是来听拉斐尔故事，却使脑中康有为印象立体起来。</p>
<p>讲座也饶是顾及大众水平，除却构图色彩等美学分析，仿佛来到大型搜证推理现场：在每幅画作中寻找他的签名、分析群像所对应的现实人物，乃至从耳环、衣服褶皱等猜测所画对象为拉斐尔的情人。大约八卦才是真接地气的吧。</p>
<p>感谢教授，领我真切的理解文艺复兴时画作中复苏的“生命力”。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>MSL-12-文字的力量</title>
    <url>/2021/10/26/MSL-12-%E6%96%87%E5%AD%97%E7%9A%84%E5%8A%9B%E9%87%8F/</url>
    <content><![CDATA[<blockquote>
<p>“晨曦载曜，万物咸覩”，五六年没有再打出这行字了。</p>
<p>并非突然追忆起曾经担任所谓文学社社长的日子，只是，想起淡忘的，文字的力量。</p>
</blockquote>
<span id="more"></span>
<p>一点巧合，几分幸运，博客能被人发现，琐碎的念叨能被人喜爱。</p>
<p>其实内心惶恐不安，只因有自知之明，自己文字水平几何，远无法与相识的才子相比。不过，更多的还是欢喜。由衷地感谢那位静悄悄访问的可人儿，告诉我这些平凡的生活随感亦有人阅读，亦感谢那理直气壮的催稿，唤起懒癌拖稿症患者更新的动力。</p>
<p>如此相逢，大约我该感谢文字的力量了。</p>
<p>白底黑字，由字及词成段成章，瞅见文字时，总觉那潜藏着深沉与淡定，以及偌大想象的空间。文字予人的想象力，最让人沉醉。所有的空间，事件，人物，都浓缩在字句中，交由每位读者自由在脑海中揣摩想象。</p>
<p>穿过长长隧道抵达的雪国，是发呆时不错的让思绪逗留的旅店；又或幻想过上如柯希莫男爵一般轻逸的日子，一直在树上生活；再或是去经受些苦难吧，回到百年前的华夏，该如何奋起救亡……</p>
<p>图像、视频，信息的量及维度大大跃升，但总觉着太过直接，少了点含蓄，少了些发呆想象的空间——至少现今过载的图、短视频app令人厌恶。摄影、平面设计或是优秀的影视作品，是该另当别论的。</p>
<p>不小心成了计算机专业的学生后，运动和阅读、输出文字，是不多的感知生活的方式吧。代码与算法，总还是少点人性和生活气息。</p>
<p>祝自己不忘文字的力量，不忘曾向往的卡尔维诺的轻逸——虽然也没完全参透就是了。</p>
<hr />
<p>对了，顺便也拾起当年文学社的口号送给你吧：“努力，终会被看见”。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>MSL-13-不谈风月</title>
    <url>/2021/11/02/MSL-13-%E4%B8%8D%E8%B0%88%E9%A3%8E%E6%9C%88/</url>
    <content><![CDATA[<h2 id="section">1.</h2>
<blockquote>
<p>告别伊豆时，那位“我”的脑中真的如一泓清泉流出吗，不再有舞女的身姿吗？</p>
<p>霍乱时期的那张黄旗，会在内河里一直飘扬吗？</p>
</blockquote>
<span id="more"></span>
<p>回看了下豆瓣已读的书单，谈情说爱的书原来早先读过不少，诸如阿兰德波顿的《爱情笔记》、《在爱情与欲望之间》，又或是《爱的艺术》、《非暴力沟通》等等。内容却都左耳进右耳出，脑中逡巡的日子不过阅读前后一两周罢了。启迪或许是有的，多少曾吸纳了些方法论。更多的，不过是对文中情节发出一时的感慨。绝大内容都已无法回忆，远不如情歌动人持久。</p>
<p>若说恋爱是考试，这些书似乎只用于预习，或是考场速查了，考后也没心思重新翻来检索错题。</p>
<p>所谓纸上得来终觉浅，感情这码事总还是要每人自行去经历、总结，心力憔悴几回，便能摸索个大概。</p>
<p>虽说身边人对情感的渴求愈发旺盛，小览虎扑这种直男社区也可瞅见大伙的浮躁——寻求着快速脱单的技巧。但脱单向来不是心愿的结束，反而是里程的开始。于是乎，看着那些求“术”的人群，总觉得遗憾。</p>
<p>术有其重要性不假，然则修身定性，明晰自身对恋爱的需求与追求更为重要（渣男渣女们大约便只需轻巧的玩弄术式吧）。</p>
<p>情话易说，有点闲钱的人准备几份礼物也不是难事，从始至终担当起责任却是真切的难事。</p>
<p>海誓山盟总是能挑动荷尔蒙的分泌，催眠人的理智。所谓地老天荒等等，煽情处用用也罢，常挂嘴边便只是花言巧语。</p>
<p>我想，立身于现实，刨去对小说影视等内容的幻想，恋人间最真切的盼望和承诺，大约还是“共同成为更好的人”吧——务实，又兼具在时间轴上彼此相伴前行的浪漫。</p>
<p>对了，也当锻造更完整的自我，不谈风月，风月自在。</p>
<hr />
<h2 id="section-1">2.</h2>
<blockquote>
<p><em>Salvator Mundi</em>，《救世主》，专家们鉴定为达芬奇的画作，被深度学习模型 [1] 质疑并非真迹。</p>
</blockquote>
<p>历经千朝百代，尚能被公众所见的艺术品总有些坎坷身世，乃至离奇故事。《富春山居图》如是，达芬奇“所作”的《救世主》亦如是。</p>
<p>只是，这副画作的奇闻轶事，远超我所设想。</p>
<p>起笔初衷，不过是想感叹深度学习的跨界——竟一步踏入画作鉴定的领域。不曾想，查阅资料后，反倒震撼于画作的传奇故事。</p>
<p><img src="./01.png" /></p>
<p>还是回到闲谈的起点吧——深度学习模型本就似黑箱，建模者都不能详尽阐明其背后机制，怎就能用以鉴定画作了？</p>
<p>捣腾深度学习模型的日子，对其态度总有几分割裂。一方面，自己所作成果多似“人工智障”，所学亦让我知晓其能力上界，离强人工智能的时代相去甚远，因而总觉大众对其抱有过高的期望，舆论里泡沫喧嚣太多；另一方面，又不时惊讶于各种AI奇思妙想般的应用，从未想过那些基础的模型可以被迁移魔改至各式奇妙的场景。</p>
<p>粗略阅读这论文，与其说是正儿八经的的学术研究，不如说是研习CNN(卷积神经网络)后学以致用的精巧游戏。称其“精巧”，是佩服于其巧妙的任务定义、模型设计、实验论证，再配上篇似模似样的论文，可以说当个本硕的毕业论文都有余；说其“游戏”，是因为单靠CNN与若干画作样例输入便给出画作真假的判定，更像是一本正经的自说自话——论文里也说了，这判别模型不过是“methodologically sound model”。</p>
<p>不过，这亦引出一有趣话题：人类的智能，是否可交由机器判定？或许这是图灵测试的高阶问题。图灵测试[6]目的仅在测试机器能否表现出与人等价或无法区分的智能，而由机器判定人的智能，或许意味着机器已拥有了人类智能的超集。</p>
<p>小处着眼，现今似乎已有为作文等展示人类创造力成果打分的产品。只不过它们大多基于固定的踩分点等，离真正如人般有理有据衡量他人创作成果差十万八千里。遥望未来，若是人类智能被机器判定，大约意味着统治关系的颠倒，人被奴役于机器也说不定——如《沙丘》中曾经的圣战、《黑客帝国》中虚幻的世界。</p>
<p>人工智能研究的那么一丝丝趣味，在于不想调参炼丹或啃论文时，有个切口能去思索人类的价值与意义，胡思乱想下那遥远的肉身不能抵达的未来。</p>
<hr />
<p>总觉得艺术是人类对自身的反思及对外交互后的产物，是难以编码的混沌信息，且作品定型时不过只完成了一半，彻底的完成则有赖于作品与观众的交互。</p>
<p>还是再瞧多一眼实验结果吧，广义来讲，这何尝不是结合AI后对作品的再创作。</p>
<figure>
<img src="./02.png" alt="Fig.2: Probability maps for Salvator Mundi. The maps color-code the probabilities assigned to the examined regions of an image at a granular level: red corresponds to high-likelihood (≥ 0.65) classification as Leonardo, gold to moderate-likelihood (0.5 ≤ p &lt; 0.65) classification asLeonardo, green to moderate-likelihood (0.5 &gt; p &gt; 0.35) classification as not Leonardo, and blue to high-likelihood (≤ 0.35) classification as not Leonardo." /><figcaption aria-hidden="true">Fig.2: Probability maps for Salvator Mundi. The maps color-code the probabilities assigned to the examined regions of an image at a granular level: red corresponds to high-likelihood (≥ 0.65) classification as Leonardo, gold to moderate-likelihood (0.5 ≤ p &lt; 0.65) classification asLeonardo, green to moderate-likelihood (0.5 &gt; p &gt; 0.35) classification as not Leonardo, and blue to high-likelihood (≤ 0.35) classification as not Leonardo.</figcaption>
</figure>
<p>艺术，在大众参与中丰富而多姿。连这篇随笔，都在互联网光年外的小角落里，为其创作填上了一点点故事。</p>
<p>Reference:</p>
<p>[1] <a href="https://arxiv.org/abs/2005.10600?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;utm_content=178545826&amp;_hsenc=p2ANqtz-8mzSfYtd4GZC22CNAKTe67o7G4-MXdHcUA9sNwZ6DZHlWv0-zdB5XKVWgLbGs9RXATu5SCOIqIr-kiFcdtfcsH7RWviw#">A Neural Network Looks at Leonardo's(?) Salvator Mundi.</a></p>
<p>[2] https://www.bbc.com/culture/article/20210819-where-is-the-worlds-most-expensive-painting</p>
<p>[3] http://art.ifeng.com/2019/0110/3463608.shtml</p>
<p>[4] https://new.qq.com/omn/20210528/20210528A0CD7H00.html</p>
<p>[5] https://cn.thevalue.com/articles/stolen-salvator-mundi-500-year-old-copy-recovered-in-naples</p>
<p>[6] Turing A M. Computing machinery and intelligence[M]//Parsing the turing test. Springer, Dordrecht, 2009: 23-65.</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL_14_星火不熄</title>
    <url>/2021/11/12/MSL-14-%E6%98%9F%E7%81%AB%E4%B8%8D%E7%86%84/</url>
    <content><![CDATA[<blockquote>
<p>长河无声奔去，唯爱与信念永存。</p>
<p>大约借贷了不少幸运，才得以有佳人相伴，赶上了这场舞剧——《永不消逝的电波》。</p>
</blockquote>
<span id="more"></span>
<p>我与舞剧，仿似若即若离。</p>
<p>看电影是轻松的，取了票往影院软凳一躺，兴致其高时说不定还揽一桶爆米花入场（虽然上一次吃爆米花看电影的记忆早已模糊）；观舞剧嘛，刻板印象里将它定义为风雅之事。刷豆瓣活动时总会看到些有趣的剧目，每每为其内容描述心动时，但或因无人作陪，或忧剧目高雅大老粗人难以体悟，总归是在购票界面迟疑许久后，默默地点下取消。</p>
<p>这回，总算是昂首步入了琴台剧院。</p>
<h2 id="无端联想">1. 无端联想</h2>
<p>且说观剧体验。</p>
<p>高坐三楼，俯瞰舞台，看不清舞者细微的神态与动作，却也一览群舞全貌。</p>
<p>虽说些许“一场论”了，但舞剧更有人世的风貌，而电影不过是被镜头捕获的局促视角。初次观剧，用目不暇接来概括最为恰当。舞台上。每位舞者都倾情演绎着自己的角色。携带的望远镜也无用武之地，剧场上各个角落，各个人物都尽心舞蹈着，以律动的肢体叙事——光饱览全貌已然耗尽心神，望远镜着实无法定下关注的焦点。恰似人世，大家都在自己一片时空中过活，时空不时交会，大多并行延申。全知全能如“神”，才能不错过分毫细节；一般人若俯瞰人世，怕也是如观舞剧般，粗览全局后，定睛瞅了这头，漏过了那头。</p>
<p>再谈舞蹈。</p>
<p>对舞蹈几近是白痴，脑中能有印象的舞，是《闻香识女人》里阿尔·帕西诺那曲探戈——和舞剧也不搭边就是了。此番观舞，难说有啥专业见解，只是深深地被曼妙的舞姿打动——举手投足间倾诉的情愫或溢出的力量。</p>
<p>记得一众身着旗袍的舞者，婀娜身姿甚至脱去了想象中民国上海纸醉金迷的脂粉气，约有几分”翩如兰苕翠，婉如游龙举“之貌；记得夜幕中的追捕与搏斗，没有拳拳到肉的实感，没有快切没有特写，但飞舞的黑色衣襟，高跳、翻滚、旋转，依旧描摹着激烈的生死斗争；记得昂首阔步舞至人生终章的豪迈；记得一众烈士步履艰难地带镣前进……</p>
<p>也还记得身边紧握的手。</p>
<p>不多的遗憾，是无法录影吧。恨自己双眼与脑瓜的记录能力有限，不能让我逐帧细致地回味。</p>
<p>舞美设计也与人震撼，奈何文字苍白，那些精巧的编排唯亲临现场才能体会。</p>
<p>便是略提一点有趣的观察吧：裁缝的店铺中，立着一扇镜子。仔细看去，发现镜面并非平整，照镜之人身形都被扭曲拉伸。或许借着反射，暗喻着那时代的光怪陆离罢。</p>
<h2 id="听不见的电波">2. 听不见的电波</h2>
<p>曾看过电影《听风者》，那故事更传奇些——盲人调音师识破敌台。《永不消逝的电波》，才来得真实些，更易设身处地遐想，更易动情。</p>
<p>如今再度富强的华夏，便是当年的同志们，各自坚守自己的一份职责，聚沙成塔，血肉叠铸而成。比起如今的我们，他们大多不会有更多的学识吧，甚至也无更多的阅历——那么多可爱的同志们，从年岁上看不过是个孩子。就像剧中的小裁缝学徒，无任务时蹦蹦跳跳玩乐才是天性，与相遇的卖花的女孩子本还有一段故事可以延展。他们多的，大约是对未来的信念，以及一腔热血吧。相信着中华民族五千年血脉不会中断，相信镰刀锤头能挥舞出光明，相信以自己的生命，做好分内事，便有星星之火，将见燎原。</p>
<p>因而，尤其看不得剧中小裁缝被害后，梦中还魂、道别的场景。一来，带大我、授童稚的我以人生原则的外公逝世后，每每梦见，醒来总是不免泪流，故也算是略知梦见逝者，醒后所感的悲恸、萧瑟；二来，最不忍见孩童生命的消逝。他们本有无穷条交汇、分叉的通往未来的道路，却横地被在主干道上插上此路不通的牌子，此后，再无路可走。</p>
<p>梦中小裁缝的谢幕，最让人动容——他越洒脱，越是安慰、鼓励生者，越使观者反思、自愧——坦然接受死亡的人能有几多，能使短暂人世经历重于泰山者又有几多。</p>
<p>身边的心跳声一个个沉寂下去，空气中总震荡着听不见的电波，夜晚，发报机仍不能停下。回望那段历史，总会满怀敬意。强大的信念与意志，让工作的接力棒在生死两界传递——可慨然赴死，也会负重继续前进。</p>
<h2 id="听不到的故事">3. 听不到的故事</h2>
<p>剧终时，黑底白字，投影出”长河无声奔去，唯爱与信念永存“。</p>
<p>奔涌的长江浪涛滚滚，怎会无声？沉默的，是翻卷浪花下，离去的人们，以及他们无人传述的故事。</p>
<p>遗憾惭愧是难免的，那么多生命无声暗淡了去，甚至连历史的尘埃都不是。</p>
<p>不过，故事大约不是必须的，信念才是。不需要留声机，需要长明的火把。</p>
<p>星火不熄，华夏长存。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL_15_夜与便利店</title>
    <url>/2021/12/13/MSL-15-%E5%A4%9C%E4%B8%8E%E4%BE%BF%E5%88%A9%E5%BA%97/</url>
    <content><![CDATA[<blockquote>
<p>搬家的前一夜，一如往常，走进罗森。打算买两个茶叶蛋，和舍友一人一个分了——煮泡一天的蛋最为入味。却只见一锅红褐色的茶汤，蛋已售罄了。和那胖乎乎的年轻店员对视一眼，又走出店门。</p>
<p>大约很难再见他。</p>
</blockquote>
<p>没有所谓深夜食堂的热络，夜间的便利店，默默消化着每个独身过客。</p>
<span id="more"></span>
<p>总觉着，夜里的便利店，往来的人们总算能卸下一日的包袱或伪装，短暂地释放真实的自我。</p>
<p>它不是酒吧，并不能趁着酒意与人攀谈，彼此交换故事。大多时候，我只是在选购食物、付款间隙，瞄几眼货架前的人们，高脚凳上的人们——大多沉默，享受自己的独处时刻。</p>
<p>有见过：十一点的罗森，邻座四瓶AD钙一字排开，窄桌上再加一份咖喱炸鸡便当，只着手机看直播。一瓶、两瓶，吸管咕噜噜的声音与筷子扒拉米饭刮蹭盒底的声音相和。直到每瓶AD钙上都插了吸管，黑色塑料餐盒只留一点咖喱汁时，便起身离去。</p>
<p>也见过：情侣，大约是热恋期吧。深夜忙碌后，选好食物，不在暖烘烘的店内就餐，倒是寻了店门外的小石凳——女生坐在男生大腿上，团身靠在胸口。</p>
<p>更多的人，像我，不作逗留，一个普通的消费者罢了。进店奔向货架搜寻目标，偶尔的优惠组合会扰乱采购计划。有货，心满意足；售罄，摇摇头，叹气离开。</p>
<p>真正和便利店相伴的，是店员。没有顾客时应该会坐下休息吧，站一夜实在辛苦。夜晚顾客不多，却有其孤独的忙碌。货物补给总是晚上送抵，扫码入库上架，不得停息。</p>
<p>金玟岐17年写的《7-11》，不是我的故事，却照映着城市里的孤勇者们。</p>
<p>不算好吃的食物，不算美丽的价格，只因深夜它有唯一点亮的灯火，变得温暖可爱起来。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL-16-匆匆2021又一年</title>
    <url>/2021/12/28/MSL-16-%E5%8C%86%E5%8C%862021%E5%8F%88%E4%B8%80%E5%B9%B4/</url>
    <content><![CDATA[<blockquote>
<p>总算考完一门硬核的试，抢下些许喘息时间。不知不觉年关又至，流水账般收集下今年尚能想起的记忆碎片吧。</p>
<p>试图手动统计些数据，量化将逝的2021。要是有时间，或许再来做点好看的可视化吧。</p>
</blockquote>
<span id="more"></span>
<h1 id="输出">1. 输出</h1>
<p>2020年彻底抛弃了个人公众号，扼住自己的咽喉，不再发声。2021年，换了这个私人角落，重新逼着自己输出。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;总数&quot;</span>: <span class="number">31</span>,</span><br><span class="line">    <span class="attr">&quot;分类&quot;</span>: &#123;</span><br><span class="line">    	<span class="attr">&quot;ML知识总结&quot;</span>: <span class="number">3</span>,</span><br><span class="line">        <span class="attr">&quot;随笔&quot;</span>: <span class="number">20</span>,</span><br><span class="line">        <span class="attr">&quot;论文笔记&quot;</span>: <span class="number">5</span>,</span><br><span class="line">        <span class="attr">&quot;算法实践&quot;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">&quot;工具人&quot;</span>: <span class="number">2</span>,</span><br><span class="line">	&#125;,</span><br><span class="line">    <span class="attr">&quot;总字数&quot;</span>: <span class="number">33024</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>总字数的统计有偏差有水分，一些读书笔记里包括着复制的内容，一些总结归纳的文字绘制在图片中无法计数。</p>
</blockquote>
<p>总体而言，持续撰写博客是个好的开端，但仍有广阔的发展空间。</p>
<p>每每想到要码稿，对事物的观察就会细致些。无论是论文的研读，还是生活中的种种体验，借着要输出的压力，更能挖掘出易忽略的细节。生活的感知能力随着写作，一点点被唤醒。虽然说来有点矫情，但仍为自己庆幸，寻到了几分对抗冷漠功利社会的“多情”——愿为黄叶驻足，看它摇摆地飘落，乐得雨夜阳台闭目，倾听雨珠敲打万物的声响。</p>
<p>从内容分布上看，呻吟、唠叨太多而干货太少。随笔与学习笔记将近二比一的比例，反映出今年学习总结得太少了些，对半开才是理想情况。此外，学习还主要停留在“集百家所长”的积累阶段，愿明年能厚积薄发，注重知行合一，除了“论文笔记”外，能有更多“算法实践”类别文章的产出。</p>
<h1 id="阅读">2. 阅读</h1>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;书&quot;</span>: <span class="number">12</span>,</span><br><span class="line">    <span class="attr">&quot;影视&quot;</span>: <span class="number">21</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如上，是在豆瓣中可追溯的记录。还有些许看了小半，或是阅后无感等等，未作标记。</p>
<p>少，太少了。堪称贫瘠的一年。</p>
<p>借口是有的，诸如上半年忙着毕设，又遇情感波澜；临了毕业，栽进《沙丘》大长篇里；开学后总算找回阅读的状态，却随着学业渐紧，阅读量像抛物线样起了又伏。</p>
<p>终究是借口。来年但求翻个倍吧，<strong>每月2本</strong>不是难事才对。</p>
<p>所读数量太少，不好意思分享书单。现时回忆起来，《沙丘》系列及《富爸爸，穷爸爸》应被提名——是马上能想起的书。《富爸爸，穷爸爸》催促着人积极入世，与人斗、与金钱为友，摆正心态积极入世。《沙丘》尽管能联系当今世界风云变幻，但仍被我孤立地当成科幻史诗欣赏。从此，脑中除了战火纷飞的三国，满是自由浪漫海贼的大海等外，又多了黄沙漫天的沙丘星可供游历、幻想。</p>
<p>文学作品读少的结果，是遣词造句都干瘪乏力，写这些博客都要绞尽脑汁才能勉强成篇散文。</p>
<p>今年印象最深的影视， 都与满腔热血相关——《觉醒年代》，宣告我们何以选择今日道路；《1950他们正年轻》，述说我们的道路何以延续。历史不可不知不能遗忘，时时回望来时鲜血浇筑的道路，才能更坚定前行的方向。愿能一直赤诚，仿效先人，怀揣大志大义，不被物欲盲目，不为五斗米折腰。</p>
<h1 id="运动">3. 运动</h1>
<p>自8月来的不完全统计数据如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;健身&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;俯卧撑&quot;</span>:&#123;</span><br><span class="line">            <span class="attr">&quot;标准&quot;</span>: <span class="number">2214</span>,</span><br><span class="line">            <span class="attr">&quot;标准慢速&quot;</span>: <span class="number">115</span>,</span><br><span class="line">            <span class="attr">&quot;窄距&quot;</span>: <span class="number">230</span>,</span><br><span class="line">            <span class="attr">&quot;宽距&quot;</span>: <span class="number">284</span>,</span><br><span class="line">            <span class="attr">&quot;偏重&quot;</span>: <span class="number">600</span>,</span><br><span class="line">            <span class="attr">&quot;偏重慢速&quot;</span>: <span class="number">20</span>,</span><br><span class="line">            <span class="attr">&quot;钻石&quot;</span>: <span class="number">1055</span>,</span><br><span class="line">            <span class="attr">&quot;钻石慢速&quot;</span>: <span class="number">100</span>,</span><br><span class="line">            <span class="attr">&quot;Total&quot;</span>: <span class="number">4618</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;撸铁&quot;</span>:&#123;</span><br><span class="line">            <span class="attr">&quot;哑铃弯举7kg&quot;</span>: <span class="number">1138</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃弯举8kg&quot;</span>: <span class="number">212</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃俯身肱三弯举8kg&quot;</span>: <span class="number">176</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃俯身划船5kg&quot;</span>: <span class="number">440</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃俯身划船7kg&quot;</span>: <span class="number">606</span>,</span><br><span class="line">            <span class="attr">&quot;哑铃俯身划船8kg&quot;</span>: <span class="number">360</span>,</span><br><span class="line">            &#x27;哑铃前&amp;侧平举2.5kg&#x27;: <span class="number">1260</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;引体向上&quot;</span>:&#123;</span><br><span class="line">            <span class="attr">&quot;半引体&quot;</span>: <span class="number">470</span>,</span><br><span class="line">            <span class="attr">&quot;正手&quot;</span>: <span class="number">864</span>,</span><br><span class="line">            <span class="attr">&quot;反手&quot;</span>: <span class="number">38</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;举腿&quot;</span>: <span class="number">439</span>, </span><br><span class="line">        <span class="attr">&quot;卷腹&quot;</span>: <span class="number">470</span>,</span><br><span class="line">        <span class="attr">&quot;深蹲&quot;</span>: <span class="number">559</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;跑步&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;总距离/km&quot;</span>: <span class="number">1294.92</span>,</span><br><span class="line">        <span class="attr">&quot;总时间/min&quot;</span>: <span class="number">7497</span>,</span><br><span class="line">        <span class="attr">&quot;半马&quot;</span>: <span class="number">8</span>,</span><br><span class="line">        <span class="attr">&quot;全马&quot;</span>: <span class="number">2</span>,</span><br><span class="line">        <span class="attr">&quot;10km PB&quot;</span>: <span class="string">&quot;00:43:50&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;半马 PB&quot;</span>: <span class="string">&quot;01:43:44&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;全马 PB&quot;</span>: <span class="string">&quot;04:18:59&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>“欲文明其精神，先自野蛮其体魄。 苟野蛮其体魄矣，则文明之精神随之。 ”</p>
</blockquote>
<p>农历新年起开始重拾跑步，下半年开始自重健身。看了数据才知道，原来坚持一点点的锻炼，积少成多也有成百上千的数量，从5公里、十公里，到了能挑战全马的距离。</p>
<p>体型变化仍不甚明显，更多的是对心态的调节吧。不快时，换双跑鞋出门小跑个把小时，或是找出干净地方就地俯卧撑，练到双臂酸胀，整个人趴在地上，心头的烦扰杂念也消散不少。不像其他事物，运动的进步曲线大多平滑且平缓，最能获取一分耕耘一分收获的欢喜。以及胃口是真的好了很多，成“饭学长”了。</p>
<h1 id="其他">4. 其他</h1>
<p>情感方面，高低起伏动荡不安的一年，行至年关总算是到了心略安的时候。今年学业不敢说有何增进，亲密关系的处置方面绝对是学习良多。来到第四季度算是打点好自己重新出发了。</p>
<p>本科毕业的年份，因顺利的保研继续求学，显得平淡。仍是老地方，一点点推进所谓的“科研”吧。</p>
<hr />
<p>匆匆，着实匆匆。跨了年后，欠下的文稿已不想再补。</p>
<p>总结与展望，以及新的FLAG，留待农历新年吧。总觉得《难忘今宵》唱响，一年才是真的到头了。</p>
<p>以及，虚岁已是二三，愿见贤思齐，多内省，多干实事。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL-17-多安的岛</title>
    <url>/2022/06/22/MSL-17-%E5%A4%9A%E5%AE%89%E7%9A%84%E5%B2%9B/</url>
    <content><![CDATA[<blockquote>
<p>孤岛生存，非桃花源，而是片刻的幻梦。抛开高达繁重的设定、历史，不失为佳作。</p>
</blockquote>
<hr />
<p>久违了啊，高达的新剧场版。</p>
<span id="more"></span>
<p><img src="./image-20220622113823158.png" alt="image-20220622113823158" style="zoom:33%;" /></p>
<p>历史的脚注总是简短而片面。哪怕留名者，大多也就寥寥数句记录其官衔军功。其人真实的生命历程，种种细节不可追。借助段段OVA或剧场版展开，延申多些许人物的弧光，实是幸事。</p>
<p>看到本片里坚毅的塞拉，不由忆起《GTO》中她幼年时所一路闯过的磨难；留下“北宋的壶，这可是好东西啊”名梗的马·克贝上校，除善谋权术数，亦是真切地心系地球文化——作战失败时的大笑怕是一种释怀吧。</p>
<p><img src="./image-20220622012934111.png" alt="image-20220622012934111" style="zoom: 33%;" /></p>
<p>以及，库库鲁斯·多安。</p>
<p>哪怕是没看过0079的人，但凡接触过高达相关的游戏，都会记得有个格斗专精、会扔石头的扎古Ⅱ，往往戏称驾驶员为石头哥，却不知其人经历。得以此番，略睹多安的人生碎片。</p>
<p>小队内战的片段，虽然久违的机战动作镜头激起多巴胺的刺激，反倒最令人感到沉重。多安是谁，追溯他过往MS出击的履历，是技术高超乃至坊间评价堪比“赤色彗星”的ACE，却也是驾驶扎古试图逃离战场的人。于是，来袭的原小队里，有视其为叛徒，咬牙切齿要歼灭多安的递补队长；有慕名而来的挑战者；还有暗生情愫却未能理解多安远走缘由的队员。所驾驶的绿扎已然破旧，却仍无言挥舞仅剩的热能斧，击破来者。</p>
<p><img src="./image-20220622111003227.png" alt="image-20220622111003227" style="zoom:33%;" /></p>
<p>斩杀的可是曾经的战友——一同出生入死，将后背交由其保护的战友。他会在想些什么？兵戎相见、刀剑相交之间，没留下互述苦衷的时空。捍卫这弹丸小岛，保护孩子们以赎罪，是多安唯一踏入驾驶舱的理由了吧。多安或许会选择什么都不再想了吧。从战场脱逃的战争机器，只会延续机械的迎战。</p>
<p>阿姆罗最后毁掉多安的扎古，算是将多安从杀人机器中解脱出来。</p>
<p><img src="./image-20220622113008083.png" alt="image-20220622113008083" style="zoom:33%;" /></p>
<p>算是happy ending了吧，核弹被摧毁，小岛彻底失去战略价值，多安岛的和平能延续多些时日。</p>
<p>但转念又觉得唏嘘，联邦的“白色恶魔”阿姆罗，往后宿命仍与战争绑定，直到推着阿克西斯消失在银河彼端的那天。</p>
<hr />
<p>专属于高达的槽点不少：</p>
<ul>
<li><p>财团为了卖模型不择手段啊，强行插入10秒高机动型红扎广告片段；</p>
<p><img src="./image-20220622113922357.png" alt="image-20220622113922357" style="zoom:25%;" /></p></li>
<li><p>重制“我爸爸也没有打过我”，好评；</p>
<p><img src="./image-20220622114220005.png" alt="image-20220622114220005" style="zoom:25%;" /></p></li>
<li><p>阿姆罗不愧白色恶魔，上来就捅驾驶舱，从不手软。</p>
<p><img src="胡扯.assets/image-20220622114048397.png" alt="image-20220622114048397" style="zoom:25%;" /></p></li>
</ul>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>MSL-18-声生不息</title>
    <url>/2022/07/10/MSL-18-%E5%A3%B0%E7%94%9F%E4%B8%8D%E6%81%AF/</url>
    <content><![CDATA[<p>《声生不息》落下帷幕，第一次追完了一档芒果台综艺，此刻，应该记录下什么，评述些什么？</p>
<span id="more"></span>
<h2 id="听歌">听歌？</h2>
<p>发掘新歌手、听喜爱的歌者演绎旧曲当是置于首位的乐趣。</p>
<p>香港新生代Mike同Gigi，此前只略有耳闻，欣赏他们演绎后，被彻底征服；Hacken、千嬅的歌一直在我的歌单里，此回也算是追星成功；不曾想还能见到真声大魔王般的林子祥老师录制节目。</p>
<p>一个季度地录制，给予观众充分的时间了解各位歌手。仍记得初听第一期节目时，吐槽魔动闪霸等——不知道哪里抓出来的喽啰。现今，已发现他们各自的可爱之处、音乐上的造诣。</p>
<p>虽然一些曲目改编得过于华丽而失其本韵，仍有不少舞美与歌唱俱佳的作品产出。不是我过往随笔的风格，掉书袋一样进行罗列。不过随笔就该随心所欲吧，还是列一下印象中喜爱的舞台吧。</p>
<ul>
<li>《单车》 父子，车站，不知将远行或是总算相逢。结合Mike身世，不由就想起日常父子默然对视，心中思绪翻涌，却总是无言；</li>
<li>《红绿灯》大约总有个人，会隔着红绿灯的距离，待到绿灯亮起时，只能夹于人潮中在斑马线上擦身而过吧；</li>
<li>《灰姑娘》Mike唱出了浮夸的感觉；</li>
<li>《高山低谷》《勇》撇开情爱的纷纷扰扰，品味生活的五味吧。</li>
</ul>
<h2 id="小遗憾">小遗憾？</h2>
<p>广东歌这么多年，又怎能是一季节目，十几位歌手能回顾完的呢？</p>
<p>只是，陈胖子你的歌基本集集都被唱，人却一集都不来算什么。一边哭穷一边不出来营业也不发歌，上一首歌还是变成儿歌的《孤勇者》😢；Joey在内地却在另一个台陪着那些只知口水半吊子的假粤语歌《大风吹》的网红们又是什么情况🤦‍♂️；古Sir和Hins怕是和TVB关系不好也来不到现场？</p>
<p>虽然新歌实在太少，但选歌属于是众口难调，不必多言。</p>
<p>政治原因，两伟文，林夕千首填词的曲直接石沉海底，黄伟文填词的歌被翻唱，本人却不得出现在背景介绍中。不能说政治绝对凌驾于艺术，只是涉及民族、家国底线的原则，在公众传媒上不能含糊。</p>
<p>幸运的是仍能欣赏二位的作品，也愿家国能更自由、包容吧。</p>
<h2 id="生生不息">生生不息？</h2>
<p>要正视粤语的地位和历史。</p>
<p>靠着地理位置的优势，广东、港澳的经济才得以在近代腾飞；而由于中英的历史问题，香港特立独行地走了很长一段路。</p>
<p>粤语得以从一众方言中脱颖而出，在近代得到更多的发展和曝光。广东歌，更随着HK八九十年代特殊的经济地位，短暂披上黄金时代的外衣。</p>
<p>而今，该老实承认广东歌不再与繁华挂钩，慢慢成为音乐类别里一小小的按钮才是。</p>
<p>或许未来，是“不生不死”的。难再有过往那般火热的消费者市场，其能吸纳、养活的音乐人便有限。小众门类里，不离不弃的粤语爱好者们亦不会离去。</p>
<blockquote>
<p>香港歌手不會死</p>
<p>怎麼尖酸的你　那樣看不起</p>
<p>漠視　挖苦　比較</p>
<p>恥笑　指責　拋棄這一代</p>
<p>我請你不必再比</p>
<p>贈你這卡式機　聽返你舊時多優美</p>
</blockquote>
<hr />
<p>有趣的是，周末来到武汉的猫咖，老板一直放着声生不息的歌单，吵着不让我午睡——听到就忍不住跟着哼唱。在武汉咖啡馆里听广东歌，一听一下午，巴适。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>Torch_Einsum入门</title>
    <url>/2022/09/19/Torch-Einsum%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<blockquote>
<p>看代码遇到了精妙的<strong>爱因斯坦求和约定（einsum）</strong>，并在zhihu上发现了生动的讲解。简要拆解内容为知识导图做备份。 原文地址👉<a href="https://zhuanlan.zhihu.com/p/361209187">戳这里</a></p>
</blockquote>
<span id="more"></span>
<p>（原文还有结合代码的例子讲解哦！）</p>
<figure>
<img src="./einsum.png" alt="mindmap" /><figcaption aria-hidden="true">mindmap</figcaption>
</figure>
]]></content>
      <categories>
        <category>工具人</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>图预训练-GCC论文笔记</title>
    <url>/2021/07/09/%E5%9B%BE%E9%A2%84%E8%AE%AD%E7%BB%83-GCC%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="论文分享gcc-graph-contrastive-coding-for-graph-neural-network-pre-training">论文分享《GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training》</h1>
<blockquote>
<p>论文链接：http://keg.cs.tsinghua.edu.cn/jietang/publications/KDD20-Qiu-et-al-GCC-GNN-pretrain.pdf</p>
<p>论文会议：KDD2020</p>
<p>论文代码：https://github.com/THUDM/GCC</p>
</blockquote>
<p>写在前面：刚刚开始了解<em>self-supervised learning</em>，本篇工作也有许多前人做了优秀的总结，此篇分享仅作个人阅读记录用，也请各位指出我理解的错漏。</p>
<span id="more"></span>
<h2 id="abstract">1. Abstract</h2>
<h3 id="what-do-they-do">1.1 What do they do</h3>
<p>基于自监督对比学习提出图跨领域(cross-domain)的预训练模型，尝试学习并迁移图结构信息。具体的，通过Random Walk with Restart在每个节点的r-ego network上导出子图，得到正负例，基于MoCo范式进行模型预训练。</p>
<p><img src="./gcc_01.png" style="zoom:50%;" /></p>
<h3 id="whats-amazing-points">1.2 What's amazing points</h3>
<ul>
<li>设计r-ego子图及其预训练任务，尝试捕获可跨领域迁移的structural patterns；</li>
<li>实验表明预训练模型在不同数据集及任务上，经过fine-tuning后可达comparative results。</li>
</ul>
<h3 id="learning-model">1.3 Learning model</h3>
<ul>
<li>graph: graph without node attributes and node labels</li>
<li>self-supervised learning</li>
<li>GNN model: GIN</li>
</ul>
<h2 id="motivation">2. Motivation</h2>
<ul>
<li>目前较少在图上做跨领域预训练的模型;</li>
<li>基于如下假设“代表性的图结构模式是通用的并且可以跨网络转移(<strong>Representative graph structural patterns are universal and transferable across networks.</strong>)”，希望设计预训练模型，习得可迁移的graph embedding。</li>
</ul>
<h2 id="model">3. Model</h2>
<h3 id="the-gnn-pre-training-problem">3.1 The GNN Pre-Training Problem</h3>
<ul>
<li>目标：在不同数据集上预训练得到一个函数<span class="math inline">\(f\)</span>，能将节点映射为低维向量，这个函数能用于新的数据集。</li>
<li>函数<span class="math inline">\(f\)</span>的性质：
<ul>
<li>结构相似性 structural similarity</li>
<li>可迁移性 transferability</li>
</ul></li>
</ul>
<h3 id="gcc-pre-training">3.2 GCC Pre-Training</h3>
<p>基于Contrastive Learning对比学习范式，本工作将<em>subgraph instance discrimination</em>作为预训练任务，<em>InfoNCE</em>作为学习目标，有 <span class="math display">\[
\mathcal{L}=-\log \frac{\exp \left(q^{\top} \boldsymbol{k}_{+} / \tau\right)}{\sum_{i=0}^{K} \exp \left(q^{\top} \boldsymbol{k}_{i} / \tau\right)}
\]</span></p>
<p>其中，<span class="math inline">\(q=f_{q}\left(x^{q}\right)\)</span>，<span class="math inline">\(k=f_{k}\left(x^{k}\right)\)</span>，<span class="math inline">\(f\)</span>为图神经网络，将实例<span class="math inline">\(x\)</span>映射为向量表示，<span class="math inline">\(\tau\)</span>为超参。</p>
<p>对比学习希望给定实例(instance)<span class="math inline">\(q\)</span>，能得到与之最相似的实例<span class="math inline">\(k_{+}\)</span>。</p>
<blockquote>
<p>感谢@<a href="https://www.zhihu.com/people/ju-cheng-37">Tobias Lee</a>的👉<a href="https://tobiaslee.top/2020/05/18/contrastive-learning-notes/">对比学习简介笔记</a></p>
</blockquote>
<p>如上所述，有3个问题需要解决：</p>
<ol type="1">
<li>如何定义图中的子图实例？</li>
<li>实例间的相似度如何评估？</li>
<li>选用什么encoder？</li>
</ol>
<p><strong>1. 设计图中的实例</strong></p>
<p>为了学习节点的结构信息，选择节点临近的子图作为实例。此工作使用<em>r-ego network</em>。即由节点<span class="math inline">\(v\)</span>及其<span class="math inline">\(≤r\)</span>阶的邻居组成的子图。</p>
<p><strong>2. 定义实例相似度</strong></p>
<p>由CV中数据扩增技术启发，此工作通过如下三步获取相似实例：</p>
<pre><code>1.  给定节点$v$，由其出发进行带重启的随机游走Random walk with restart；
2.  随机游走所得节点集，导出它们对应的r-ego子图；
3.  匿名化，将子图节点下标重排为&#123;1,2,……&#125;</code></pre>
<p>匿名化目的：</p>
<ol type="1">
<li>防止模型仅学到“通过比较vertex id来判别相似度”</li>
<li>使模型具备泛化能力 ( 由于 GNN are invariant to permutations)</li>
</ol>
<p><strong>3. encoder选择</strong></p>
<p>本工作选用<strong>GIN</strong>作为编码器。</p>
<p>由于此工作研究的图无特征，此工作提出<em>Generalized positional embedding</em>，使用normalized graph Laplacian的特征向量作为attribute matrix。</p>
<p><img src="./gcc_07.png" /></p>
<h2 id="实验">4. 实验</h2>
<ol type="1">
<li><p>硬件：an Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz, 256GB RAM and 8 NVIDIA 2080Ti GPUs</p></li>
<li><p>预训练数据集</p>
<p><img src="./gcc_06.png" /></p></li>
<li><p>实验结果</p>
<p><img src="./gcc_03.png" /></p>
<p><img src="./gcc_04.png" /></p>
<p><img src="./gcc_05.png" /></p>
<p>从结果可以观察</p>
<ul>
<li>node classification中，预训练模型展现了喜人的可迁移能力；</li>
<li>其他任务中，GCC也与SOTA模型表现相近。</li>
</ul></li>
</ol>
<p>总得来说，预训练完成后的GCC，一方面可以视作图神经网络的初始化参数，另一方面也可以作为强大的节点特征提取器。</p>
<p>其他：</p>
<p>@<a href="https://www.zhihu.com/people/shi-si-lou-de-can-hun-83">十四楼的残魂</a> 对图上的对比学习做了高屋建瓴的总结，推荐阅读！<a href="https://zhuanlan.zhihu.com/p/187247235">论文阅读｜浅谈图上的自监督学习——对比学习</a></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>图神经网络</tag>
        <tag>图表示学习</tag>
      </tags>
  </entry>
  <entry>
    <title>社区发现01-AGM论文笔记</title>
    <url>/2020/12/06/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B001-AGM%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="论文分享community-affiliation-graph-model-for-overlapping-network-community-detection">论文分享《Community-affiliation graph model for overlapping network community detection》</h1>
<blockquote>
<p>日期： 2021. 12. 05</p>
<p>论文链接：https://cs.stanford.edu/~jure/pubs/agmfit-icdm12.pdf</p>
<p>论文会议：ICDM, 2012</p>
</blockquote>
<h2 id="abstract">1. Abstract</h2>
<h3 id="what-do-they-do">1.1 What do they do</h3>
<p>对现实数据中重叠社区的分布进行研究，提出社区-节点的二分图模型<strong>AGM</strong>，并基于<strong>AGM</strong>设计算法完成重叠社区发现任务。</p>
<span id="more"></span>
<h3 id="whats-amazing-points">1.2 What's amazing points</h3>
<ol type="1">
<li>通过数据挖掘研究<strong>社区重叠部分节点对间边的稠密程度</strong>，反驳过往重叠社区发现工作的基础假设；</li>
<li>设计的图生成模型<strong>AGM</strong>能简洁的描述多种社区重叠情况（non-overlap/overlap/nested)</li>
</ol>
<h3 id="learning-model">1.3 Learning model</h3>
<ul>
<li>graph: non-attributed, unweighted graph</li>
<li>unsupervised learning</li>
<li>task: overlapped community detection</li>
</ul>
<h2 id="motivation">2. Motivation</h2>
<ul>
<li><p>Assumptions comparison</p>
<p><img src="./AGM_01.png" style="zoom:80%;" /></p>
<ul>
<li>过往模型假设：社区重叠部分节点对间边是<strong>稀疏的</strong>；</li>
<li>本工作发现：社区重叠部分节点对间边是<strong>稠密的</strong>，即，<strong>节点对间所属相同的社区越多，节点对间越有可能有边</strong>。</li>
</ul></li>
<li><p>Empirical Observations</p>
<ul>
<li><p>实验：</p>
<p><img src="./AGM_02.png" style="zoom:75%;" /></p>
<blockquote>
<p>分别为social network, co-purchasing network, collaboration network</p>
</blockquote>
<p>研究边的分布表明，随着节点对所属相同社区越多，该节点对间有边的概率越大。</p>
<p>作为对比，实验还计算了图中随机两个节点间有边的概率 ≈ <span class="math inline">\(10^{-5}\)</span></p></li>
<li><p>解读：</p>
<p>作者以人际关系举例，诸如“兴趣”、”亲属关系“相近的越多，两人越有可能有联系，又如蛋白质中拥有越多相同的功能模块，越有可能发生交互。</p>
<p><img src="./AGM_03.png" style="zoom:50%;" /></p>
<blockquote>
<p>引 <em>Stanford CS224w</em> slide 直观示例</p>
</blockquote></li>
</ul></li>
</ul>
<h2 id="model">3. Model</h2>
<h3 id="community-affiliation-graph-model-agm">3.1 Community-affiliation graph model (AGM)</h3>
<ul>
<li><p>工作提出的模型主要基于两个要素：</p>
<ol type="1">
<li>社区出现的原因，是源自节点有相近的隶属关系(shared group affiliations)</li>
<li>基于如下事实：人们属于多个社区（朋友，家人和同事），但人们间的联系主要由于某一个主要原因。</li>
</ol></li>
<li><p>模型定义（参见下图）</p>
<p>有二分图 <span class="math inline">\(B(V,C,M)\)</span>， <span class="math inline">\(V,C\)</span>分别为节点集合、社区集合，<span class="math inline">\((u, c) \in M\)</span> 意味着节点<span class="math inline">\(u\)</span>属于社区<span class="math inline">\(c\)</span>；</p>
<p>此外，有对社区集合有概率集 <span class="math inline">\({p_c}\)</span>, <span class="math inline">\(p_c\)</span>表示 ”同属于社区<span class="math inline">\(c\)</span>的节点对间生成边的概率，</p>
<p>所以，给定<span class="math inline">\(B, V\)</span>， 我们能生成图 <span class="math inline">\(G(V,E)\)</span>，通过如下概率方式决定图中边的生成：</p>
<p><span class="math display">\[p(u, v)=1-\prod_{k \in C_{u v}}\left(1-p_{k}\right)\]</span></p>
<blockquote>
<p>即P(u,v 有边) = 1 - P(u, v 在任何一个共同社区概率<span class="math inline">\(p_c\)</span>下都没能生成边)</p>
</blockquote></li>
</ul>
<p><img src="./AGM_04.png" /></p>
<ul>
<li><p>模型表达灵活性</p>
<p>对于重叠/嵌入/非重叠的社区都能描述</p>
<p><img src="./AGM_05.png" /></p></li>
</ul>
<h3 id="agm-for-community-detection">3.2 AGM for Community Detection</h3>
<p>任务：给定无向无权图<span class="math inline">\(G(V,E)\)</span>，通过拟合<strong>AGM</strong>，求最大似然的方式进行重叠社区发现。</p>
<p>似然函数：</p>
<p><span class="math display">\[\underset{B,\left\{p_{c}\right\}}{\operatorname{argmax}} L\left(B,\left\{p_{c}\right\}\right)=\prod_{(u, v) \in E} p(u, v) \prod_{(u, v) \notin E}(1-p(u, v))\]</span></p>
<p>伪码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for iterations to convergence:</span><br><span class="line">    fixed B, update &#123;pc&#125; by gradient descent</span><br><span class="line">    fixed &#123;pc&#125;, update B # use the Metropolis-Hastings algorithm</span><br></pre></td></tr></table></figure>
<h3 id="others">3.3 Others</h3>
<ul>
<li><p>ε-community</p>
<p>上述模型，生成的图中对于无共同社区的节点对，不能生成边，这与实际图的情况不符。</p>
<p>为此，引入一个ε-community，所有节点都属于该社区，设置<span class="math inline">\(p_c=\varepsilon=2|E| /|V|(|V|-1)\)</span>，由此，任意节点能以较低概率生成边。</p></li>
<li><p>the number of community</p>
<p><strong>AGM</strong>中社区的数量为超参，为了找出合适的社区数量，本工作通过：</p>
<p>设置较大数值的社区(<span class="math inline">\(\left|C_{0}\right|=O(|V|)\)</span>)，训练一个初始的模型，并施加<strong>L1</strong>罚项，有</p>
<p><span class="math inline">\(\left\{\hat{p}_{c}(\lambda)\right\}=\underset{\left\{p_{c}\right\}}{\operatorname{argmax}} P\left(G \mid B_{0},\left\{p_{c}\right\}\right)-\lambda \sum_{c}\left|p_{c}\right|\)</span></p>
<p>训练后统计<span class="math inline">\(pc\)</span>不为零的个数作为实际社区数进行模型训练。</p></li>
</ul>
<h2 id="later-works-个人补充">4. Later works (个人补充)</h2>
<ul>
<li><p><strong>BIGCLAM</strong></p>
<blockquote>
<p><em>Overlapping Community Detection at Scale: A Nonnegative Matrix Factorization Approach</em></p>
</blockquote>
<p>可理解为对<em>AGM</em>约束放松的模型，即每个结点属于对应社区的概率是连续且独立的，而非统一的<span class="math inline">\(pc\)</span>,</p>
<p>即得到 隶属权重矩阵 <span class="math inline">\(F \in{|V|}\)</span> x <span class="math inline">\(|C|\)</span>, 每行表示结点<span class="math inline">\(u\)</span>属于社区<span class="math inline">\(c_1,c_2,...,c_k\)</span>的权重。</p>
<p>见下图：</p>
<p><img src="./AGM_06.png" style="zoom:80%;" /></p></li>
<li><p><strong>CommunityGAN</strong></p>
<blockquote>
<p><span class="math inline">\(CommunityGAN: Community Detection with Generative Adversarial Nets\)</span></p>
</blockquote>
<p>将AGM中节点对的生成，扩展为clique的生成，将AGM结合入GAN中完成社区发现.</p></li>
</ul>
<h2 id="thoughts">5. Thoughts</h2>
<ol type="1">
<li><p>工作基于数据集研究所得结论进行了简洁的图生成模型建模，生成方式依照“所属相同社区越多，节点对越可能有边”。但单纯从图生成的角度考虑，图应该不止由社区结构决定边的产生，因此<strong>AGM</strong>模型对图整体结构信息的把握是有缺失的；</p></li>
<li><p>本文所述observation”所属相同社区越多，节点对越可能有边“。但仅从图结构上看，下图a,b 更符合社区的定义”社区内节点的边稠密，社区外节点的边稀疏“。如何<strong>理解、定义重叠社区</strong>，是值得更深入思考的问题。</p>
<p><img src="./AGM_01.png" style="zoom:50%;" /></p></li>
</ol>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>图表示学习</tag>
        <tag>社区发现</tag>
      </tags>
  </entry>
  <entry>
    <title>对比学习_ContrastiveLearning笔记</title>
    <url>/2021/07/22/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0-ContrastiveLearning%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="contrastive-learning-笔记">Contrastive Learning 笔记</h1>
<blockquote>
<p>参考资料：</p>
<ul>
<li>https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html</li>
<li>https://ankeshanand.com/blog/2020/01/26/contrative-self-supervised-learning.html</li>
<li>https://zhuanlan.zhihu.com/p/334732028</li>
<li>https://zhuanlan.zhihu.com/p/367290573</li>
<li>https://zhuanlan.zhihu.com/p/368678302</li>
</ul>
<p>论文引用见文末。</p>
</blockquote>
<span id="more"></span>
<h2 id="motivations">1. Motivations</h2>
<h3 id="纯监督学习的弊端">1.1 纯监督学习的弊端</h3>
<ol type="1">
<li>数据潜在的结构难以通过少量的labels来描述，因而purely supervised learning需要大量样本来学习，同时容易收敛到特殊情况；</li>
<li>模型为针对task-specific，所学的并非可重用的知识。</li>
</ol>
<h3 id="nlp领域预训练模型的进展">1.2 NLP领域预训练模型的进展</h3>
<p>NLP领域如Bert预训练模型，从<strong>海量无标注文本</strong>中学习通用知识的能力。而CV领域的预训练，常为<strong>有监督</strong>，在ImageNet上预训练，但在下游任务中Fine-tuning的效果远不如NLP预训练模型来得显著。那，CV领域，能不能类似的，“充分使用越来越大量的无标注数据，使用越来越复杂的模型，采用自监督预训练模式，来从中吸取图像本身的先验知识分布，在下游任务中通过Fine-tuning，来把预训练过程习得的知识，迁移给并提升下游任务的效果。”</p>
<h3 id="toy-example">1.3 Toy Example</h3>
<p><img src="./flgnn_01.png" /></p>
<p>左图是人们根据记忆草绘的钞票，<strong>抽象程度较高</strong>，右图则是人们对着钞票临摹的结果，是接近<strong>像素级别</strong>的绘制。</p>
<p>尽管无数次看到一美元钞票，人们无法复刻它的全部细节。但是，根据脑中的印象，我们能轻松地把它与其他对象区分。类似地，我们能否构建不关注像素级细节，只编码足以区分不同对象的高级特征的表示学习算法？</p>
<h2 id="brief-introduction">2. Brief Introduction</h2>
<h3 id="goal">2.1 Goal</h3>
<p>Contrastive Learning的目标是学习这样一个嵌入空间，其中<strong>相似的样本对彼此靠近而不同的样本对相距很远</strong>，所得的编码器及嵌入为下游任务所用。</p>
<p>正式地，有：</p>
<p><img src="./flgnn_03.png" /></p>
<p>与supervised learning对比，直观地可见下图：</p>
<p><img src="./flgnn_02.png" /></p>
<h3 id="basic-model-architecture">2.2 Basic model architecture</h3>
<p><img src="./flgnn_04.png" /></p>
<p>主要包括如下三步：</p>
<ol type="1">
<li>对样本<span class="math inline">\(X\)</span>，进行<strong>data augmentation</strong>，得到正样例<span class="math inline">\(V\)</span>，而其他样本的样例则作为本样本的负例<span class="math inline">\(V&#39;\)</span>；</li>
<li>使用<strong>encoder</strong>得到样例的嵌入表示<span class="math inline">\(Y\)</span>；</li>
<li>基于对比学习的<span class="math inline">\(Loss\)</span>进行参数更新。</li>
</ol>
<h2 id="key-ingredients">3. Key Ingredients</h2>
<h3 id="loss-design">3.1 Loss Design</h3>
<blockquote>
<p>Loss的设计、发展详见<a href="https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html#contrastive-training-objectives">Trend of training objectives</a></p>
</blockquote>
<ul>
<li><p>从形式上的发展来说，损失函数从早期仅对一个正负样例对进行学习，逐渐向考虑多个正负样例对发展；</p></li>
<li><p>此外，也有工作跳出self-supervised，将<strong>label信息</strong>也考虑入模型[9]；</p></li>
<li><p>从核心来说，好的损失函数应具备Alignment和Uniformity[1]：</p>
<p><img src="./flgnn_06.png" /></p>
<p>所谓“Alignment”，指的是相似的例子，也就是正例，映射到单位超球面后，应该有接近的特征，也即是说，在超球面上距离比较近；所谓“Uniformity”，指的是系统应该倾向在特征里保留尽可能多的信息，这等价于使得映射到单位超球面的特征，尽可能均匀地分布在球面上，分布得越均匀，意味着保留的信息越充分。Uniformity特性的极端反例，是所有数据映射到单位超球面同一个点上，即模型坍塌（Collapse），如下图：</p>
<p><img src="./flgnn_07.png" style="zoom:50%;" /></p></li>
</ul>
<h3 id="data-augmentation">3.2 Data Augmentation</h3>
<p>给定一个训练样本，需要通过数据增强获取正负样例。合理的数据增强设置对于学习good and generalizable的嵌入表示至关重要。例如，SimCLR[2] 实验表明，随机裁剪和随机颜色失真的组合对于学习图像视觉表示的良好性能至关重要。</p>
<h3 id="large-batch-size">3.3 Large Batch Size</h3>
<p>只有当批量足够大时，损失函数才能覆盖足够多样化的负样本集合，让模型学习有意义的表示以区分不同的示例。但由于硬件的限制，如何让模型能支持更大batch size，需要进一步地考量模型反向传播的方式。</p>
<p>研究有如[3]：</p>
<p><img src="./flgnn_05.png" /></p>
<h2 id="cl-gnn">4. CL + GNN</h2>
<p>目前CL和GNN结合的工作[4-8]，主要是将CL的SOTA模型应用到GNN领域，模型架构上无太大创新。</p>
<p>迁移的主要难点，在于两个领域的输入不同，故CL+GNN的工作，主要创新在于如何对图数据进行augmentation，得到正负样例。</p>
<p>其扩增的方法归类如下：</p>
<p><img src="./flgnn_08.png" /></p>
<hr />
<p>Reference:</p>
<ol type="1">
<li>Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere</li>
<li>A Simple Framework for Contrastive Learning of Visual Representations</li>
<li>Momentum Contrast for Unsupervised Visual Representation Learning</li>
<li>Contrastive multi-view representation learning on graphs</li>
<li>Gcc: Graph contrastive coding for graph neural network pre-training</li>
<li>Deep Graph Infomax</li>
<li>Graph contrastive learning with augmentations</li>
<li>Graph contrastive learning with adaptive augmentation</li>
<li>Supervised contrastive learning</li>
</ol>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>图神经网络</tag>
        <tag>图表示学习</tag>
        <tag>对比学习</tag>
      </tags>
  </entry>
  <entry>
    <title>社区发现02_ComE论文笔记</title>
    <url>/2020/12/06/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B002-ComE%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="论文分享learning-community-embedding-with-community-detection-and-node-embedding-on-graphs">论文分享《Learning community embedding with community detection and node embedding on graphs》</h1>
<blockquote>
<p>论文链接：https://sentic.net/community-embedding.pdf</p>
<p>论文会议：<strong>CIKM 2017</strong></p>
</blockquote>
<h2 id="abstract">1. Abstract</h2>
<h3 id="what-do-they-do">1.1 What do they do</h3>
<p>引入多元高斯分布来描述社区embedding，在LINE的基础上结合社区embedding来同时实现node embedding learning 和 社区发现任务。</p>
<span id="more"></span>
<h3 id="whats-amazing-points">1.2 What's amazing points</h3>
<ul>
<li>使用multivariate Gaussian distribution 多元高斯分布建模社区 ( learn community embedding)；</li>
<li>设计端到端的训练模型，同步学习node embedding，多元高斯分布参数并更新社区发现结果。</li>
</ul>
<h3 id="learning-model">1.3 Learning model</h3>
<ul>
<li>graph：non-attributed graph</li>
<li>unsupervised learning</li>
<li>task：non-overlapped community detection</li>
<li>learning model: Skip-gram based</li>
</ul>
<h2 id="motivation">2. Motivation</h2>
<figure>
<img src="./ComE01.png" alt="motivation" /><figcaption aria-hidden="true">motivation</figcaption>
</figure>
<p>考虑上图3个任务，各自结果有助于提升彼此：</p>
<ol type="1">
<li>① 好的node embedding能捕获图的结构、去除噪音，使用该embedding做输入，有助于community detection；</li>
<li>② 精准的社区发现结果是进行community embedding的基础，因为community embedding是对社区节点特征分布的一种描述；</li>
<li>③ 引入community embedding，可以理解为引入了<strong>high-order information</strong>，能让node embeding更好的关注全局结构信息。</li>
</ol>
<p>关于③，如下图所示：</p>
<p><img src="./ComE02.png" alt="example" style="zoom:50%;" /></p>
<ul>
<li>节点3、10为一阶邻居，但属于不同社区。仅基于first-order proximity的模型无法把握此结构信息；</li>
<li>节点9、10共享了许多二阶邻居，但二者属于不同社区，基于second-order proximity的模型不易描述此差异。</li>
</ul>
<p><strong>Q: 上述3个任务用pipeline实现？</strong></p>
<p>A：可以，如a. 首先用spectral clustering进行社区发现；b. 学习node embedding；c. 基于社区发现结果和node embedding，学习一个分布，以该分布的参数来描述社区(即community embedding)</p>
<p>不过，上述pipeline有缺陷：</p>
<ol type="1">
<li>node embedding方法未引入社区信息；</li>
<li>3个任务独立，无法联合优化训练。</li>
</ol>
<h2 id="model">3. Model</h2>
<p>基于上述motivation，本文提出end-to-end的模型ComE来同步完成上述3个任务。</p>
<h3 id="前导知识">3.0 前导知识</h3>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/30483076">高斯混合模型 GMM</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/64991884">Skip-gram based 图表示学习</a></li>
</ul>
<h3 id="community-detection-embedding">3.1 Community detection &amp; embedding</h3>
<p>本文基于高斯混合模型，假设同社区的node embedding符合正态分布，多个社区的节点混合，组成了多元正态分布。由此，假设每个node embedding <span class="math inline">\(\phi_{i}\)</span>是由其对应的社区<span class="math inline">\(z_i=k\)</span>生成的。</p>
<p>我们有如下似然：</p>
<p><img src="./ComE03.png" /></p>
<p>其中，</p>
<p><img src="./ComE04.png" /></p>
<p>对应commnity detection 任务，节点<span class="math inline">\(i\)</span>所属社区<span class="math inline">\(k\)</span>为最大概率<span class="math inline">\(p(z_i=k)\)</span>，下文记作<span class="math inline">\(\pi_{ik}\)</span>。</p>
<p>对应community embedding任务，给定输入node embedding <span class="math inline">\(\Phi\)</span>，我们目标是学习最合适的<span class="math inline">\((\Psi, \Sigma)\)</span>。</p>
<h3 id="node-embedding-loss-function">3.2 Node embedding &amp; Loss function</h3>
<p>基于LINE，有对应一阶、二阶相似性的目标函数：</p>
<p><img src="./ComE05.png" /></p>
<p><img src="./ComE06.png" /></p>
<p><img src="./ComE07.png" /></p>
<p>同时，希望同社区内node embedding相近，设计有：</p>
<p><img src="./ComE08.png" /></p>
<p>故模型最终的损失函数为：</p>
<p><img src="./ComE09.png" /></p>
<h3 id="inference略">3.3 Inference(略)</h3>
<p>文章进一步讨论了如何实现对上述损失函数的优化，详情略。</p>
<p>简略伪码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Initialize Φ and Φ′ by DeepWalk</span><br><span class="line">for i in range(iterations):</span><br><span class="line">	Fix (Φ, Φ′), optimize (Π, Ψ, Σ).</span><br><span class="line">	Fix (Π, Ψ, Σ), optimize (Φ, Φ′).</span><br></pre></td></tr></table></figure>
<h2 id="experiments略">4. Experiments(略)</h2>
<p>本工作就模型进行全面的实验，包括1. graph visualization; 2. community detection; 3. node classification; 4. model study.</p>
<h3 id="baselines">4.1 baselines</h3>
<ul>
<li>SF: straightforward approach, 与本工作做对照的pipeline。分别使用：Spectral Clustering for community detection; DeepWalk for node embedding; use GMM to fit community</li>
<li>DeepWalk, LINE, Node2Vec, GraRep: Skip-gram based model</li>
<li>M-NMF: non-negative matrix factorization based</li>
</ul>
<h3 id="graph-visualization">4.2 Graph Visualization</h3>
<p><img src="./ComE10.png" style="zoom:80%;" /></p>
<h3 id="community-detection">4.3 Community Detection</h3>
<p><img src="./ComE11.png" /></p>
<h3 id="node-classification">4.4 Node Classification</h3>
<p><img src="./ComE12.png" /></p>
<p><img src="./ComE13.png" /></p>
<blockquote>
<p><strong>Flickr</strong>数据集中缺失项，是由于模型训练爆内存无法完成</p>
</blockquote>
<h3 id="model-study">4.5 Model Study</h3>
<p><img src="./ComE14.png" /></p>
<h2 id="thoughts">5. Thoughts</h2>
<ol type="1">
<li>为什么用GMM建模社区？社区结构用GMM描述合适吗？</li>
<li>除了用多元高斯分布，如何更显式的建模社区结构？</li>
<li>motivation 阐述的Loop中，community embedding是否真的有必要？</li>
</ol>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>图表示学习</tag>
        <tag>社区发现</tag>
      </tags>
  </entry>
  <entry>
    <title>社区发现03_GEMSEC论文笔记</title>
    <url>/2020/12/06/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B003-GEMSEC%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="论文笔记gemsec-graph-embedding-with-self-clustering">论文笔记《GEMSEC: Graph Embedding with Self Clustering》</h1>
<blockquote>
<p>论文链接：https://arxiv.org/abs/1802.03997</p>
<p>论文会议：ASONAM, 2019</p>
<p>论文代码：https://github.com/benedekrozemberczki/GEMSEC</p>
</blockquote>
<h2 id="abstract">1. Abstract</h2>
<h3 id="what-do-they-do">1.1 What do they do</h3>
<p>工作基于Skip-gram提出<strong>GEMSEC</strong>模型，通过在损失函数中加入clustering cost来要求社区节点表示的近似性，该模型能同步完成节点嵌入学习和社区发现。</p>
<span id="more"></span>
<h3 id="whats-amazing-points">1.2 What's amazing points</h3>
<ul>
<li>类似<strong>K-Means</strong>，通过计算节点与所属的聚类中心距离，设计clustering lost；</li>
<li>基于对社交网络中“同社区内邻居节点高度重合”的观察，设计regularization term来降低参数敏感性</li>
</ul>
<h3 id="learning-model">1.3 Learning model</h3>
<ul>
<li>graph：non-attributed graph</li>
<li>unsupervised learning</li>
<li>task：non-overlapped community detection</li>
<li>learning model: Skip-gram based</li>
</ul>
<h2 id="motivation">2. Motivation</h2>
<ul>
<li>借助<strong>K-Means</strong>算法思路来描述节点与社区（聚类）的关系；</li>
<li>在社交网络中，同属一个社区的节点可能有许多相同的朋友，这意味着社区中<strong>节点邻居重叠度很高</strong>。</li>
</ul>
<h2 id="model">3. Model</h2>
<h3 id="clustering-cost">3.1 Clustering Cost</h3>
<p><img src="./gemsec_01.png" /></p>
<p><span class="math inline">\(f(v)\)</span>即节点<span class="math inline">\(v\)</span>的嵌入表示，<span class="math inline">\(\mu_c\)</span>为第<span class="math inline">\(c\)</span>个社区(或理解为cluster)的社区中心向量表示。</p>
<p>clustering cost目标是最小化节点嵌入和其社区中心的距离，使得同社区节点的表示近似。</p>
<h2 id="smoothness-regularization">3.2 Smoothness Regularization</h2>
<p>基于motivation中第二点对社交网络的观察，提出如下正则项：</p>
<p><img src="./gemsec_02.png" /></p>
<p>其中，<span class="math inline">\(w(v,u)\)</span>为节点间邻居重叠度，即<span class="math inline">\(\frac{N(a) \cap N(b)}{N(a) \cup N(b)}\)</span>。</p>
<p>所以，上式可以理解为：</p>
<ul>
<li>节点<span class="math inline">\(u,v\)</span>共享邻居越多，越可能同属一个社区，于是<span class="math inline">\(w(v,u)\)</span>趋近1，则两节点的嵌入表示应当相近；</li>
<li>反之，共享邻居少，<span class="math inline">\(w(v,u)\)</span>趋近0，则不强求二者表示相近。</li>
</ul>
<h3 id="others">3.3 others</h3>
<p>本工作还讨论了learning rate及其他超参的退火调整，整个模型算法伪码如下：</p>
<p><img src="./gemsec_03.png" style="zoom:50%;" /></p>
<h2 id="thoughts">4. Thoughts</h2>
<ul>
<li>与<strong>KMeans</strong>局限性类似，本工作发现的社区是否很大程度受聚类中心节点初始化的影响；</li>
<li>比起得到embedding后再用<strong>KMeans</strong>，本工作简单的走多一步但取得更好的效果——大约还是要多实验、并自信地发出来吧。</li>
</ul>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>图表示学习</tag>
        <tag>社区发现</tag>
      </tags>
  </entry>
  <entry>
    <title>社区发现04_NOCD论文笔记</title>
    <url>/2020/12/06/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B004-NOCD%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="论文分享overlapping-community-detection-with-graph-neural-networks">论文分享《Overlapping Community Detection with Graph Neural Networks》</h1>
<blockquote>
<p>论文链接：https://arxiv.org/pdf/1909.12201.pdf</p>
<p>论文会议：<strong>DLG 2019</strong></p>
</blockquote>
<h2 id="abstract">1. Abstract</h2>
<h3 id="what-do-they-do">1.1 What do they do</h3>
<p>面向<strong>重叠社区</strong>问题，结合 GNN 和 Bernoulli-Poisson 概率模型进行建模。</p>
<span id="more"></span>
<h3 id="whats-amazing-points">1.2 What's amazing points</h3>
<h3 id="learning-model">1.3 Learning model</h3>
<ul>
<li>graph：attributed graph</li>
<li>supervised learning</li>
<li>task：overlapped community detection</li>
<li>learning model: GNN based</li>
</ul>
<h2 id="motivation">2. Motivation</h2>
<p>当前缺少进行<strong>重叠社区发现</strong>的工作。</p>
<h2 id="model">3. Model</h2>
<h3 id="前导简介">3.1 前导简介</h3>
<ol type="1">
<li><p>Affiliation Matrix <span class="math inline">\(F \in \mathbb{R}_{\geq 0}^{N \times C}\)</span>, 每列表示对应节点属于该社区的强度。用以表示节点属于多社区的结果。</p></li>
<li><p>Bernoulli-Poisson</p>
<p>伯努利-泊松模型是一个重叠社团的图生成模型。对于给定的隶属关系矩阵 <span class="math inline">\(F\)</span>，可以得到邻接矩阵 Auv 采样为：</p>
<p><span class="math display">\[A_{u v} \sim Bernoulli \left(1-\exp \left(-F_{u} F_{v}^{T}\right)\right)\]</span></p>
<p>其中，行向量 Fu 表示节点 u 的社团隶属关系。从上式可以看出节点 u 和节点 v 之间属于相同社团的数量越多说明两节点之间存在边的概率越高。</p></li>
</ol>
<h3 id="模型架构">3.2 模型架构</h3>
<p>两层GCN：</p>
<p><span class="math display">\[F:=\operatorname{GCN}_{\theta}(A, X)=\operatorname{ReLU}\left(\hat{A} \operatorname{ReLU}\left(\hat{A} X W^{(1)}\right) W^{(2)}\right)\]</span></p>
<p>对于伯努利-泊松模型的负对数似然函数为：</p>
<p><span class="math inline">\(-\log p(A \mid F)=-\sum_{(u, v) \in E} \log \left(1-\exp \left(-F_{u} F_{v}^{T}\right)\right)+\sum_{(u, v) \notin E} F_{u} F_{v}^{T}\)</span></p>
<p>由于现实中的图是非常稀疏的，因此上式中的第二项对于损失函数的贡献较大。可以通过不平衡分类的方法来消除这两项的不平衡：</p>
<p><span class="math inline">\(\mathcal{L}(F)=-\mathbb{E}_{(u, v) \sim P_{E}}\left[\log \left(1-\exp \left(-F_{u} F_{v}^{T}\right)\right)\right]+\mathbb{E}_{(u, v) \sim P_{N}}\left[F_{u} F_{v}^{T}\right]\)</span></p>
<p>其中 <span class="math inline">\(P_E\)</span>和 <span class="math inline">\(P_N\)</span> 分别表示边存在或者不存在的均匀分布。</p>
<p>其它论文中的方法通常是直接优化隶属矩阵 <span class="math inline">\(F\)</span> , 本文中直接通过最小化对数似然函数的值来调整神经网络的参数：</p>
<p><span class="math inline">\(\boldsymbol{\theta}^{\star}=\underset{\boldsymbol{\theta}}{\arg \min } \mathcal{L}\left(\operatorname{GNN}_{\boldsymbol{\theta}}(A, X)\right)\)</span></p>
<h2 id="实验">4. 实验</h2>
<ol type="1">
<li><p>数据集</p>
<ul>
<li>标准的 Facebook 数据集</li>
<li>作者自己提供的四个数据集：Chemistry、Computer Science、Engineering 和 Medicine。</li>
</ul></li>
<li><p>相关参数</p>
<p>对于生成的隶属矩阵，作者采用隶属阈值 <span class="math inline">\(ρ=0.5\)</span> 来判定是否属于某社团。对于评价指标，文中仅使用了重叠的 NMI 值来对比不同模型的结果。NOCD-G 表示以邻接矩阵 <span class="math inline">\(A\)</span>作为节点属性输入，NOCD-X 表示以原节点属性值作为输入。</p></li>
<li><p>实验结果</p>
<p>NMI 比较</p>
<figure>
<img src="./NOCD_01.png" alt="image-20201121084217604" /><figcaption aria-hidden="true">image-20201121084217604</figcaption>
</figure>
<p>GNN重要性比较</p>
<p><img src="./NOCD_02.png" /></p></li>
</ol>
<h2 id="后续">5. 后续</h2>
<p>经更多了解，本工作中讨论的矩阵<span class="math inline">\(F\)</span>，实际是源自<a href="https://www.researchgate.net/publication/262272761_Overlapping_community_detection_at_scale_A_nonnegative_matrix_factorization_approach">BIGCLAM</a> 的设计。</p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>图表示学习</tag>
        <tag>社区发现</tag>
      </tags>
  </entry>
  <entry>
    <title>社区发现05-CommunityGAN论文笔记</title>
    <url>/2021/01/01/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B005-CommunityGAN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="论文分享communitygan-community-detection-with-generative-adversarial-nets">论文分享《CommunityGAN: Community Detection with Generative Adversarial Nets》</h1>
<blockquote>
<p>论文链接：https://arxiv.org/pdf/1901.06631</p>
<p>论文会议：The World Wide Web Conference, 2019</p>
</blockquote>
<h2 id="abstract">1. Abstract</h2>
<h3 id="what-do-they-do">1.1 What do they do</h3>
<p>通过真实数据集上的统计研究，验证了clique与community的强相关性，并基于GAN思路建模，结合AGM来同步完成<strong>社区发现</strong>和<strong>节点表示学习任务</strong>。</p>
<span id="more"></span>
<p><img src="./ComGAN_01.png" style="zoom:50%;" /></p>
<h3 id="whats-amazing-points">1.2 What's amazing points</h3>
<ul>
<li>将AGM中节点对的生成公式，扩展为clique的生成公式，并设计相应random walk，从motivation到建模实现较为清晰；</li>
<li>在合成数据集及真实数据的实验中，社区发现任务的结果较为理想。</li>
</ul>
<h3 id="learning-model">1.3 Learning model</h3>
<ul>
<li>GAN based</li>
<li>unsupervised learning</li>
<li>overlapped community detection</li>
<li>non-attributed graph</li>
</ul>
<h2 id="motivation">2. Motivation</h2>
<ol type="1">
<li><p>当前缺少对重叠社区发现任务的建模；</p></li>
<li><p>数据分析发现，团和社区结构常同时出现。具体分析如下：</p>
<ul>
<li><p>在分别在全图及社区中抽样2/3/4个节点，统计节点能组成团clique的概率，结果如下：</p>
<p><img src="./ComGAN_06.png" style="zoom:67%;" /></p></li>
<li><p>统计“节点集同属社区的个数-节点集形成团”间的关系，结果如下：</p>
<p>表明<strong>节点集共享社区越多，越有可能形成团</strong>。</p>
<blockquote>
<p>此前<strong>AGM</strong>中节点对与共享社区关系的数据分析，可以理解为2-Clique，而本文则进一步研究3,4-Clique与共享社区的关系。</p>
</blockquote>
<p><img src="./ComGAN_02.png" style="zoom:50%;" /></p>
<p>综上所属，团与社区结构密切相关。</p></li>
</ul></li>
</ol>
<h2 id="model">3. Model</h2>
<h3 id="framework">3.1 Framework</h3>
<p>基于GAN建模，生成器G和判别器D迭代学习（此处引入强化学习中常用的<em>policy gradient</em>来训练）。</p>
<p>其中，</p>
<ul>
<li>G用于生成最像clique的节点子集（也可理解为从图中抽取节点子集，并且该子集尽可能像clique）。</li>
<li>D则判别上述节点子集是否在图中为clique</li>
</ul>
<p>上述目标形式化表示为： <span class="math display">\[
\begin{array}{l}
\min _{\theta_{G}} \max _{\theta_{D}} V(G, D)=\sum_{c=1}^{V}\left(\mathbb{E}_{m \sim p_{\text {true}}}\left(\cdot \mid v_{c}\right)\left[\log D\left(m ; \theta_{D}\right)\right]\right. \\
\left.\quad+\mathbb{E}_{s \sim G\left(s \mid v_{c} ; \theta_{G}\right)}\left[\log \left(1-D\left(s ; \theta_{D}\right)\right)\right]\right)
\end{array}
\]</span> <img src="./ComGAN_03.png" style="zoom:60%;" /></p>
<blockquote>
<p>乍一看此时还未和社区发现、图表示学习产生关联，切莫着急，作者按顺序慢慢推导建模。</p>
</blockquote>
<h3 id="a-naive-implementation-of-d-and-g">3.2 A Naive Implementation of D and G</h3>
<ul>
<li>判别器<strong>D</strong>：连乘经过sigmoid函数后的节点向量内积</li>
</ul>
<p><span class="math display">\[
D(s)=\prod_{(u, v) \in s, u \neq v} \sigma\left(\mathrm{d}_{u}^{\top} \cdot \mathrm{d}_{v}\right)
\]</span></p>
<ul>
<li>生成器<strong>G</strong>：</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp; G\left(s \mid v_{c}\right) \\
=&amp; G_{v}\left(v_{s_{2}} \mid v_{s_{1}}\right) G_{v}\left(v_{s_{3}} \mid v_{s_{1}}, v_{s_{2}}\right) \cdots G_{v}\left(v_{s_{m}} \mid v_{s_{1}}, \ldots, v_{s_{m-1}}\right)
\end{aligned}
\]</span></p>
<p>基于此前采的节点集<span class="math inline">\({v_{s_1},...,v_{s_{m-1}}}\)</span>,来生成<span class="math inline">\(v_{s_m}\)</span>，最后得到生成的节点子集。</p>
<p>最直接的方法，通过softmax来完成上述采样计算： <span class="math display">\[
G_{v}\left(v_{s_{m}} \mid v_{s_{1}}, \ldots, v_{s_{m-1}}\right)=\frac{\exp \left(\sum_{i=1}^{m-1} \mathbf{g}_{v_{s_{m}}}^{\top} \mathbf{g} v_{s_{i}}\right)}{\sum_{v \notin\left(v_{s_{1}}, \ldots, v_{s_{m-1}}\right)} \exp \left(\sum_{i=1}^{m-1} \mathbf{g}_{v}^{\top} \mathbf{g}_{v_{s_{i}}}\right)}
\]</span></p>
<h3 id="communitygan">3.3 CommunityGAN</h3>
<p>上述实现有如下缺陷：</p>
<ul>
<li>未能实现社区发现</li>
<li>softmax计算开销大</li>
<li>softmax忽略图结构信息</li>
</ul>
<p>为此，引入<strong>AGM</strong>进行建模，<strong>AGM</strong>基本示意图如下：</p>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/331754085">AGM论文笔记</a></p>
<p>用一个非负矩阵<span class="math inline">\(F\)</span>描述每个节点与社区的隶属关系，每行表示该行对应节点属于各个社区的概率。</p>
<p>有了<span class="math inline">\(F\)</span>后，生成新图<span class="math inline">\(G&#39;\)</span>，对于节点对<span class="math inline">\(u,v\)</span>间是否有边，依照如下公式计算概率 <span class="math display">\[
p(u, v)=1-\exp \left(-F_{u}^{\top} \cdot F_{v}\right)
\]</span></p>
</blockquote>
<p><img src="./ComGAN_04.png" style="zoom:50%;" /></p>
<p>将上式扩展为“对于节点集<span class="math inline">\(v_{1,...m}\)</span>，能形成clique的概率”： <span class="math display">\[
\begin{aligned}
p\left(v_{1}, v_{2}, \ldots, v_{m}\right) &amp;=1-\prod_{c}\left(1-p_{c}\left(v_{1}, v_{2}, \ldots, v_{m}\right)\right) \\
&amp;=1-\exp \left(-\odot\left(F_{v_{1}}, F_{v_{2}}, \ldots, F_{v_{m}}\right)\right)
\end{aligned}
\]</span> 自然而然，我们可以用上式作为判别器D，即 <span class="math display">\[
D(s)=1-\exp \left(-\odot\left(\mathrm{d}_{v_{1}}, \mathrm{~d}_{v_{2}}, \ldots, \mathrm{d}_{v_{m}}\right)\right)
\]</span> 生成器G中每个节点的采样也可基于上式，使用softmax计算采样概率： <span class="math display">\[
\begin{array}{l}
G_{v}\left(v_{s_{m}} \mid v_{s_{1}}, \ldots, v_{s_{m-1}}\right) \\
=\frac{1-\exp \left(-\odot\left(\mathrm{g} v_{s_{1}}, \ldots, \mathrm{g}_{v_{s_{m}}}\right)\right)}{\sum_{v \notin\left(v_{s_{1}}, \ldots, v_{s_{m-1}}\right)} 1-\exp \left(-\odot\left(\mathrm{g}_{v_{s_{1}}}, \ldots, \mathrm{g}_{v_{s_{m-1}}}, \mathrm{~g}_{v}\right)\right)}
\end{array}
\]</span> 具体采样则通过random walk实现。</p>
<p>模型算法如下：</p>
<p><img src="./ComGAN_07.png" style="zoom:80%;" /></p>
<p>算法中的<span class="math inline">\(\theta_{G,D}\)</span>即为<strong>AGM</strong>模型中的非负矩阵<span class="math inline">\(F\)</span>，用以完成社区发现。</p>
<p><strong>实现细节</strong>：</p>
<ul>
<li><p>矩阵<span class="math inline">\(\theta\)</span>文章给出两种初始化方式（延用前人模型方法），分别为(1) 训练AGM模型；(2) locally minimal neighborhoods 算法；</p></li>
<li><p>为了让<strong>G</strong>能采样出最像clique的节点子集，本文设计了如下random walk：</p>
<p><img src="./ComGAN_05.png" /></p></li>
</ul>
<h2 id="experiments">4. Experiments</h2>
<h3 id="合成数据集">4.1 合成数据集</h3>
<p>作者希望通过实验证明：</p>
<ul>
<li>CommunityGAN能有效在社区重叠稠密的图上完成社区发现工作</li>
<li>motif-level生成与判别的能力</li>
</ul>
<p>基于<em>Distributed Generation of Billion-node Social Graphs with Overlapping Community Structure</em>工作生成如下合成图：</p>
<p><img src="./ComGAN_08.png" style="zoom:67%;" /></p>
<blockquote>
<p>可见合成的图社区重叠率都很高。</p>
</blockquote>
<p>实验结果如下：</p>
<p><img src="./ComGAN_09.png" style="zoom:67%;" /></p>
<p><img src="./ComGAN_10.png" style="zoom:67%;" /></p>
<h3 id="真实数据集">4.2 真实数据集</h3>
<p>实验结果如下:</p>
<p><img src="./ComGAN_11.png" style="zoom:67%;" /></p>
<h2 id="thoughts">5. Thoughts</h2>
<ul>
<li>Cliques与社区结构常常共同出现不假，但非社区结构的必要特征，还是要看数据集的真实分布情况。可能模型对部分数据集的拟合能力较差。</li>
<li>文章有点tricky的描述：模型学得了有解释意义的节点embedding，每个维度代表属于对应社区的强度。但事实上，模型所谓的embedding即是AGM模型中的矩阵<span class="math inline">\(F\)</span>。如此一来，embedding维度受限与社区个数，而非任意取值了。</li>
<li>作为建模工作的副产物，本文似乎为图数据挖掘中clique挖掘带来了新思路。</li>
</ul>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>图表示学习</tag>
        <tag>社区发现</tag>
      </tags>
  </entry>
  <entry>
    <title>联邦学习01--技术层面的联邦入门</title>
    <url>/2021/04/23/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A001-%E6%8A%80%E6%9C%AF%E5%B1%82%E9%9D%A2%E7%9A%84%E8%81%94%E9%82%A6%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h1 id="联邦学习01技术层面的联邦入门">联邦学习01——技术层面的联邦入门</h1>
<blockquote>
<p>本篇联邦学习 Federated Learning笔记 总结自课程：<a href="https://www.youtube.com/watch?v=STxtRucv_zo">https://www.youtube.com/watch?v=STxtRucv_zo</a></p>
</blockquote>
<span id="more"></span>
<h1 id="motivation简述">1. motivation简述</h1>
<div data-align="center">
<img src="./FL01_motivation.png" alt="FL01_motivation" style="zoom:75%;" />
</div>
<p>以Google为例，Google有许多app运行在各种各样的的手机上。</p>
<ul>
<li>目标：希望使用<strong>用户数据</strong>训练模型；</li>
<li>最直接的方案：收集用户数据至服务器，使用集群完成模型训练；</li>
<li>问题：需要保护<strong>用户数据隐私</strong>！用户不愿提供个人数据。</li>
</ul>
<p>总结：</p>
<p>在许多场景中，人们希望在<strong>数据不出本地，保护隐私</strong>的情况下，利用<strong>多方数据</strong>训练更好的模型。</p>
<p>为达成上述目标，人们提出了<strong>联邦学习Federated Learning</strong>的概念</p>
<h1 id="概念辨析">2. 概念辨析</h1>
<p>联邦学习，本质上是<strong>特殊需求下的分布式学习</strong>。</p>
<p>我们回顾分布式学习的基本场景：</p>
<div data-align="center">
<img src="./FL01_distributedL.png" alt="FL01_motivation" style="zoom:50%;" />
</div>
<ul>
<li>worker节点：负责接收server传来的更新后的参数，冰计算本地数据的gradient，发送gradient给server；</li>
<li>server节点：负责接收gradients，计算global gradient后更新参数并发还。</li>
</ul>
<p>上述范式中，我们看到workers就如多方数据源，在分布式学习的场景下，数据没有离开worker，吻合联邦学习的初衷。</p>
<p>实际上，联邦学习就是在具体挑战下的分布式学习，其所面临场景有如下特征：</p>
<div data-align="center">
<img src="./FL01_scenario.png" alt="FL01_motivation" style="zoom:100%;" />
</div>
<h1 id="研究方向">3. 研究方向</h1>
<p>联邦学习的特殊场景带来了新的挑战，其主要研究方向如下：</p>
<ol type="1">
<li><p>communication-efficiency</p>
<p>如上图，可见通信开销是模型训练的主要阻碍，如何提升通信效率是一大方向，</p>
<p>常见思路，是<strong>多进行本地计算，减少通信</strong>。代表如<em>FedAvg</em>——在本地迭代多个epochs后再发送gradient；</p></li>
<li><p>privacy</p>
<p>数据不出本地不意味着绝对安全，发送的梯度、参数等都包含数据信息，甚至可能被逆向，如何进行更好的隐私保护，同时平衡模型的性能损失，亦是一大方向；</p></li>
<li><p>adversarial robustness</p>
<p>e.g. <a href="https://baike.baidu.com/item/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98">拜占庭将军问题</a>，节点中出了“叛徒”，发送错误的梯度等，如何抵抗其对模型的影响。</p></li>
</ol>
]]></content>
      <categories>
        <category>ML知识总结</category>
      </categories>
      <tags>
        <tag>联邦学习</tag>
      </tags>
  </entry>
  <entry>
    <title>联邦学习02--读综述与谷歌开山论文的笔记</title>
    <url>/2021/04/23/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A002-%E8%AF%BB%E7%BB%BC%E8%BF%B0%E4%B8%8E%E8%B0%B7%E6%AD%8C%E5%BC%80%E5%B1%B1%E8%AE%BA%E6%96%87%E7%9A%84%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>#　联邦学习02——读综述与谷歌开山论文的笔记</p>
<p>粗略阅读了谷歌关于联邦学习的两篇开山论文，及一篇2020年的综述，以思维导图方式总结联邦学习概念由来、面临挑战、未来方向如下。</p>
<blockquote>
<p>本文总结自：</p>
<p>Konečný, J., B. McMahan and D. Ramage (2015). "Federated optimization: Distributed optimization beyond the datacenter." arXiv preprint arXiv:1511.03575.</p>
<p>McMahan, B., E. Moore, D. Ramage, S. Hampson and B. A. y Arcas (2017). Communication-efficient learning of deep networks from decentralized data. Artificial Intelligence and Statistics, PMLR.</p>
<p>Li, T., A. K. Sahu, A. Talwalkar and V. Smith (2020). "Federated learning: Challenges, methods, and future directions." IEEE Signal Processing Magazine 37(3): 50-60.</p>
</blockquote>
<span id="more"></span>
<h2 id="google-奠基工作">1. Google 奠基工作</h2>
<p>工作首先介绍谷歌的任务场景，进而分析其特点，最后针对“通信开销”提出<em>FedAvg</em>算法。</p>
<p><strong>联邦学习的任务场景</strong></p>
<p>以谷歌开发的各类app为例，为了提供更好的服务，常需要采集广大用户app的相关信息来训练机器学习模型。传统做法是收集用户信息至中央服务器进行训练，然而用户隐私意识渐强，谷歌不便“直接作恶👀”。</p>
<p>于是，谷歌总结了适用联邦学习而非收集数据训练模型的问题场景：</p>
<ol type="1">
<li>训练来自移动设备的真实数据比训练数据中心通常提供的代理数据具有明显的优势;</li>
<li>此数据是隐私敏感的或较大的（与模型的大小相比），不适合上传到数据中心;</li>
<li>对于监督任务，可以从用户交互中自然推断出数据上的标签（如键盘输入，预测下一个单词）。</li>
</ol>
<p><strong>联邦学习任务特点</strong></p>
<p>从分布式学习出发，全局模型的优化目标可以记为： <span class="math display">\[
\min _{w \in \mathbb{R}^{d}} f(w) \quad \text { where } \quad f(w) \stackrel{\text { def }}{=} \frac{1}{n} \sum_{i=1}^{n} f_{i}(w)
\]</span> 但与传统分布式学习不同的，联邦学习还具备如下任务特点：</p>
<ul>
<li><strong>Non-IID</strong>：由于本地训练数据与具体用户相关，从而任意用户的数据集一般都不能反映全局数据分布，即各个本地数据集非独立同分布；</li>
<li><strong>Unbalanced</strong>：每个用户使用app频率不同，产生的数据量不同；</li>
<li><strong>Massively distributed</strong>：总参与模型训练的用户数远大于每轮参与迭代的用户数；</li>
<li><strong>Limited communication</strong>：不像传统分布式学习，节点间彼此通信开销低，手机设备常常会离线或通信缓慢，如上传带宽常低于1MB/s。</li>
</ul>
<p>根据上述特点，优化目标可改写为： <span class="math display">\[
f(w)=\sum_{k=1}^{K} \frac{n_{k}}{n} F_{k}(w) \quad \text { where } \quad F_{k}(w)=\frac{1}{n_{k}} \sum_{i \in \mathcal{P}_{k}} f_{i}(w)
\]</span> 其中，K为参与用户数，<span class="math inline">\(n_k\)</span>为第k个用户本地训练数据大小，<span class="math inline">\(P_k\)</span>为训练数据的索引，有<span class="math inline">\(n_k=|P_k|\)</span>。</p>
<p><strong>FedAvg算法</strong></p>
<p>联邦学习场景中，通信是制约模型训练效率的一大瓶颈，为此，Google提出<em>FedAvg</em>算法，其核心思想是<strong>本地多轮迭代后再上传梯度，用算力交换通信开销</strong>。</p>
<p><img src="./FL02_fedavg.png" style="zoom:50%;" /></p>
<p>可以发现，Google早期关于联邦学习的工作中，对隐私保护的关注度略少，仅把“数据留在本地”作为隐私保护的方法，而未解决上传参数、梯度时泄露信息等问题。</p>
<h2 id="综述梳理">2. 综述梳理</h2>
<p>联邦学习的相关研究近年来得到进一步发展，下面以导图形式树理"Federated learning: Challenges, methods, and future directions."，罗列联邦学习面临的挑战及概括的解决思路。</p>
<p><img src="./FL_02.png" /></p>
]]></content>
      <categories>
        <category>ML知识总结</category>
      </categories>
      <tags>
        <tag>联邦学习</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL_19_Why Decentralization Matters笔记</title>
    <url>/2022/10/14/MSL-19-WhyDecentralizationMatters%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<blockquote>
<p>Ref:</p>
<p>原始blog 👉 <a href="https://cdixon.org/2018/02/18/why-decentralization-matters">here</a></p>
<p>zhihu笔记 👉 <a href="https://zhuanlan.zhihu.com/p/572235146">here</a></p>
</blockquote>
<span id="more"></span>
<p><img src="./Whydecentralizationmatters.png" /></p>
<blockquote>
<p>Instead of placing our trust in corporations, we can place our trust in community-owned and -operated software, transforming the internet’s governing principle from “don’t be evil” back to <strong>“can’t be evil.”</strong></p>
</blockquote>
<p>仅从此篇blog来看，以去中心化概念为核心的web 3.0 时代仅有淳朴的愿景。期待由于网络基础架构的改变，支持去中心化的网络发展后，人类组织合作方式能随之<strong>演进到community-govern的共治模式</strong>。基于web 3.0里的tokens激励机制，能让参与者劳有所得，从机制上实现<strong>公平的按劳分配</strong>。</p>
<p>从愿景而言让人向往，但其实现方式仍需继续了解。此外，如何顺利接轨现有社会体系，而非技术理论上的空想，也待分析。</p>
<hr />
<p>放下对元宇宙，比特币的成见，了解下Internet可能的未来。</p>
<p>去中心化，朴素自治的未来有何技术基础支持？web 3.0到底在讨论怎样的Internet？便从此刻开始去了解，准备吧。</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL_20_蹒跚科研小记</title>
    <url>/2022/10/15/MSL-20-%E8%B9%92%E8%B7%9A%E7%A7%91%E7%A0%94%E5%B0%8F%E8%AE%B0/</url>
    <content><![CDATA[<blockquote>
<p>Oct.14, 2022，再怎样不满意工作也好，终究是把自己的论文投了出去，为蹒跚的科研立下一个小里程碑。</p>
</blockquote>
<p>无论结果好坏，且将若干总结记录于此。</p>
<span id="more"></span>
<ul>
<li><p><strong>持续输入——哪怕idea定型</strong></p>
<p>把读论文变作习惯，把了解最新工作看作每日读报一样的消遣。</p>
<p>要保证持续的输入，跟进最新的工作。不只是研究选题时的广泛阅读，而是哪怕在idea定型，专心做实验时，依旧需要保持输入。他人的成果或能带来对个人研究方向的新视角，或提供更新的理论佐证等。闭门造车不可取，不知不觉就走入岔路落后他人了。</p></li>
<li><p><strong>活用工具，管理进度</strong></p>
<p>课题做了一年多，从新颖拖到平庸，自我的不断拖延虽是核心原因，但仍有不少工具能助我提振精神，管理进度。</p>
<p>一如这一个月来使用的任务看板<em>Trello</em></p>
<p><img src="./trello.png" /></p>
<p>借助看板，排好工作档期，依照重要性逐次按时攻破任务。每次将任务从“进行中”挪至“完成”时，都可享受自造的成就感。</p></li>
<li><p><strong>任何结论，想多一步</strong></p>
<p><strong>我们写的论文不是说明书，而重在议论</strong>。</p>
<p>论文不是简单罗列做了什么，而是完整地论述为何要做，怎样去做，解决了什么问题。</p>
<p>议论从何来，便是得到任何实验结果，推导出任何结论，都想多一步——为什么。</p></li>
<li><p><strong>推敲与交流并行</strong></p>
<p>科研不必做孤胆英雄，与其他方向友人交流或许有更多灵光乍现的时刻。</p></li>
<li><p><strong>平和心态——过程奋进，悦纳结果</strong></p>
<p>不及预期也罢，但求过程无悔。画上句点后，尊重自己的劳动成果，投身下一段研究中去吧。</p></li>
</ul>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>科研心声</tag>
      </tags>
  </entry>
  <entry>
    <title>GNN_表达能力小结</title>
    <url>/2022/10/29/GNN-%E8%A1%A8%E8%BE%BE%E8%83%BD%E5%8A%9B%E5%B0%8F%E7%BB%93/</url>
    <content><![CDATA[<h1 id="如何理解-gnn-表达能力的粗浅小结">如何理解 GNN 表达能力的粗浅小结</h1>
<blockquote>
<p>参考阅读：</p>
<ol type="1">
<li><a href="https://graph-neural-networks.github.io/gnnbook_Chapter5.html">Chapter5: The Expressive Power of Graph Neural Networks</a></li>
<li><a href="https://www.163.com/dy/article/FG0J275N0511DPVD.html">中科院计算所沈华伟：图神经网络表达能力的回顾和前沿</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/369869891">【ICLR2021论文解读】初探 GNN 表达能力</a></li>
<li><a href="https://openreview.net/forum?id=-qh0M9XWxnv">Analyzing the Expressive Power of Graph Neural Networks in a Spectral Perspective</a></li>
<li><a href="https://www.cnblogs.com/hilbert9221/p/14443747.html">图神经网络的表达能力与置换同变性</a></li>
</ol>
</blockquote>
<span id="more"></span>
<h2 id="神经网络的表达能力">1. 神经网络的表达能力</h2>
<p>机器学习的任务，可以理解为存在一个从特征空间到目标空间的映射<span class="math inline">\(f^*\)</span>，希望能用模型 <span class="math inline">\(f_\theta\)</span> 来近似<span class="math inline">\(f^*\)</span> 。可将 <span class="math inline">\(f_\theta\)</span> 能近似的<strong>映射范围</strong>理解为模型的表达能力。</p>
<p>先前研究已证明了定义任意定义在compact space上的连续函数都可被<strong>MLP</strong>近似。但其实，一方面并不能保证<strong>模型经训练所学的<span class="math inline">\(\hat{f}\)</span> 是想近似的<span class="math inline">\(f^*\)</span></strong>，另一方面过强的表达能力还可能导致overfitting。</p>
<figure>
<img src="./image-20221024121136460.png" alt="image-20221024121136460" /><figcaption aria-hidden="true">image-20221024121136460</figcaption>
</figure>
<p>因此，我们希望建立能够保持强大表达能力的NN，同时对其参数施加约束——归纳偏置反映着对问题的先验认知。</p>
<p>对于CNN/RNN，模型共享参数的机制隐含着translation invariance的假设，对模型的表达力进行限制，但已经能完成对应任务<strong>(limited but sufficient)</strong>。</p>
<figure>
<img src="./image-20221024153918940.png" alt="image-20221024153918940" /><figcaption aria-hidden="true">image-20221024153918940</figcaption>
</figure>
<p>对于GNN，则有如下图所示的permutation invariance限定。</p>
<figure>
<img src="./image-20221024154514368.png" alt="image-20221024154514368" /><figcaption aria-hidden="true">image-20221024154514368</figcaption>
</figure>
<h2 id="gnn表达能力的不同视角">2. GNN表达能力的不同视角</h2>
<ol type="1">
<li><p><strong>区分能力(separating power)/相似性度量</strong>：</p>
<p>经典工作为 <em>How Powerful are Graph Neural Networks？</em>，它使用的<strong>图同构检验graph isomorphism problem</strong>来衡量GNN表达能力。表达力强的GNN能学到分辨性强的graph embedding，让我们<strong>在隐空间中判定两个图是否同构</strong>。</p>
<p>进一步的，还可尝试探索GNN是否能处理更难的 <strong>图编辑距离graph edit distance problem</strong>。</p></li>
<li><p><strong>逼近能力(approximation power)</strong>：</p>
<p>基于<strong>函数逼近</strong>思路，关心神经网络能够<strong>表达的函数的范围有多大</strong>，工作举例有<em>EXPRESSIVE POWER OF INVARIANT AND EQUIVARIANT GRAPH NEURAL NETWORKS</em>。尝试证明GNN可以逼近的定义在图上的映射集合。</p></li>
<li><p><strong>模式识别</strong>：</p>
<p>通过研究GNN是否能识别图中的特定结构，把模式识别能力视作GNN的表达能力，工作举例有<em>Can graph neural networks count substructures?</em>。</p></li>
</ol>
<h2 id="提升表达力方式wl-test视角">3. 提升表达力方式（WL-test视角）</h2>
<p><a href="https://graph-neural-networks.github.io/gnnbook_Chapter5.html">Chapter5: The Expressive Power of Graph Neural Networks</a>的5.4章给出了具体介绍，在此不赘述。</p>
<figure>
<img src="./image-20221024162739401.png" alt="image-20221024162739401" /><figcaption aria-hidden="true">image-20221024162739401</figcaption>
</figure>
<hr />
<p>上述观察，主要都聚焦在graph-level研究GNN表达能力，而缺乏从node-level出发的表达能力讨论。</p>
<p>一说对于node-level任务，GNN已经是universal approximator，不必深入研究。（参考阅读2）</p>
<figure>
<img src="./image-20221024185051603.png" alt="image-20221024185051603" /><figcaption aria-hidden="true">image-20221024185051603</figcaption>
</figure>
<p>但另一方面，一直以来关于GNN架构的研究，除了提升其表达能力外，也在努力提升其拟合能力——使模型能从有限的训练数据中尽可能拟合ground truth映射函数<span class="math inline">\(f^*\)</span>。</p>
<figure>
<img src="./image-20221024185802289.png" alt="image-20221024185802289" /><figcaption aria-hidden="true">image-20221024185802289</figcaption>
</figure>
<p>或许可理论层面分析node-level层面GNN的表达能力、泛化能力（待阅读<a href="https://openreview.net/pdf?id=UH-cmocLJC">How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks. Keyulu Xu et al. ICLR 2021.</a>、<a href="https://openreview.net/pdf?id=rJxbJeHFPS">What Can Neural Networks Reason About? Keyulu X et al. ICLR2020</a>）；</p>
<p>也可能参考上述他人证明，指导设计 theortical proven node-level specific GNN。</p>
]]></content>
      <categories>
        <category>ML知识总结</category>
      </categories>
      <tags>
        <tag>图神经网络</tag>
        <tag>图表示学习</tag>
      </tags>
  </entry>
  <entry>
    <title>联邦学习03_模型异构</title>
    <url>/2022/11/05/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A003-%E6%A8%A1%E5%9E%8B%E5%BC%82%E6%9E%84/</url>
    <content><![CDATA[<h1 id="flheterogeneous-model-小结">FL：Heterogeneous model 小结</h1>
<h2 id="motivations">0. Motivations</h2>
<ol type="1">
<li><strong>System heterogeneity</strong>. Clients have various computation and bandwidth resources, where each participant has capacity and desire to design their own unique model.</li>
<li>Strong server, weak client.</li>
</ol>
<span id="more"></span>
<h2 id="knowledge-distillation-入门">1. Knowledge Distillation 入门</h2>
<blockquote>
<p>Ref: 【经典简读】知识蒸馏(Knowledge Distillation) 经典之作 - 潘小小的文章 - 知乎 https://zhuanlan.zhihu.com/p/102038521</p>
</blockquote>
<figure>
<img src="./image-20221104103056522.png" alt="image-20221104103056522" /><figcaption aria-hidden="true">image-20221104103056522</figcaption>
</figure>
<p>知识蒸馏使用的是Teacher—Student模型，其中teacher是“知识”的输出者，student是“知识”的接受者。知识蒸馏的过程分为2个阶段:</p>
<ol type="1">
<li>原始模型训练: 训练"Teacher模型", 简称为Net-T，它的特点是模型相对复杂。对于输入X, 其都能输出Y，其中Y经过softmax的映射，输出值对应相应类别的概率值。</li>
<li>精简模型训练: 训练"Student模型", 简称为Net-S，它是参数量较小、模型结构相对简单的单模型。同样的，对于输入X，其都能输出Y，Y经过softmax映射后同样能输出对应相应类别的概率值。</li>
</ol>
<p><strong>Soft Labels(Soft Targets)</strong></p>
<figure>
<img src="./image-20221104103157056.png" alt="image-20221104103157056" /><figcaption aria-hidden="true">image-20221104103157056</figcaption>
</figure>
<p>最后，Net-S的目标函数有： <span class="math display">\[
L=\alpha L_{\text {soft }}+\beta L_{\text {hard }}
\]</span></p>
<h2 id="hetemodel-fl-with-knowledge-distillation">2. HeteModel-FL with knowledge distillation</h2>
<h3 id="fedhe">2.1 FedHe</h3>
<blockquote>
<p>FedHe: Heterogeneous Models and Communication-Efficient Federated Learning</p>
<p>2021 17th International Conference on Mobility, Sensing and Networking (MSN) 2021</p>
</blockquote>
<figure>
<img src="./image-20221104104226887.png" alt="image-20221104104226887" /><figcaption aria-hidden="true">image-20221104104226887</figcaption>
</figure>
<p>Server不承担teacher模型训练，只负责聚合各个client上传的各类样本的logits，并将聚合的结果发还。</p>
<p>Clients端把 aggregated logits 视作 soft label 进行学习。</p>
<h3 id="fedmd">2.2 FedMD</h3>
<blockquote>
<p>Fedmd: Heterogenous federated learning via model distillation</p>
<p>arXiv preprint 2019</p>
<p>Code: https://github.com/diogenes0319/FedMD_clean</p>
</blockquote>
<figure>
<img src="./image-20221104110228287.png" alt="image-20221104110228287" /><figcaption aria-hidden="true">image-20221104110228287</figcaption>
</figure>
<p>Clients提供一部分数据来构建public dataset。</p>
<p>各 client 求 public dataset 对应的 logits。Server 负责聚合各个 client 的 logits 并求平均。发还的 avg(logits) 用以蒸馏 client 端的 model。</p>
<p>由于各 client 是用private dataset + public dataset训练模型，故对public dataset算出的logits中隐性地包含client private data distribution的信息，意味着使用蒸馏可以在不侵犯隐私的情况下获得其他的client的帮助。</p>
<h3 id="fml">2.3 FML</h3>
<blockquote>
<p>Federated mutual learning</p>
<p>arXiv preprint 2020</p>
</blockquote>
<figure>
<img src="./image-20221104110855842.png" alt="image-20221104110855842" /><figcaption aria-hidden="true">image-20221104110855842</figcaption>
</figure>
<p>设置 Global model 及 Personalized model。 Global model 架构相同，按照一般FL方式进行训练，作为 teacher model使用。</p>
<h3 id="fedh2l">2.4 FedH2L</h3>
<blockquote>
<p>FedH2L: Federated learning with model and statistical heterogeneity</p>
<p>arXiv preprint 2021</p>
</blockquote>
<p>需要共享部分数据作为seed data（文中未讨论seed data的选择和对模型影响）。</p>
<p>直接将知识蒸馏迁移到去中心化FL场景。client间互为teacher-student，进行知识蒸馏。</p>
<h3 id="对比">2.5 对比</h3>
<table>
<thead>
<tr class="header">
<th>Model</th>
<th>Architecture</th>
<th>Share</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>FedHe</td>
<td>CS</td>
<td>Logits with class</td>
</tr>
<tr class="even">
<td>FedMD</td>
<td>CS</td>
<td>Public dataset</td>
</tr>
<tr class="odd">
<td>FML</td>
<td>CS</td>
<td>Global model weights</td>
</tr>
<tr class="even">
<td>FedH2L</td>
<td>P2P</td>
<td>Seed data</td>
</tr>
</tbody>
</table>
<p>如何兼顾隐私与构建强teacher模型，仍是待讨论的问题。</p>
<h2 id="others">3. Others</h2>
<p><strong>Hyper networks</strong></p>
<p>通过Hyper networks学习personalized model weights，模型自由度较知识蒸馏低。</p>
<figure>
<img src="./image-20221104111951949.png" alt="image-20221104111951949" /><figcaption aria-hidden="true">image-20221104111951949</figcaption>
</figure>
]]></content>
      <categories>
        <category>ML知识总结</category>
      </categories>
      <tags>
        <tag>联邦学习</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL_21_LifeGoesOn</title>
    <url>/2022/12/31/MSL-21-LifeGoesOn/</url>
    <content><![CDATA[<p>Life Must Goes On...</p>
<p>2022已过去，依旧青春热血莽撞无虑，但也依旧幼稚短视懒惰。</p>
<p>回首2022的日子，并不能骄傲地于此尽数，只得怯弱地将愿景寄托于2023年。</p>
<p>或许依旧该张狂地吹下种种牛逼，然而23年，24岁的我，该将吹得牛通通实现才是。</p>
<blockquote>
<p>有悲总有喜 人不要自危</p>
<p>随时代走用眼泪伴这双手</p>
<p>再辛苦也好 亦不要淡忘</p>
<p>前景多好看</p>
<p>不要淡忘</p>
</blockquote>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL_22_经得起变化</title>
    <url>/2023/01/16/MSL-22-%E7%BB%8F%E5%BE%97%E8%B5%B7%E5%8F%98%E5%8C%96/</url>
    <content><![CDATA[<p>不再是光谷，没去到红馆。人来人往，终于是只身一人来顺德。</p>
<p>Alan Po，来日之音。</p>
<span id="more"></span>
<p>18排，1座——一楼靠后的角落，右手边是过道，左边坐着结伴而来的三位陌生人。早早到场的结果，便是开show前，些许无聊，些许尴尬无助，无人可倾谈、分享。</p>
<p>直到，灯光熄灭，舞台闪烁时。演唱会的意义，或许在于音乐奏响、歌手演唱时，观众间的陌生恍然间弥散，齐心随音乐摇摆、合唱。</p>
<p><img src="./摇摆.jpg" /></p>
<p>茫茫众生，大多都在寻求团体的温暖。演唱会两小时的时光，厅内的各位，仿似家人。为阿纶欢呼，为求婚的情侣祝福，为那首首单循过的歌曲尖叫。</p>
<p><img src="./昨天.jpg" /></p>
<p><img src="./合照.jpg" /></p>
<p>直到曲终人静时，又重回一个个陌生的个体。轻哼着encore的曲目，收拾行囊，步出会场。</p>
<p>不必否定孤独。混于人群时纷扰太多，忙于应付周遭；困于人群自我太少，疏于扪心自问。</p>
<p>三年疫情，太多人事消散变迁。我也陷入失语症：迟滞，不善表达，亦恐于落笔。关于疫情的管控已解绑，且将它视作一界碑，分隔前些日子茫然的自我。</p>
<p>而今，重温独处，重习专注，爱自我，爱生活吧。人，要经得起变化才是。</p>
<p>「望四周的身影如幻覺</p>
<p>舊照片的溫馨情已不再</p>
<p>縱使它不可變改</p>
<p>人總要自愛」</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL-23-且行一步</title>
    <url>/2023/02/12/MSL-23-%E4%B8%94%E8%A1%8C%E4%B8%80%E6%AD%A5/</url>
    <content><![CDATA[<p>终究还是迈出了那一步。</p>
<span id="more"></span>
<h1 id="再见的二义性">1. 再见的二义性</h1>
<p>再见：</p>
<p>1．再一次见面。 2．临别套语，用于分别时。表示希望以后再见面。</p>
<p>谭校长的《讲不出再见》一直未能欣赏，直到自己逢了那境遇，才知晓其词曲意。</p>
<p>情路旅途不止一段，然而此回，终于是轮到我，由我第一次来开口，道声再见。</p>
<p>原来主动开口，尽管理智层面已然分分秒秒间分析过千千万万回长远故事的不可为继，还是那般沉重且沉痛。会忍不住想象那头的神情——虽然被哥们骂自作多情；会恍惚质问自己；会失眠。</p>
<p>但仍是决定迈步，重整自我，先修身吧。</p>
<p>再见，不愿其为套话，由衷地期盼着未来仍能交会，或是作为并行的朋友。</p>
<h1 id="方向与前路">2. 方向与前路</h1>
<p>与共同成长的友人间距离愈发遥远。个人的成长是何时开始停滞的？</p>
<p>友人说，要做有价值的工作，让自己收获成就感与存在感。</p>
<p>友人说，对任何行事前不经思索，不明自己举止动机的人感到恶心。</p>
<p>友人说，构建自洽的生活方式……</p>
<p>我呢？些许混沌。谈恋爱，似乎也只是掌握不少讨欢心的tricks罢了。</p>
<p>怎样能拾回自信，怎样寻到方向与前路？</p>
<h1 id="启航">3. 启航</h1>
<p>此节且做为memo，等待不断补充吧。</p>
<p>愿景：</p>
<ul>
<li>姑且将人生目标，定为追求高质量且丰富的体验吧；</li>
</ul>
<p>愿望：</p>
<ul>
<li></li>
</ul>
<p>习惯：</p>
<ul>
<li>自省前置，决策前自问是否符合自我愿景，对其是否有利；</li>
</ul>
<p>技巧：</p>
<ul>
<li></li>
</ul>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>Torch-CopyModel的坑</title>
    <url>/2023/02/16/Torch-CopyModel%E7%9A%84%E5%9D%91/</url>
    <content><![CDATA[<blockquote>
<p>Main reference: <a href="https://androidkt.com/copy-pytorch-model-using-deepcopy-and-state_dict/">Copy PyTorch Model using deepcopy() and state_dict()</a></p>
</blockquote>
<p>近日验证idea，踩中Pytorch复制模型的大坑，遂记录如下。</p>
<span id="more"></span>
<h1 id="概况">1. 概况</h1>
<p><strong>问题现象：</strong>进行联邦学习+GNN知识蒸馏的idea验证，发现在进行FedAvg后，模型loss、acc等不再变化。</p>
<figure>
<img src="./image-20230216104047624.png" alt="image-20230216104047624" /><figcaption aria-hidden="true">image-20230216104047624</figcaption>
</figure>
<p><strong>原因概述</strong>：复制模型时未对optimizer做重新初始化。</p>
<figure>
<img src="./image-20230216103949066.png" alt="image-20230216103949066" /><figcaption aria-hidden="true">image-20230216103949066</figcaption>
</figure>
<h1 id="问题发现与探索简述">2. 问题发现与探索（简述）</h1>
<ol type="1">
<li>FedAvg+KD时，loss、acc未如预期一般成锯齿形下降，而是在第一次聚合后便不再变化。</li>
<li>检查模型架构是否异常；</li>
<li>聚合算法实现检查。但FedAvg + GNN/MLP 正常收敛（这就是坑点，代码实现的单个分析都没有问题）；</li>
<li>检查模型是否设置异常，未开启反向传播。但<code>print(model.weight.grad())</code>不为0，<code>require_grad==True</code>设置没有问题，但每轮训练，<code>weights, grad</code>都不变（接近发现原因了！）；</li>
<li>反思是否是梯度消失。但打印的梯度及其变化情况，与梯度消失现象不一致；</li>
<li>设置client=1，一个模型不进行<code>deepcopy()</code>，只进行知识蒸馏，可以正常训练。另一个模型进行知识蒸馏，并且每一个epoch将参数复制到相同架构的模型，再通过<code>deepcopy</code>拷贝回来，异常！</li>
</ol>
<h1 id="bug所在">3. BUG所在</h1>
<ol type="1">
<li><p>FedAvg参考他人实现，server模型下发回客户端时使用的是<code>deepcopy</code>：</p>
<figure>
<img src="./image-20230216110124249.png" alt="image-20230216110124249" /><figcaption aria-hidden="true">image-20230216110124249</figcaption>
</figure></li>
<li><p>知识蒸馏参考他人实现，训练时<code>optimizer</code>作为参数传入：</p>
<figure>
<img src="./image-20230216110251502.png" alt="image-20230216110251502" /><figcaption aria-hidden="true">image-20230216110251502</figcaption>
</figure>
<p>（而我惯常的<code>train()</code>,optimizer对象是在函数内创建，即每次调用<code>train()</code>时都会重新初始化optimizer）</p></li>
</ol>
<p>上述二者，每个都能完成原始代码的既定任务，但两者结合使用时，就会发生optimizer无法更新模型参数的问题！</p>
<h1 id="pytorch-模型复制">4. Pytorch 模型复制</h1>
<p>见<a href="https://androidkt.com/copy-pytorch-model-using-deepcopy-and-state_dict/">Copy PyTorch Model using deepcopy() and state_dict()</a></p>
<ul>
<li><code>copy.deepcopy()</code>：完整地<strong>深拷贝</strong>整个模型，创建<strong>全新的对象</strong>。该对象递归地复制原模型的内部对象的值。训练新模型需要对原optimizer<strong>重新初始化</strong>；</li>
<li><code>new_model.load_state_dict(model.state_dict())</code>，首先用户需要自己创建<code>new_model</code>，新模型的架构应与被复制模型的架构一致。<code>load_state_dict</code> only copies parameters and buffers。实践发现不需对原optimizer重新初始化。</li>
</ul>
]]></content>
      <categories>
        <category>工具人</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL-24-自驱新时代(Memo)</title>
    <url>/2023/03/07/MSL-24-%E8%87%AA%E9%A9%B1%E6%96%B0%E6%97%B6%E4%BB%A3-Memo/</url>
    <content><![CDATA[<p><strong>自驱、持续学习重要性愈发凸显</strong>。 <span id="more"></span></p>
<p>ChatGPT Api 可供大众调用了，各式产品、生产力工具开始涌现。</p>
<p>摸鱼刷着知乎，看到：</p>
<blockquote>
<p>Bilibili x OpenAI x Notion x Python：分享我的长视频自动化摘要笔记完整工作流（万字长文，代码分享，点赞收藏） - 段小草的文章 - 知乎 https://zhuanlan.zhihu.com/p/610250035</p>
</blockquote>
<p>已经有人基于ChatGPT Api，定制出视频自动化摘要笔记的程序。意味着过往截图、摘抄、个人概括等繁琐流程，都被压缩，个人时间能更多用于吸收视频传递的信息。</p>
<ul>
<li><strong>工具的进化，拉大了人与人间可达的差距</strong></li>
</ul>
<p>好比两人比赛远行，过往只能徒步，自驱者每日多行二三小时不过领先几里路；而今两人都被赋予汽车，自驱者迅速学会开车并远行，不消几日就将彻底领先无踪。</p>
<ul>
<li><strong>自驱，主动学习</strong></li>
</ul>
<p>切要摆脱应试填鸭思维，被动学习。当下时代，更需要找到自己生活的主线，主动探索，利用新生产力工具提升自我。</p>
<ul>
<li><strong>自驱亦分层级</strong></li>
</ul>
<p>高级的，知晓个人需求，定制工具强壮自身；中级的，拥抱新工具，活学活用；低级的，则仍满足于低效的旧模式，暗自满足。</p>
<hr />
<p>有了以ChatGPT代表的新LLM模型，仓鼠症更需根治了。徒劳囤积资料无效，逻辑与分辨力才是关键——海量信息可依靠AI负责提取，人则负责分辨并指引AI优化提取结果，进而将信息化作知识乃至更高维内容。</p>
<figure>
<img src="./image-20230307013217319-16781239438421.png" alt="image-20230307013217319" /><figcaption aria-hidden="true">image-20230307013217319</figcaption>
</figure>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode-代码随想录总结</title>
    <url>/2023/03/07/Leetcode-%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<blockquote>
<p>内容整理自<a href="https://www.programmercarl.com/">代码随想录</a></p>
</blockquote>
<span id="more"></span>
<h2 id="dp-动态规划">1. DP 动态规划</h2>
<h3 id="思路框架">1.1 思路框架</h3>
<p>动规五部曲分别为：</p>
<ol type="1">
<li><p><strong>确定dp数组（dp table）以及下标的含义</strong></p>
<p>一般来说，dp数组元素即为题目所求的局部最优结果。分析问题规模确定数组维数；</p></li>
<li><p><strong>确定递推公式</strong></p>
<p>注意紧扣数组定义；</p></li>
<li><p><strong>dp数组如何初始化</strong></p></li>
<li><p><strong>确定遍历顺序</strong></p>
<p>根据递推公式所需的上下文，确定方向。</p>
<p>如有 <code>dp[i][j] = dp[i + 1][j - 1] + 1</code>，则遍历顺序为 i由大到小，j由小到大；</p></li>
<li><p><strong>举例推导dp数组</strong></p>
<p>辅助Debug检验代码实现/递推公式缺漏。</p></li>
</ol>
<h3 id="背包问题">1.2 背包问题</h3>
<ul>
<li>思路</li>
</ul>
<p>题目不会直给地点明是背包问题，需要分析物品和背包对应题目中的什么元素。有时元素<strong>同时是物品和背包</strong>。</p>
<ul>
<li>01背包（每种物品仅有1件）</li>
</ul>
<p>——滚动数组实现</p>
<p>dp[j]表示：容量为j的背包，所背的物品价值可以最大为dp[j]。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; weight.<span class="built_in">size</span>(); i++) &#123; <span class="comment">// 遍历物品</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = bagWeight; j &gt;= weight[i]; j--) &#123; <span class="comment">// 遍历背包容量</span></span><br><span class="line">        dp[j] = <span class="built_in">max</span>(dp[j], dp[j - weight[i]] + value[i]);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>倒序遍历</strong>是为了保证物品i只被放入一次！</p>
<ul>
<li>完全背包（每种物品有无限件）</li>
</ul>
<p>完全背包的物品是可以添加多次的，所以要<strong>从小到大去遍历</strong>，即：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 先遍历物品，再遍历背包</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; weight.<span class="built_in">size</span>(); i++) &#123; <span class="comment">// 遍历物品</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = weight[i]; j &lt;= bagWeight ; j++) &#123; <span class="comment">// 遍历背包容量</span></span><br><span class="line">        dp[j] = <span class="built_in">max</span>(dp[j], dp[j - weight[i]] + value[i]);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但是仅仅是纯完全背包的遍历顺序是这样的，题目稍有变化，两个for循环的先后顺序就不一样了。</p>
<p><strong>如果求组合数就是外层for循环遍历物品，内层for遍历背包</strong>。</p>
<p><strong>如果求排列数就是外层for遍历背包，内层for循环遍历物品</strong>。</p>
<h3 id="其他系列">1.3 其他系列</h3>
<ul>
<li><a href="https://www.programmercarl.com/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93%E7%AF%87.html#%E8%82%A1%E7%A5%A8%E7%B3%BB%E5%88%97">股票系列</a></li>
<li><a href="https://www.programmercarl.com/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93%E7%AF%87.html#%E5%AD%90%E5%BA%8F%E5%88%97%E7%B3%BB%E5%88%97">子序列 Subsequence / 子数组 Subarray</a></li>
</ul>
<h2 id="回溯法">2. 回溯法</h2>
<h3 id="模板">2.1 模板</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void backtracking(参数) &#123;</span><br><span class="line">    if (终止条件) &#123;</span><br><span class="line">        存放结果;</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    for (选择：本层集合中元素（树中节点孩子的数量就是集合的大小）) &#123;</span><br><span class="line">        处理节点;</span><br><span class="line">        backtracking(路径，选择列表); // 递归</span><br><span class="line">        回溯，撤销处理结果</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="要点">2.2 要点</h3>
<ul>
<li><p>组合问题，<strong>收集叶子节点的结果</strong></p>
<ul>
<li><p><strong>对于组合问题，什么时候需要startIndex呢？</strong></p>
<p>如果是一个集合来求组合的话，就需要startIndex，例如：<a href="https://programmercarl.com/0077.组合.html">回溯算法：求组合问题</a>，<a href="https://programmercarl.com/0216.组合总和III.html">回溯算法：求组合总和</a>。</p>
<p>如果是多个集合取组合，各个集合之间相互不影响，那么就不用startIndex，例如：<a href="https://programmercarl.com/0017.电话号码的字母组合.html">回溯算法：电话号码的字母组合</a></p></li>
</ul></li>
<li><p>剪枝</p></li>
<li><p>去重</p>
<ul>
<li><figure>
<img src="https://code-thinking-1253855093.file.myqcloud.com/pics/2020111820220675.png" alt="40.组合总和II1" /><figcaption aria-hidden="true">40.组合总和II1</figcaption>
</figure></li>
<li><p><strong>“树枝去重”和“树层去重”</strong>。</p>
<p>都知道组合问题可以抽象为树形结构，那么“使用过”在这个树形结构上是有两个维度的，一个维度是同一树枝上“使用过”，一个维度是同一树层上“使用过”。</p></li>
<li><p>例子：</p>
<ul>
<li>排序后比较上一个（树层）https://leetcode.com/problems/non-decreasing-subsequences/</li>
<li>用集合去重（树层） https://leetcode.com/problems/non-decreasing-subsequences/</li>
</ul></li>
</ul></li>
<li><p>子集问题，<strong>收集所有节点的结果</strong>（遍历整棵树）</p></li>
<li><p>排列问题</p></li>
</ul>
]]></content>
      <categories>
        <category>工具人</category>
      </categories>
      <tags>
        <tag>Leetcode</tag>
        <tag>找工</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL-25-又是一年找实习</title>
    <url>/2023/05/08/MSL-25-%E5%8F%88%E6%98%AF%E4%B8%80%E5%B9%B4%E6%89%BE%E5%AE%9E%E4%B9%A0/</url>
    <content><![CDATA[<blockquote>
<p>又到了毕业的前一年。拖拖拉拉，春节假期仍在摆烂，拒绝直面已是要找暑期实习的事实。</p>
</blockquote>
<span id="more"></span>
<p>虽然接到阿里的意向书，但未真正入职实习前，心仍悬着。暂且凌乱的随记下这3个月的找实习历程吧。</p>
<h2 id="个人情况">0. 个人情况</h2>
<ul>
<li>方向：图表示学习，基本都在玩GNN；</li>
<li>科研成果：只有1篇survey被接收，余下1篇工作在投，1篇还在肝实验&amp;改论文；</li>
<li>竞赛：打了个没进复赛的王者荣耀强化学习比赛；</li>
<li>码力：Python调包调参侠，无工程经验，不熟悉其他语言；</li>
<li>Leetcode：正式找实习前，荒废许久；</li>
<li>其他：接触过强化学习、联邦学习、推荐系统。</li>
</ul>
<h2 id="海投">1. 海投</h2>
<p>如上所述，个人技能点属实匮乏，加之时间紧迫。故决定海投，一来增大可选对象（不配挑食），二来以战养战。</p>
<p>二月底开始海投，总计:</p>
<ul>
<li>投递： 30 家</li>
<li>笔试：15家</li>
<li>面试：
<ul>
<li>携程（5月才发，未面）</li>
<li>快手（日常实习，止步二面）</li>
<li>招行卡中心（方向不合，止步一面）</li>
<li><strong>美团</strong>（一面跪，被捞起后两轮技术面、无hr面，拿offer）</li>
<li><strong>PDD</strong>（一面跪，被捞起后两轮技术面、hr面）</li>
<li>腾讯（一面跪）</li>
<li>OPPO（二面跪）</li>
<li><strong>阿里</strong>（一轮电话技术面+二轮hr/技术综合面+三轮纯手撕代码面，拿意向书）</li>
</ul></li>
</ul>
<h2 id="备战内容">2. 备战内容</h2>
<ol type="1">
<li><p><strong>Leetcode</strong></p>
<p>二月开始，随着《<a href="https://www.programmercarl.com/">代码随想录</a>》刷题，约莫一两周一章的节奏，二月底过了一遍。</p>
<p>刷题时的自我要求，则是easy必须会独立做，medium至少思考30分钟，随后可考虑参考题解再复现，hard则不强制要求。</p>
<p>刷完一轮后，medium类型的题基本不怵——未必能现时内做出，但建立了挑战的自信。</p>
<p><img src="./image-20230508112143038.png" alt="image-20230508112143038" style="zoom:50%;" /></p>
<p>三月中下旬笔试渐多，基本靠笔试的题保持手感（日均一场笔试后属实无心再刷新题）。</p>
<p>四月渐渐开始有面试邀约，每天有空时做一道https://codetop.cc/home里的常见手撕代码题保持手感。</p></li>
<li><p><strong>八股</strong></p>
<p>二月底开始简单回顾了下西瓜书监督学习的章节，EasyRL的1-5章，GBDT官网的tutorial。</p>
<p>到面试时发现基本围绕项目展开，提问相关技术，遂未继续深入准备ML的八股。</p></li>
<li><p><strong>项目</strong></p>
<p>未接到面试前：回顾科研项目细节、motivation、related works；</p>
<p>场场面试后：根据被面试官问倒的点，补齐相关知识。</p></li>
<li><p><strong>其他</strong></p>
<ul>
<li>推荐系统：主要投递推荐算法岗。故翻看了《深度学习推荐系统》，对领域发展历程有所了解，能和面试官在大方向上吹水的水平；</li>
<li><strong>技术敏感性</strong>：跟进技术的更迭——AI领域的要通吃。非自己方向未必能了然其原理，但至少要关注其应用和商业化潜力。（阿里综合面时的场景题之一便是“ChatGPT如何应用于淘宝”）</li>
</ul></li>
</ol>
<h2 id="心态">3. 心态</h2>
<p>从3月开始海投简历时便饱受拷打。现时回顾，却难重新浸入那时的绝望感，只剩细碎的片段记忆。</p>
<ul>
<li>投出简历后半个月不曾有笔试邀约的时刻；</li>
<li>同学已面完3轮，而我未曾熬到一个面试邮件的时刻；</li>
<li>与恋人分手，收到邮件，发现是论文拒信的时刻；</li>
<li>初次手撕代码，哪怕面试官提醒，仍大脑空空，自认无法解出，彻底宕机的时刻；</li>
<li>……</li>
</ul>
<p>总要熬过，总会熬过去。</p>
<p>到最后，面试时，能和面试官谈笑风生了，手撕代码也算冷静下来，能尽力撕了。</p>
<hr />
<p>堪堪幸运地找到实习，但这仅仅是起点。草包一只，肚里几分墨水内心清楚，愿不再倦怠拖延。</p>
<hr />
<blockquote>
<p>好好記住昨天在昨天就已跑掉</p>
<p>不相信命數和定數從沒需要</p>
<p>轉身抱緊當下 眼淚抹掉煩擾</p>
<p>風急雨大你都能撐起渡過低潮</p>
<p>漆黑裡就發亮燃燒</p>
<p>變幻於當前每下心跳 至最重要</p>
</blockquote>
<p>《All we have is now》真是正，帮手撑过多少夜晚。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL-26-写于实习离职前夜</title>
    <url>/2023/09/26/MSL-26-%E5%86%99%E4%BA%8E%E5%AE%9E%E4%B9%A0%E7%A6%BB%E8%81%8C%E5%89%8D%E5%A4%9C/</url>
    <content><![CDATA[<blockquote>
<p>"在拒绝遵循让人心安理得的常规同时，这个世界也变得更加丰富。"——《碰巧的杰作》</p>
<p>入职后的第94天夜，随记这3月的感触。</p>
</blockquote>
<p>作为回顾，无非工作、生活、展望三大部分。</p>
<span id="more"></span>
<h1 id="工作">1. 工作</h1>
<p>答辩时讲了太多正确但不真挚的话。在自己博客里，还是该更坦诚地直面自己的软肋。</p>
<h2 id="老调重弹的奥义">1.1 老调重弹的奥义</h2>
<p>道理都懂，仍是没能好好执行。重述于此，该吃一堑长一智了。</p>
<ul>
<li><strong>敏捷开发，迅速构建baseline</strong></li>
</ul>
<p>至转正答辩当日，共入职72天。前21天熟悉环境，剩51天进行实习项目推进。又耗费近30天，才第一次得到线上实验结果。即耗费过三分之二的时间，才迈开从零到一的第一步。</p>
<p>如何做到敏捷开发，快速迭代？此番实习有三点经验。</p>
<ol type="1">
<li>学会倒排规划。按照最终的DDL倒着安排任务节点，明确每个节点需要取得的阶段性成果。比起顺序地制定规划，倒排提供了更强的紧迫感；</li>
<li>有效技术选型。既要考虑长远开发的可行性、扩展性，也要考虑当下实践的难度曲线；</li>
<li>多路并进。在Pytorch开发停滞且有Tensorflow方案可简单配置尝试时，不妨分点神尝试下Tensorflow的方案。</li>
</ol>
<ul>
<li><strong>数据支撑结论</strong></li>
</ul>
<p>道理深谙于心，但总是恐惧——不敢直面糟糕的评估结果。然而研究数据才能发现算法的优劣。一昧逃避，凭借粗浅的理论理解及搭积木的故事来幻想最终优秀的结果，不过是试图纸糊摩天大楼罢了。</p>
<ul>
<li><strong>知其然知其所以然</strong></li>
</ul>
<p>切莫只记着“敏捷”两字，就一路<code>import</code>下去。<strong>“敏捷”的实质是分治</strong>。</p>
<p>将任务细分后，执行的每一步仍要不断自问——我做这步的目的是什么？我选择的方法是什么？它和我的目标一致吗？</p>
<p>此番实习，也曾盲目地想着迅速跑通模型就好。跑通后评估指标不佳，召回结果一塌糊涂？暴力地选择调整LR重新训练。浪费几日算力仍未见成效。</p>
<p>冷静之后，反思GNN聚合的本质，只简单地调整了重要特征的维度，召回结果得到立竿见影的提升。</p>
<h2 id="技能广度">1.2 技能广度</h2>
<p>各式新算法总是层出不穷，不必焦虑，请敞开怀抱，扩展自身的技能广度。</p>
<ul>
<li>在校的研究方向不该是个人技能的全集，而应该是优势子集。</li>
</ul>
<p>做算法工程的，遇到问题不能因为超出了个人的研究方向就摆手拒绝。工作摆在那，总是要迎难而上的。而研究生阶段投入了两三年光阴的研究方向，也不是直接抛掷脑后，而是作为人无我有的优势。</p>
<ul>
<li>会选工具，会用工具。</li>
</ul>
<p>做算法工程的，核心技能之一是拆解需求并抽象为算法问题，再选择合适的工具求解。不必刻意追求时髦算法，而是找到在“算力、人力”等诸多约束条件下的最优工具。</p>
<h2 id="做个情绪稳定的人">1.3 做个情绪稳定的人</h2>
<ul>
<li>白日当理智而清醒；</li>
<li>入夜情绪流动无妨，但切莫自陷。</li>
</ul>
<p>独居独处，周遭安静时不免一人胡思乱想。刷到个故事分享，随机到一首苦情歌，就开始无尽牵扯自身的忧郁情怀。事后按点罗列分析，又不过是虚无缥缈的情绪薄雾。本就没经啥大风浪，哪来那么多苦楚要倾诉。</p>
<p>需要做个能共情，心思细腻的人——作为技能，关注、宽慰他人。作用于自身时，当是结合理智去解构自身的波动，而非任由情绪下坠。</p>
<p>明镜止水，波澜不惊。愿自勉。</p>
<hr />
<p>(以下内容，已是离职后若干夜晚所写。)</p>
<h1 id="work-life-balance">2. Work Life Balance</h1>
<p>Work life imbalanced! Not work for live! Work For LIFE!</p>
<h2 id="欲">2.1 欲</h2>
<p>三个月来，健身房常去，酒精每周不落。</p>
<ul>
<li>健身</li>
</ul>
<p>期望着练出雕塑般棱角分明的雄伟体魄，但真正健身的动力，源自两点。一来，排解工作烦忧。专注发力、出汗时，业务与bug都抛掷脑后了。再者，抵抗宿舍的孤寂。只想在公司里再呆久些，拖延着不回那似黑洞的宿舍。</p>
<ul>
<li>小酌</li>
</ul>
<p>未曾醉过。或独酌或与友伴吹水。</p>
<p>最初只是刷着视频对鸡尾酒来了兴趣，加之工资带来点闲钱，便想将经典鸡尾酒一一试遍。</p>
<p>再后来，便是没事借着酒精独处，恍惚间度过个把时辰；又或借着酒兴打开话匣子，与挚友把酒言欢。</p>
<p>如去码头整些薯条般尽兴，简单纯粹。</p>
<h2 id="求">2.2 求</h2>
<p>然而欲望得以消遣后，总会卧床就寝的一刻。将睡未睡时，总会被些终极的问题绑架——为何而活？何为生活？问题当然是无解的，或者说，答案是动态变化的。</p>
<p>但与其干坐空想，<strong>走在探求问题解答的路上会是更惬意的状态。</strong></p>
<p>谈恋爱是一种取巧的方式。将生活的重心倾斜他人身上，减少思考抽象问题的时间。但这只是回避，问题总还会在某刻折返，或是恋人的逼问，或是失眠的夜晚。</p>
<p>当下的思路，仍是去向生活本身寻答案——<strong>对生活怀揣好奇</strong>。从《碰巧的杰作》中摘录了一句话：在拒绝遵循让人心安理得的常规同时，这个世界也变得更加丰富。</p>
<p>解法也因而变得清晰：</p>
<ul>
<li>对内，修身。阅读、思考，看过百千人总结的观念后，总有认可的几项，甚至能凝练升华出个人的信条；</li>
<li>对外，探索。
<ul>
<li>去亲近自然。知行合一不假，哪怕只是去亲自攀爬个小土包，回首俯视来路，也能更真切感知几分何谓“而今迈步从头越”；</li>
<li>去走进人群。哪怕“人群多么像羊群”，哪怕想做只“black sheep”，仍不会摆脱是羊这一物种的本质属性。谦虚些，外向些，观察、交流他人的生活。</li>
<li>去学点玩意。投资也好调酒木工也罢，在学习新技能过程中享受愉快的内啡肽。这可比消费所唤起的多巴胺长久得多。</li>
</ul></li>
</ul>
<h1 id="杭州">3. 杭州</h1>
<p>如果让我来评判一个城市，最核心无非两个坐标轴：“有趣”和“美食”。</p>
<p>若纵轴为有趣，横轴为美食的话，会得到如下四个象限：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>难吃</th>
<th>好吃</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>有趣</td>
<td>暂住</td>
<td>定居</td>
</tr>
<tr class="even">
<td>无趣</td>
<td>逃离</td>
<td>旅游</td>
</tr>
</tbody>
</table>
<p>无疑，广州属于可定居的象限，武汉则应当逃离。杭州，则属于可暂住的城市。</p>
<p>先谈饮食。</p>
<p>杭州被大伙戏称“美食荒漠”，其实严谨而言，是“市井美食的荒漠”。拌川儿不过尔尔，一碗面却也二三十往上走。逗留三个月，也没寻到啥留下印象的小吃。然而把预算往上抬，作为一个国际化的都市，总归是能觅得好吃的——就是荷包要疼得嗷嗷叫了。</p>
<p>再谈有趣。</p>
<p>自然方面，拥有西湖的杭州风光无限，市内山丘还不少。散步、徒步，都有去处。人文方面，吸引我的是各式展览，不一而足。以及，真正有趣的，是有位能说上话的兄弟在这吧。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL-27-去看尘大师了</title>
    <url>/2023/12/06/MSL-27-%E5%8E%BB%E7%9C%8B%E5%B0%98%E5%A4%A7%E5%B8%88%E4%BA%86/</url>
    <content><![CDATA[<p>人生清单项✔ 盼望下次能在红馆重逢。 <span id="more"></span></p>
<h1 id="飞往成都前">1. 飞往成都前</h1>
<blockquote>
<p>“如果我听歌可眼红……”</p>
</blockquote>
<p>临行了，却没那么激动，或许踌躇更多些。期盼过久乃至到想放弃的事情，要成真的那刻，总还是觉得虚幻。</p>
<p>现场多半会听歌听到眼红吧。</p>
<p>说来也是矫情，但每首歌总能忆起为之着迷的时刻，以及那时交织的故事。</p>
<p>从初中时睡前iPod Shuffle入门，到此刻张张专辑遍历，还入手了实体的新专——Eason的歌陪我度过漫长岁月。</p>
<h1 id="拥抱这分钟">2. 拥抱这分钟</h1>
<p>极致的舞美，极致的演绎。拥抱这分钟，享受这分钟。</p>
<p>虽然野人很多，扰乱心弦。但仍庆幸首首歌疗愈灵魂，赐予勇气。</p>
<h1 id="人生马拉松">3. 人生马拉松</h1>
<p><strong>“没法接受渺小　却望老天照料”</strong></p>
<p>撑住，享受，人生多奥妙。</p>
<p><strong>“明明全部气力　一早消耗了</strong> <strong>用意志力抵销　却又看出奥妙”</strong></p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>MSL_Last</title>
    <url>/2024/07/07/MSL-Last/</url>
    <content><![CDATA[<p>要毕业了，MSL系列该写个终章才是。</p>
<p>该给7年武汉生活也写个句号才是。</p>
<p>一如此刻落笔的踟蹰，3年的研究生生涯似乎没留下什么值得说道的记录。宏愿未了，壮志已消，不过按部就班地完成了学业。</p>
<p>（2024.05.17）</p>
<hr />
<p>明日入职，MSL-终章最终还是没写出来。</p>
<blockquote>
<p>“偶爾亦明瞭別讓潛力浪費 但發完力三秒還是怕倦坐低”</p>
</blockquote>
<p>喂衰仔，勤力滴，给心机干活啦。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
</search>
